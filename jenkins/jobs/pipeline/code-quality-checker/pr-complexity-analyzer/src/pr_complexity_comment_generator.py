#!/usr/bin/env python3
"""
PRè¤‡é›‘åº¦è§£æçµæœã«åŸºã¥ãã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
OpenAI APIã‚’ä½¿ç”¨ã—ã¦ã€è¤‡é›‘åº¦è§£æçµæœã‹ã‚‰æ„å‘³ã®ã‚ã‚‹PRã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""

import json
import os
import argparse
import logging
import re
from typing import Dict, Any, List, Tuple
from openai import OpenAI
from datetime import datetime
from dataclasses import dataclass
import time
from prompt_builder import PromptBuilder, CommentFormatter

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class ComplexityThresholds:
    """
    è¤‡é›‘åº¦ã®é–¾å€¤è¨­å®š

    ã‚³ãƒ¼ãƒ‰è¤‡é›‘åº¦ã‚’è©•ä¾¡ã™ã‚‹éš›ã®åŸºæº–å€¤ã‚’ä¿æŒã—ã¾ã™ã€‚
    å¾ªç’°çš„è¤‡é›‘åº¦ã¨èªçŸ¥çš„è¤‡é›‘åº¦ãã‚Œãã‚Œã«å¯¾ã—ã¦ã€
    é–¾å€¤ï¼ˆè¶…éã§è­¦å‘Šï¼‰ã¨è­¦å‘Šãƒ¬ãƒ™ãƒ«ï¼ˆæ³¨æ„ãŒå¿…è¦ï¼‰ã‚’è¨­å®šã—ã¾ã™ã€‚

    Attributes:
        cyclomatic: å¾ªç’°çš„è¤‡é›‘åº¦ã®é–¾å€¤ï¼ˆã“ã®å€¤ã‚’è¶…ãˆã‚‹ã¨é«˜è¤‡é›‘åº¦ã¨åˆ¤å®šï¼‰
        cognitive: èªçŸ¥çš„è¤‡é›‘åº¦ã®é–¾å€¤ï¼ˆã“ã®å€¤ã‚’è¶…ãˆã‚‹ã¨é«˜è¤‡é›‘åº¦ã¨åˆ¤å®šï¼‰
        cyclomatic_warning: å¾ªç’°çš„è¤‡é›‘åº¦ã®è­¦å‘Šãƒ¬ãƒ™ãƒ«ï¼ˆé–¾å€¤ã®70%ç¨‹åº¦ï¼‰
        cognitive_warning: èªçŸ¥çš„è¤‡é›‘åº¦ã®è­¦å‘Šãƒ¬ãƒ™ãƒ«ï¼ˆé–¾å€¤ã®70%ç¨‹åº¦ï¼‰
    """
    cyclomatic: int
    cognitive: int
    cyclomatic_warning: int
    cognitive_warning: int


@dataclass
class FunctionMetrics:
    """
    é–¢æ•°ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹æƒ…å ±

    å€‹åˆ¥ã®é–¢æ•°ã«å¯¾ã™ã‚‹è¤‡é›‘åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿æŒã—ã¾ã™ã€‚
    é–¢æ•°ã®è­˜åˆ¥æƒ…å ±ï¼ˆåå‰ã€ãƒ•ã‚¡ã‚¤ãƒ«ã€è¡Œç•ªå·ï¼‰ã¨
    è¤‡é›‘åº¦æŒ‡æ¨™ï¼ˆå¾ªç’°çš„ã€èªçŸ¥çš„ã€è¡Œæ•°ï¼‰ã‚’å«ã¿ã¾ã™ã€‚

    Attributes:
        name: é–¢æ•°åï¼ˆã‚¯ãƒ©ã‚¹å::ãƒ¡ã‚½ãƒƒãƒ‰å å½¢å¼ã®å ´åˆã‚ã‚Šï¼‰
        file: é–¢æ•°ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        cyclomatic: å¾ªç’°çš„è¤‡é›‘åº¦ï¼ˆæ¡ä»¶åˆ†å²ã®æ•°ã«åŸºã¥ãï¼‰
        cognitive: èªçŸ¥çš„è¤‡é›‘åº¦ï¼ˆã‚³ãƒ¼ãƒ‰ã®ç†è§£ã—ã‚„ã™ã•ã®æŒ‡æ¨™ï¼‰
        lines: é–¢æ•°ã®ã‚³ãƒ¼ãƒ‰è¡Œæ•°
        start_line: é–¢æ•°å®šç¾©ã®é–‹å§‹è¡Œç•ªå·
        end_line: é–¢æ•°å®šç¾©ã®çµ‚äº†è¡Œç•ªå·
    """
    name: str
    file: str
    cyclomatic: int
    cognitive: int
    lines: int
    start_line: int
    end_line: int


@dataclass
class ComplexityStatistics:
    """
    è¤‡é›‘åº¦çµ±è¨ˆæƒ…å ±

    è§£æå¯¾è±¡å…¨ä½“ã®è¤‡é›‘åº¦çµ±è¨ˆã‚’ä¿æŒã—ã¾ã™ã€‚
    ç·é–¢æ•°æ•°ã€å¹³å‡ãƒ»æœ€å¤§è¤‡é›‘åº¦ã€é–¾å€¤è¶…éé–¢æ•°ã®ãƒªã‚¹ãƒˆãªã©ã€
    PRã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã«å¿…è¦ãªå…¨ã¦ã®çµ±è¨ˆæƒ…å ±ã‚’å«ã¿ã¾ã™ã€‚

    Attributes:
        total_functions: è§£æå¯¾è±¡ã®ç·é–¢æ•°æ•°
        total_files: è§£æå¯¾è±¡ã®ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°
        avg_cyclomatic: å¾ªç’°çš„è¤‡é›‘åº¦ã®å¹³å‡å€¤
        avg_cognitive: èªçŸ¥çš„è¤‡é›‘åº¦ã®å¹³å‡å€¤
        max_cyclomatic: å¾ªç’°çš„è¤‡é›‘åº¦ã®æœ€å¤§å€¤
        max_cognitive: èªçŸ¥çš„è¤‡é›‘åº¦ã®æœ€å¤§å€¤
        thresholds: é©ç”¨ã•ã‚ŒãŸè¤‡é›‘åº¦é–¾å€¤è¨­å®š
        functions_above_threshold: é–¾å€¤ã‚’è¶…ãˆã‚‹é–¢æ•°ã®æ•°ï¼ˆç¨®åˆ¥ã”ã¨ï¼‰
        high_complexity_functions: é–¾å€¤ã‚’è¶…ãˆã‚‹é–¢æ•°ã®ãƒªã‚¹ãƒˆ
        warning_level_functions: è­¦å‘Šãƒ¬ãƒ™ãƒ«ã®é–¢æ•°ã®ãƒªã‚¹ãƒˆ
    """
    total_functions: int
    total_files: int
    avg_cyclomatic: float
    avg_cognitive: float
    max_cyclomatic: int
    max_cognitive: int
    thresholds: ComplexityThresholds
    functions_above_threshold: Dict[str, int]
    high_complexity_functions: List[Dict[str, Any]]
    warning_level_functions: List[Dict[str, Any]]


@dataclass
class OpenAIConfig:
    """
    OpenAI APIè¨­å®š

    OpenAI APIã¸ã®æ¥ç¶šã¨ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿æŒã—ã¾ã™ã€‚
    APIã‚­ãƒ¼ã€ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã€ç”Ÿæˆåˆ¶å¾¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç®¡ç†ã—ã¾ã™ã€‚

    Attributes:
        api_key: OpenAI APIã‚­ãƒ¼ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—æ¨å¥¨ï¼‰
        model: ä½¿ç”¨ã™ã‚‹GPTãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gpt-4.1ï¼‰
        temperature: ç”Ÿæˆã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ï¼ˆ0.0-2.0ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.7ï¼‰
        max_tokens: ç”Ÿæˆã™ã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3000ï¼‰
        debug_mode: ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®æœ‰åŠ¹/ç„¡åŠ¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Falseï¼‰
    """
    api_key: str
    model: str = "gpt-4.1"
    temperature: float = 0.7
    max_tokens: int = 3000
    debug_mode: bool = False


class StatisticsCalculator:
    """çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def calculate_thresholds(analysis_result: Dict[str, Any]) -> ComplexityThresholds:
        """é–¾å€¤æƒ…å ±ã‚’è¨ˆç®—"""
        thresholds = analysis_result.get('thresholds', {})
        cyclomatic_threshold = thresholds.get('cyclomatic', 15)
        cognitive_threshold = thresholds.get('cognitive', 20)
        
        return ComplexityThresholds(
            cyclomatic=cyclomatic_threshold,
            cognitive=cognitive_threshold,
            cyclomatic_warning=int(cyclomatic_threshold * 0.7),
            cognitive_warning=int(cognitive_threshold * 0.7)
        )
    
    @staticmethod
    def classify_functions(all_functions: List[Dict[str, Any]], 
                         thresholds: ComplexityThresholds) -> Tuple[List[Dict], List[Dict]]:
        """é–¢æ•°ã‚’è¤‡é›‘åº¦ãƒ¬ãƒ™ãƒ«ã§åˆ†é¡"""
        high_complexity = []
        warning_level = []
        
        for func in all_functions:
            cogn = func.get('cognitive', 0)
            cyclo = func.get('cyclomatic', 0)
            
            if cogn > thresholds.cognitive or cyclo > thresholds.cyclomatic:
                high_complexity.append(func)
            elif (thresholds.cognitive_warning <= cogn <= thresholds.cognitive or
                  thresholds.cyclomatic_warning <= cyclo <= thresholds.cyclomatic):
                warning_level.append(func)
        
        return high_complexity, warning_level
    
    @staticmethod
    def calculate_averages(file_analyses: Dict[str, Any]) -> Tuple[float, float, int, int]:
        """ãƒ•ã‚¡ã‚¤ãƒ«è§£æãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¹³å‡å€¤ã¨æœ€å¤§å€¤ã‚’è¨ˆç®—"""
        if not file_analyses:
            return 0.0, 0.0, 0, 0
        
        # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒªã‚¹ãƒˆã‚’åé›†
        metrics = StatisticsCalculator._collect_metrics(file_analyses)
        
        # å¹³å‡å€¤ã¨æœ€å¤§å€¤ã‚’è¨ˆç®—
        avg_cyclomatic = StatisticsCalculator._calculate_average(metrics['avg_cyclo'])
        avg_cognitive = StatisticsCalculator._calculate_average(metrics['avg_cogn'])
        max_cyclomatic = max(metrics['max_cyclo']) if metrics['max_cyclo'] else 0
        max_cognitive = max(metrics['max_cogn']) if metrics['max_cogn'] else 0
        
        return avg_cyclomatic, avg_cognitive, max_cyclomatic, max_cognitive
    
    @staticmethod
    def _collect_metrics(file_analyses: Dict[str, Any]) -> Dict[str, List[float]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«è§£æãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†"""
        metrics = {
            'avg_cyclo': [],
            'avg_cogn': [],
            'max_cyclo': [],
            'max_cogn': []
        }
        
        for file_data in file_analyses.values():
            if file_data.get('average_cyclomatic', 0) > 0:
                metrics['avg_cyclo'].append(file_data['average_cyclomatic'])
            if file_data.get('average_cognitive', 0) > 0:
                metrics['avg_cogn'].append(file_data['average_cognitive'])
            metrics['max_cyclo'].append(file_data.get('max_cyclomatic', 0))
            metrics['max_cogn'].append(file_data.get('max_cognitive', 0))
        
        return metrics
    
    @staticmethod
    def _calculate_average(values: List[float]) -> float:
        """ãƒªã‚¹ãƒˆã®å¹³å‡å€¤ã‚’è¨ˆç®—"""
        return sum(values) / len(values) if values else 0.0


class PRComplexityCommentGenerator:
    """PRè¤‡é›‘åº¦è§£æçµæœã‹ã‚‰ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, debug_mode: bool = False, save_prompt: bool = False):
        """åˆæœŸåŒ–"""
        # OpenAIè¨­å®šã‚’æ§‹ç¯‰
        self.config = OpenAIConfig(
            api_key=os.getenv("OPENAI_API_KEY"),
            model=os.getenv("OPENAI_MODEL", "gpt-4.1"),
            debug_mode=debug_mode
        )
        
        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        self.client = OpenAI(
            api_key=self.config.api_key
        )
        
        self.stats_calculator = StatisticsCalculator()
        self.comment_formatter = CommentFormatter()
        self.save_prompt = save_prompt
        self.show_prompt = False  # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹
        
        # è¨­å®šã‚’ãƒ­ã‚°å‡ºåŠ›
        self._log_configuration()
    
    def _log_configuration(self):
        """ç¾åœ¨ã®è¨­å®šã‚’ãƒ­ã‚°å‡ºåŠ›"""
        logger.info("=== OpenAI API Configuration ===")
        logger.info(f"Model: {self.config.model}")
        logger.info(f"Temperature: {self.config.temperature}")
        logger.info(f"Max Tokens: {self.config.max_tokens}")
        logger.info(f"Debug Mode: {self.config.debug_mode}")
        logger.info("================================")
        
    def generate_comment(self, analysis_result: Dict[str, Any]) -> str:
        """
        è§£æçµæœã‹ã‚‰PRã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            analysis_result: è¤‡é›‘åº¦è§£æçµæœ
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆ
        """
        # çµ±è¨ˆæƒ…å ±ã‚’æº–å‚™
        stats = self._prepare_statistics(analysis_result)

        prompt_builder = PromptBuilder(stats, analysis_result)
        prompt = prompt_builder.build_prompt()
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¡¨ç¤ºã¨ä¿å­˜
        self._handle_prompt_output(prompt)
        
        # OpenAI APIã‚’å‘¼ã³å‡ºã—ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
        try:
            content = self._call_openai_api(prompt)
            return self._clean_markdown_tags(content)
        except Exception as e:
            return self._handle_api_error(e, analysis_result, stats)
    
    def _handle_prompt_output(self, prompt: str) -> None:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¡¨ç¤ºã¨ä¿å­˜ã‚’å‡¦ç†"""
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if self.show_prompt:
            print("\n" + "="*60)
            print("PROMPT TO OPENAI:")
            print("="*60)
            print(prompt)
            print("="*60 + "\n")
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã¾ãŸã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿å­˜ãŒæœ‰åŠ¹ãªå ´åˆ
        if self.config.debug_mode or self.save_prompt:
            self._save_prompt_to_file(prompt)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ–‡å­—æ•°ã¨ãƒˆãƒ¼ã‚¯ãƒ³æ¦‚ç®—ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆå¸¸ã«è¡¨ç¤ºï¼‰
        prompt_length = len(prompt)
        estimated_tokens = prompt_length // 4  # æ¦‚ç®—ï¼š1ãƒˆãƒ¼ã‚¯ãƒ³â‰’4æ–‡å­—
        logger.info(f"Prompt length: {prompt_length} characters (estimated ~{estimated_tokens} tokens)")
    
    def _call_openai_api(self, prompt: str) -> str:
        """OpenAI APIã‚’å‘¼ã³å‡ºã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—"""
        logger.info("Calling OpenAI API...")
        start_time = time.time()
        
        messages = [
            {
                "role": "system",
                "content": "ã‚ãªãŸã¯ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å°‚é–€å®¶ã§ã™ã€‚è¤‡é›‘åº¦è§£æçµæœã‚’åˆ†æã—ã€é–‹ç™ºè€…ã«æœ‰ç”¨ãªå…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¾ã™ã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ]
        
        # APIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°å‡ºåŠ›
        if self.config.debug_mode:
            logger.debug(f"Messages: {json.dumps(messages, ensure_ascii=False, indent=2)}")
        
        response = self.client.chat.completions.create(
            model=self.config.model,
            messages=messages,
            temperature=self.config.temperature,
            max_tokens=self.config.max_tokens
        )
        
        # APIå‘¼ã³å‡ºã—ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
        self._log_api_response_details(response, start_time)
        
        content = response.choices[0].message.content
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚ä¿å­˜
        if self.config.debug_mode:
            self._save_response_to_file(content)
        
        return content
    
    def _log_api_response_details(self, response: Any, start_time: float) -> None:
        """APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›"""
        elapsed_time = time.time() - start_time
        logger.info(f"API call completed in {elapsed_time:.2f} seconds")
        logger.info(f"Usage - Prompt tokens: {response.usage.prompt_tokens}")
        logger.info(f"Usage - Completion tokens: {response.usage.completion_tokens}")
        logger.info(f"Usage - Total tokens: {response.usage.total_tokens}")
    
    def _handle_api_error(self, error: Exception, analysis_result: Dict[str, Any], 
                         stats: ComplexityStatistics) -> str:
        """APIã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ã—ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ"""
        logger.error(f"OpenAI APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {error}")
        logger.error(f"Error type: {type(error).__name__}")
        return self._generate_fallback_comment(analysis_result, stats)
    
    def _save_prompt_to_file(self, prompt: str):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"openai_prompt_{timestamp}.txt"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write("=== OpenAI API Prompt ===\n")
                f.write(f"Timestamp: {datetime.now().isoformat()}\n")
                f.write(f"Model: {self.config.model}\n")
                f.write(f"Temperature: {self.config.temperature}\n")
                f.write(f"Max Tokens: {self.config.max_tokens}\n")
                f.write("========================\n\n")
                f.write(prompt)
            logger.info(f"Prompt saved to: {filename}")
        except Exception as e:
            logger.error(f"Failed to save prompt: {e}")
    
    def _save_response_to_file(self, response: str):
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"openai_response_{timestamp}.md"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(response)
            logger.info(f"Response saved to: {filename}")
        except Exception as e:
            logger.error(f"Failed to save response: {e}")
    
    def _clean_markdown_tags(self, content: str) -> str:
        """
        ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ä¸è¦ãªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚¿ã‚°ã‚’å‰Šé™¤
        
        Args:
            content: å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            
        Returns:
            ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        """
        if not content:
            return content
            
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡Œã«åˆ†å‰²
        lines = content.split('\n')
        
        # æœ€åˆã¨æœ€å¾Œã®```markdownã‚¿ã‚°ã‚’å‰Šé™¤
        if lines and lines[0].strip().lower() in ['```markdown', '```md', '```']:
            lines = lines[1:]
        if lines and lines[-1].strip() == '```':
            lines = lines[:-1]
            
        # å†åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆè¤‡æ•°ã®```ã‚¿ã‚°ãŒã‚ã‚‹å ´åˆï¼‰
        cleaned_content = '\n'.join(lines)
        
        # æ­£è¦è¡¨ç¾ã§æ®‹ã‚Šã®```markdownã‚¿ã‚°ã‚’å‰Šé™¤ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã®ã‚‚ã®ã¯ä¿æŒï¼‰
        # ãƒ‘ã‚¿ãƒ¼ãƒ³: è¡Œé ­ã®```markdown ã¾ãŸã¯ ```md ã‚’å‰Šé™¤
        cleaned_content = re.sub(r'^```(?:markdown|md)\s*\n', '', cleaned_content, flags=re.MULTILINE)
        cleaned_content = re.sub(r'\n```\s*$', '', cleaned_content, flags=re.MULTILINE)
        
        # é€£ç¶šã™ã‚‹ç©ºè¡Œã‚’1ã¤ã«å‰Šæ¸›
        cleaned_content = re.sub(r'\n\n\n+', '\n\n', cleaned_content)
        
        # å…ˆé ­ã¨æœ«å°¾ã®ç©ºç™½ã‚’å‰Šé™¤
        cleaned_content = cleaned_content.strip()
        
        return cleaned_content
    
    def _prepare_statistics(self, analysis_result: Dict[str, Any]) -> ComplexityStatistics:
        """çµ±è¨ˆæƒ…å ±ã‚’æº–å‚™ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰"""
        # é–¾å€¤ã‚’è¨ˆç®—
        thresholds = self.stats_calculator.calculate_thresholds(analysis_result)
        
        # åŸºæœ¬çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        total_functions = analysis_result.get('total_functions', 0)
        total_files = analysis_result.get('total_files_analyzed', 0)
        
        # å…¨é–¢æ•°æƒ…å ±ã‚’å–å¾—
        all_functions = analysis_result.get('all_functions', [])
        
        # é–¢æ•°ã‚’åˆ†é¡
        if all_functions:
            high_complexity, warning_level = self.stats_calculator.classify_functions(
                all_functions, thresholds
            )
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šhigh_complexity_functionsã®ã¿ã‚’ä½¿ç”¨
            high_complexity = analysis_result.get('high_complexity_functions', [])
            warning_level = []
        
        # å¹³å‡å€¤ã¨æœ€å¤§å€¤ã‚’è¨ˆç®—
        avg_cyclo, avg_cogn, max_cyclo, max_cogn = self.stats_calculator.calculate_averages(
            analysis_result.get('file_analyses', {})
        )
        
        return ComplexityStatistics(
            total_functions=total_functions,
            total_files=total_files,
            avg_cyclomatic=avg_cyclo,
            avg_cognitive=avg_cogn,
            max_cyclomatic=max_cyclo,
            max_cognitive=max_cogn,
            thresholds=thresholds,
            functions_above_threshold={
                'cyclomatic': analysis_result.get('high_complexity_functions_cyclomatic', 0),
                'cognitive': analysis_result.get('high_complexity_functions_cognitive', 0)
            },
            high_complexity_functions=high_complexity,
            warning_level_functions=warning_level
        )
    
    def _generate_fallback_comment(self, analysis_result: Dict[str, Any], 
                                  stats: ComplexityStatistics) -> str:
        """APIã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰"""
        comment = []
        
        # ã‚µãƒãƒªãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        comment.extend(self.comment_formatter.create_summary_section(stats, analysis_result))
        
        # é–¾å€¤ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        comment.extend(self.comment_formatter.create_threshold_section(stats.thresholds))
        
        # é‡è¦ãªç™ºè¦‹äº‹é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        comment.extend(self._create_findings_section(stats))
        
        # æ¨å¥¨äº‹é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        has_complex = (stats.functions_above_threshold['cognitive'] > 0 or 
                      stats.functions_above_threshold['cyclomatic'] > 0)
        comment.extend(self.comment_formatter.create_recommendations_section(has_complex))
        
        return "\n".join(comment)
    
    def _create_findings_section(self, stats: ComplexityStatistics) -> List[str]:
        """ç™ºè¦‹äº‹é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        findings = ["## ğŸ¯ é‡è¦ãªç™ºè¦‹äº‹é …"]
        
        # é«˜è¤‡é›‘åº¦é–¢æ•°
        if stats.high_complexity_functions:
            findings.extend(self._format_critical_functions(stats))
        
        # è­¦å‘Šãƒ¬ãƒ™ãƒ«é–¢æ•°
        if stats.warning_level_functions:
            findings.extend(self._format_warning_functions(stats))
        
        # å…¨ã¦è‰¯å¥½ãªå ´åˆ
        if not stats.high_complexity_functions and not stats.warning_level_functions:
            findings.extend([
                "## âœ… è‰¯å¥½ãªå®Ÿè£…",
                "ã™ã¹ã¦ã®é–¢æ•°ã®è¤‡é›‘åº¦ãŒé©åˆ‡ã«ç®¡ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚",
                ""
            ])
        
        return findings
    
    def _format_critical_functions(self, stats: ComplexityStatistics) -> List[str]:
        """é‡è¦åº¦ã®é«˜ã„é–¢æ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        result = ["\n### ğŸš¨ å„ªå…ˆçš„ã«å¯¾å¿œãŒå¿…è¦ãªé–¢æ•°"]
        
        sorted_funcs = sorted(stats.high_complexity_functions, 
                            key=lambda x: x.get('cognitive', 0), reverse=True)
        
        for i, func in enumerate(sorted_funcs[:5], 1):
            result.extend([
                f"\n**{i}. {func.get('name', 'Unknown')}**",
                f"- èªçŸ¥çš„è¤‡é›‘åº¦: {func.get('cognitive', 0)} (é–¾å€¤: {stats.thresholds.cognitive})",
                f"- å¾ªç’°çš„è¤‡é›‘åº¦: {func.get('cyclomatic', 0)} (é–¾å€¤: {stats.thresholds.cyclomatic})",
                f"- ãƒ•ã‚¡ã‚¤ãƒ«: `{func.get('file', 'Unknown')}`",
                f"- æ”¹å–„ææ¡ˆ: ã“ã®é–¢æ•°ã¯è¤‡é›‘åº¦ãŒé«˜ã„ãŸã‚ã€æ©Ÿèƒ½ã”ã¨ã«å°ã•ãªé–¢æ•°ã«åˆ†å‰²ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
            ])
        
        return result
    
    def _format_warning_functions(self, stats: ComplexityStatistics) -> List[str]:
        """è­¦å‘Šãƒ¬ãƒ™ãƒ«ã®é–¢æ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        result = ["\n### âš ï¸ æ³¨æ„ãŒå¿…è¦ãªé ˜åŸŸ"]
        
        for i, func in enumerate(stats.warning_level_functions[:3], 1):
            result.append(
                f"{i}. `{func.get('name', 'Unknown')}` - "
                f"èªçŸ¥çš„: {func.get('cognitive', 0)}, "
                f"å¾ªç’°çš„: {func.get('cyclomatic', 0)}"
            )
        
        return result


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='PRè¤‡é›‘åº¦è§£æã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ')
    parser.add_argument('--analysis-result', required=True, help='è§£æçµæœJSONãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--output', required=True, help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--debug', action='store_true', help='ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–')
    parser.add_argument('--save-prompt', action='store_true', help='ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜')
    parser.add_argument('--show-prompt', action='store_true', help='ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤º')
    
    args = parser.parse_args()
    
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®è¨­å®š
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # è§£æçµæœã‚’èª­ã¿è¾¼ã¿
    logger.info(f"Loading analysis result from {args.analysis_result}")
    with open(args.analysis_result, 'r', encoding='utf-8') as f:
        analysis_result = json.load(f)
    
    # ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
    generator = PRComplexityCommentGenerator(
        debug_mode=args.debug,
        save_prompt=args.save_prompt
    )
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if args.show_prompt:
        generator.show_prompt = True
    
    comment = generator.generate_comment(analysis_result)
    
    # çµæœã‚’ä¿å­˜
    result = {
        'comment': comment,
        'generated_at': datetime.now().isoformat(),
        'analysis_summary': {
            'total_files_analyzed': analysis_result.get('total_files_analyzed', 0),
            'total_functions': analysis_result.get('total_functions', 0),
            'high_complexity_cyclomatic': analysis_result.get('high_complexity_functions_cyclomatic', 0),
            'high_complexity_cognitive': analysis_result.get('high_complexity_functions_cognitive', 0)
        },
        'generation_metadata': {
            'model': generator.config.model,
            'temperature': generator.config.temperature,
            'max_tokens': generator.config.max_tokens
        }
    }
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«å«ã‚ã‚‹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if args.save_prompt or args.show_prompt or args.debug:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å†ç”Ÿæˆã—ã¦çµæœã«å«ã‚ã‚‹
        stats = generator._prepare_statistics(analysis_result)
        prompt_builder = PromptBuilder(stats, analysis_result)
        prompt = prompt_builder.build_prompt()
        result['generation_metadata']['prompt'] = prompt
        result['generation_metadata']['prompt_length'] = len(prompt)
        result['generation_metadata']['estimated_prompt_tokens'] = len(prompt) // 4
    
    logger.info(f"Saving comment to {args.output}")
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    # ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    print(f"\nComment generated successfully!")
    print(f"- Model used: {generator.config.model}")
    print(f"- Files analyzed: {result['analysis_summary']['total_files_analyzed']}")
    print(f"- Total functions: {result['analysis_summary']['total_functions']}")
    print(f"- High complexity functions (cyclomatic): {result['analysis_summary']['high_complexity_cyclomatic']}")
    print(f"- High complexity functions (cognitive): {result['analysis_summary']['high_complexity_cognitive']}")


if __name__ == '__main__':
    main()
