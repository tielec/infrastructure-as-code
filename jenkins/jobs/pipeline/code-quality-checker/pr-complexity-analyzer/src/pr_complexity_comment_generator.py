#!/usr/bin/env python3
"""
PRè¤‡é›‘åº¦è§£æçµæœã«åŸºã¥ãã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
OpenAI APIã‚’ä½¿ç”¨ã—ã¦ã€è¤‡é›‘åº¦è§£æçµæœã‹ã‚‰æ„å‘³ã®ã‚ã‚‹PRã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""

import json
import os
import argparse
import logging
import re
from typing import Dict, Any, List, Tuple, Optional
from openai import OpenAI
from datetime import datetime
from dataclasses import dataclass
import time

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class ComplexityThresholds:
    """è¤‡é›‘åº¦ã®é–¾å€¤è¨­å®š"""
    cyclomatic: int
    cognitive: int
    cyclomatic_warning: int
    cognitive_warning: int


@dataclass
class FunctionMetrics:
    """é–¢æ•°ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹æƒ…å ±"""
    name: str
    file: str
    cyclomatic: int
    cognitive: int
    lines: int
    start_line: int
    end_line: int


@dataclass
class ComplexityStatistics:
    """è¤‡é›‘åº¦çµ±è¨ˆæƒ…å ±"""
    total_functions: int
    total_files: int
    avg_cyclomatic: float
    avg_cognitive: float
    max_cyclomatic: int
    max_cognitive: int
    thresholds: ComplexityThresholds
    functions_above_threshold: Dict[str, int]
    high_complexity_functions: List[Dict[str, Any]]
    warning_level_functions: List[Dict[str, Any]]


@dataclass
class OpenAIConfig:
    """OpenAI APIè¨­å®š"""
    api_key: str
    model: str = "gpt-4.1"
    temperature: float = 0.7
    max_tokens: int = 3000
    debug_mode: bool = False


class StatisticsCalculator:
    """çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def calculate_thresholds(analysis_result: Dict[str, Any]) -> ComplexityThresholds:
        """é–¾å€¤æƒ…å ±ã‚’è¨ˆç®—"""
        thresholds = analysis_result.get('thresholds', {})
        cyclomatic_threshold = thresholds.get('cyclomatic', 15)
        cognitive_threshold = thresholds.get('cognitive', 20)
        
        return ComplexityThresholds(
            cyclomatic=cyclomatic_threshold,
            cognitive=cognitive_threshold,
            cyclomatic_warning=int(cyclomatic_threshold * 0.7),
            cognitive_warning=int(cognitive_threshold * 0.7)
        )
    
    @staticmethod
    def classify_functions(all_functions: List[Dict[str, Any]], 
                         thresholds: ComplexityThresholds) -> Tuple[List[Dict], List[Dict]]:
        """é–¢æ•°ã‚’è¤‡é›‘åº¦ãƒ¬ãƒ™ãƒ«ã§åˆ†é¡"""
        high_complexity = []
        warning_level = []
        
        for func in all_functions:
            cogn = func.get('cognitive', 0)
            cyclo = func.get('cyclomatic', 0)
            
            if cogn > thresholds.cognitive or cyclo > thresholds.cyclomatic:
                high_complexity.append(func)
            elif (thresholds.cognitive_warning <= cogn <= thresholds.cognitive or
                  thresholds.cyclomatic_warning <= cyclo <= thresholds.cyclomatic):
                warning_level.append(func)
        
        return high_complexity, warning_level
    
    @staticmethod
    def calculate_averages(file_analyses: Dict[str, Any]) -> Tuple[float, float, int, int]:
        """ãƒ•ã‚¡ã‚¤ãƒ«è§£æãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¹³å‡å€¤ã¨æœ€å¤§å€¤ã‚’è¨ˆç®—"""
        if not file_analyses:
            return 0.0, 0.0, 0, 0
        
        # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒªã‚¹ãƒˆã‚’åé›†
        metrics = StatisticsCalculator._collect_metrics(file_analyses)
        
        # å¹³å‡å€¤ã¨æœ€å¤§å€¤ã‚’è¨ˆç®—
        avg_cyclomatic = StatisticsCalculator._calculate_average(metrics['avg_cyclo'])
        avg_cognitive = StatisticsCalculator._calculate_average(metrics['avg_cogn'])
        max_cyclomatic = max(metrics['max_cyclo']) if metrics['max_cyclo'] else 0
        max_cognitive = max(metrics['max_cogn']) if metrics['max_cogn'] else 0
        
        return avg_cyclomatic, avg_cognitive, max_cyclomatic, max_cognitive
    
    @staticmethod
    def _collect_metrics(file_analyses: Dict[str, Any]) -> Dict[str, List[float]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«è§£æãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†"""
        metrics = {
            'avg_cyclo': [],
            'avg_cogn': [],
            'max_cyclo': [],
            'max_cogn': []
        }
        
        for file_data in file_analyses.values():
            if file_data.get('average_cyclomatic', 0) > 0:
                metrics['avg_cyclo'].append(file_data['average_cyclomatic'])
            if file_data.get('average_cognitive', 0) > 0:
                metrics['avg_cogn'].append(file_data['average_cognitive'])
            metrics['max_cyclo'].append(file_data.get('max_cyclomatic', 0))
            metrics['max_cogn'].append(file_data.get('max_cognitive', 0))
        
        return metrics
    
    @staticmethod
    def _calculate_average(values: List[float]) -> float:
        """ãƒªã‚¹ãƒˆã®å¹³å‡å€¤ã‚’è¨ˆç®—"""
        return sum(values) / len(values) if values else 0.0


class CommentFormatter:
    """ã‚³ãƒ¡ãƒ³ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def format_function_header(func: Dict[str, Any], index: int) -> List[str]:
        """é–¢æ•°ã®ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        return [
            f"\n{index}. **{func.get('name', 'Unknown')}**",
            f"   - ãƒ•ã‚¡ã‚¤ãƒ«: {func.get('file', 'Unknown')}",
            f"   - è¡Œ: {func.get('start_line', 0)}-{func.get('end_line', 0)}",
        ]
    
    @staticmethod
    def format_complexity_metrics(func: Dict[str, Any], thresholds: ComplexityThresholds) -> List[str]:
        """è¤‡é›‘åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        return [
            f"   - èªçŸ¥çš„è¤‡é›‘åº¦: {func.get('cognitive', 0)} (é–¾å€¤: {thresholds.cognitive})",
            f"   - å¾ªç’°çš„è¤‡é›‘åº¦: {func.get('cyclomatic', 0)} (é–¾å€¤: {thresholds.cyclomatic})",
            f"   - ã‚³ãƒ¼ãƒ‰è¡Œæ•°: {func.get('lines', 0)}",
        ]
    
    @staticmethod
    def format_warning_metrics(func: Dict[str, Any], thresholds: ComplexityThresholds) -> List[str]:
        """è­¦å‘Šãƒ¬ãƒ™ãƒ«ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        return [
            f"   - èªçŸ¥çš„è¤‡é›‘åº¦: {func.get('cognitive', 0)} "
            f"(è­¦å‘Š: {thresholds.cognitive_warning}, é–¾å€¤: {thresholds.cognitive})",
            f"   - å¾ªç’°çš„è¤‡é›‘åº¦: {func.get('cyclomatic', 0)} "
            f"(è­¦å‘Š: {thresholds.cyclomatic_warning}, é–¾å€¤: {thresholds.cyclomatic})",
        ]
    
    @staticmethod
    def create_summary_section(stats: ComplexityStatistics, pr_info: Dict[str, Any]) -> List[str]:
        """ã‚µãƒãƒªãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        return [
            "# ğŸ” ã‚³ãƒ¼ãƒ‰è¤‡é›‘åº¦è§£æãƒ¬ãƒãƒ¼ãƒˆ",
            "",
            "## ğŸ“Š è§£æã‚µãƒãƒªãƒ¼",
            f"PR #{pr_info.get('pr_number', 'N/A')}ã®è¤‡é›‘åº¦è§£æãŒå®Œäº†ã—ã¾ã—ãŸã€‚",
            f"- è§£æãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats.total_files}",
            f"- ç·é–¢æ•°æ•°: {stats.total_functions}",
            f"- å¹³å‡å¾ªç’°çš„è¤‡é›‘åº¦: {stats.avg_cyclomatic:.2f}",
            f"- å¹³å‡èªçŸ¥çš„è¤‡é›‘åº¦: {stats.avg_cognitive:.2f}",
            "",
        ]
    
    @staticmethod
    def create_threshold_section(thresholds: ComplexityThresholds) -> List[str]:
        """é–¾å€¤ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        return [
            "## ğŸ“ è¤‡é›‘åº¦ã®é–¾å€¤",
            f"- èªçŸ¥çš„è¤‡é›‘åº¦: è­¦å‘Š {thresholds.cognitive_warning}, é–¾å€¤ {thresholds.cognitive}",
            f"- å¾ªç’°çš„è¤‡é›‘åº¦: è­¦å‘Š {thresholds.cyclomatic_warning}, é–¾å€¤ {thresholds.cyclomatic}",
            "",
        ]
    
    @staticmethod
    def create_recommendations_section(has_complex_functions: bool) -> List[str]:
        """æ¨å¥¨äº‹é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        if has_complex_functions:
            return [
                "",
                "## ğŸ’¡ æ¨å¥¨äº‹é …",
                "1. ğŸ”´ é–¾å€¤ã‚’è¶…ãˆã‚‹é–¢æ•°ã¯å„ªå…ˆçš„ã«ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã—ã¦ãã ã•ã„",
                "2. å˜ä¸€è²¬ä»»ã®åŸå‰‡ã«å¾“ã£ã¦é–¢æ•°ã‚’åˆ†å‰²ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                "3. æ¡ä»¶åˆ†å²ãŒå¤šã„å ´åˆã¯ã€æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ã‚„ã‚¬ãƒ¼ãƒ‰å¥ã‚’æ´»ç”¨ã—ã¦ãã ã•ã„",
                "4. ãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã‚’æ¸›ã‚‰ã™ãŸã‚ã«ã€å‡¦ç†ã‚’åˆ¥é–¢æ•°ã«æŠ½å‡ºã—ã¦ãã ã•ã„",
            ]
        else:
            return [
                "",
                "## ğŸ’¡ æ¨å¥¨äº‹é …",
                "- ç¾åœ¨ã®è‰¯å¥½ãªçŠ¶æ…‹ã‚’ç¶­æŒã—ã¦ãã ã•ã„",
                "- æ–°æ©Ÿèƒ½è¿½åŠ æ™‚ã‚‚è¤‡é›‘åº¦ã‚’æ„è­˜ã—ãŸå®Ÿè£…ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„",
                "- å®šæœŸçš„ãªã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§è¤‡é›‘åº¦ã‚’ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã—ã¦ãã ã•ã„",
            ]


class PRComplexityCommentGenerator:
    """PRè¤‡é›‘åº¦è§£æçµæœã‹ã‚‰ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, debug_mode: bool = False, save_prompt: bool = False):
        """åˆæœŸåŒ–"""
        # OpenAIè¨­å®šã‚’æ§‹ç¯‰
        self.config = OpenAIConfig(
            api_key=os.getenv("OPENAI_API_KEY"),
            model=os.getenv("OPENAI_MODEL", "gpt-4.1"),
            debug_mode=debug_mode
        )
        
        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        self.client = OpenAI(
            api_key=self.config.api_key
        )
        
        self.stats_calculator = StatisticsCalculator()
        self.comment_formatter = CommentFormatter()
        self.save_prompt = save_prompt
        self.show_prompt = False  # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹
        
        # è¨­å®šã‚’ãƒ­ã‚°å‡ºåŠ›
        self._log_configuration()
    
    def _log_configuration(self):
        """ç¾åœ¨ã®è¨­å®šã‚’ãƒ­ã‚°å‡ºåŠ›"""
        logger.info("=== OpenAI API Configuration ===")
        logger.info(f"Model: {self.config.model}")
        logger.info(f"Temperature: {self.config.temperature}")
        logger.info(f"Max Tokens: {self.config.max_tokens}")
        logger.info(f"Debug Mode: {self.config.debug_mode}")
        logger.info("================================")
        
    def generate_comment(self, analysis_result: Dict[str, Any]) -> str:
        """
        è§£æçµæœã‹ã‚‰PRã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            analysis_result: è¤‡é›‘åº¦è§£æçµæœ
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆ
        """
        # çµ±è¨ˆæƒ…å ±ã‚’æº–å‚™
        stats = self._prepare_statistics(analysis_result)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        prompt = self._build_prompt(analysis_result, stats)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¡¨ç¤ºã¨ä¿å­˜
        self._handle_prompt_output(prompt)
        
        # OpenAI APIã‚’å‘¼ã³å‡ºã—ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ
        try:
            content = self._call_openai_api(prompt)
            return self._clean_markdown_tags(content)
        except Exception as e:
            return self._handle_api_error(e, analysis_result, stats)
    
    def _handle_prompt_output(self, prompt: str) -> None:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¡¨ç¤ºã¨ä¿å­˜ã‚’å‡¦ç†"""
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if self.show_prompt:
            print("\n" + "="*60)
            print("PROMPT TO OPENAI:")
            print("="*60)
            print(prompt)
            print("="*60 + "\n")
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã¾ãŸã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿å­˜ãŒæœ‰åŠ¹ãªå ´åˆ
        if self.config.debug_mode or self.save_prompt:
            self._save_prompt_to_file(prompt)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ–‡å­—æ•°ã¨ãƒˆãƒ¼ã‚¯ãƒ³æ¦‚ç®—ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆå¸¸ã«è¡¨ç¤ºï¼‰
        prompt_length = len(prompt)
        estimated_tokens = prompt_length // 4  # æ¦‚ç®—ï¼š1ãƒˆãƒ¼ã‚¯ãƒ³â‰’4æ–‡å­—
        logger.info(f"Prompt length: {prompt_length} characters (estimated ~{estimated_tokens} tokens)")
    
    def _call_openai_api(self, prompt: str) -> str:
        """OpenAI APIã‚’å‘¼ã³å‡ºã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—"""
        logger.info("Calling OpenAI API...")
        start_time = time.time()
        
        messages = [
            {
                "role": "system",
                "content": "ã‚ãªãŸã¯ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å°‚é–€å®¶ã§ã™ã€‚è¤‡é›‘åº¦è§£æçµæœã‚’åˆ†æã—ã€é–‹ç™ºè€…ã«æœ‰ç”¨ãªå…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¾ã™ã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ]
        
        # APIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°å‡ºåŠ›
        if self.config.debug_mode:
            logger.debug(f"Messages: {json.dumps(messages, ensure_ascii=False, indent=2)}")
        
        response = self.client.chat.completions.create(
            model=self.config.model,
            messages=messages,
            temperature=self.config.temperature,
            max_tokens=self.config.max_tokens
        )
        
        # APIå‘¼ã³å‡ºã—ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
        self._log_api_response_details(response, start_time)
        
        content = response.choices[0].message.content
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚ä¿å­˜
        if self.config.debug_mode:
            self._save_response_to_file(content)
        
        return content
    
    def _log_api_response_details(self, response: Any, start_time: float) -> None:
        """APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›"""
        elapsed_time = time.time() - start_time
        logger.info(f"API call completed in {elapsed_time:.2f} seconds")
        logger.info(f"Usage - Prompt tokens: {response.usage.prompt_tokens}")
        logger.info(f"Usage - Completion tokens: {response.usage.completion_tokens}")
        logger.info(f"Usage - Total tokens: {response.usage.total_tokens}")
    
    def _handle_api_error(self, error: Exception, analysis_result: Dict[str, Any], 
                         stats: ComplexityStatistics) -> str:
        """APIã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ã—ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ"""
        logger.error(f"OpenAI APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {error}")
        logger.error(f"Error type: {type(error).__name__}")
        return self._generate_fallback_comment(analysis_result, stats)
    
    def _save_prompt_to_file(self, prompt: str):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"openai_prompt_{timestamp}.txt"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write("=== OpenAI API Prompt ===\n")
                f.write(f"Timestamp: {datetime.now().isoformat()}\n")
                f.write(f"Model: {self.config.model}\n")
                f.write(f"Temperature: {self.config.temperature}\n")
                f.write(f"Max Tokens: {self.config.max_tokens}\n")
                f.write("========================\n\n")
                f.write(prompt)
            logger.info(f"Prompt saved to: {filename}")
        except Exception as e:
            logger.error(f"Failed to save prompt: {e}")
    
    def _save_response_to_file(self, response: str):
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"openai_response_{timestamp}.md"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(response)
            logger.info(f"Response saved to: {filename}")
        except Exception as e:
            logger.error(f"Failed to save response: {e}")
    
    def _clean_markdown_tags(self, content: str) -> str:
        """
        ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ä¸è¦ãªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚¿ã‚°ã‚’å‰Šé™¤
        
        Args:
            content: å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            
        Returns:
            ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        """
        if not content:
            return content
            
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡Œã«åˆ†å‰²
        lines = content.split('\n')
        
        # æœ€åˆã¨æœ€å¾Œã®```markdownã‚¿ã‚°ã‚’å‰Šé™¤
        if lines and lines[0].strip().lower() in ['```markdown', '```md', '```']:
            lines = lines[1:]
        if lines and lines[-1].strip() == '```':
            lines = lines[:-1]
            
        # å†åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆè¤‡æ•°ã®```ã‚¿ã‚°ãŒã‚ã‚‹å ´åˆï¼‰
        cleaned_content = '\n'.join(lines)
        
        # æ­£è¦è¡¨ç¾ã§æ®‹ã‚Šã®```markdownã‚¿ã‚°ã‚’å‰Šé™¤ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã®ã‚‚ã®ã¯ä¿æŒï¼‰
        # ãƒ‘ã‚¿ãƒ¼ãƒ³: è¡Œé ­ã®```markdown ã¾ãŸã¯ ```md ã‚’å‰Šé™¤
        cleaned_content = re.sub(r'^```(?:markdown|md)\s*\n', '', cleaned_content, flags=re.MULTILINE)
        cleaned_content = re.sub(r'\n```\s*$', '', cleaned_content, flags=re.MULTILINE)
        
        # é€£ç¶šã™ã‚‹ç©ºè¡Œã‚’1ã¤ã«å‰Šæ¸›
        cleaned_content = re.sub(r'\n\n\n+', '\n\n', cleaned_content)
        
        # å…ˆé ­ã¨æœ«å°¾ã®ç©ºç™½ã‚’å‰Šé™¤
        cleaned_content = cleaned_content.strip()
        
        return cleaned_content
    
    def _prepare_statistics(self, analysis_result: Dict[str, Any]) -> ComplexityStatistics:
        """çµ±è¨ˆæƒ…å ±ã‚’æº–å‚™ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰"""
        # é–¾å€¤ã‚’è¨ˆç®—
        thresholds = self.stats_calculator.calculate_thresholds(analysis_result)
        
        # åŸºæœ¬çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        total_functions = analysis_result.get('total_functions', 0)
        total_files = analysis_result.get('total_files_analyzed', 0)
        
        # å…¨é–¢æ•°æƒ…å ±ã‚’å–å¾—
        all_functions = analysis_result.get('all_functions', [])
        
        # é–¢æ•°ã‚’åˆ†é¡
        if all_functions:
            high_complexity, warning_level = self.stats_calculator.classify_functions(
                all_functions, thresholds
            )
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šhigh_complexity_functionsã®ã¿ã‚’ä½¿ç”¨
            high_complexity = analysis_result.get('high_complexity_functions', [])
            warning_level = []
        
        # å¹³å‡å€¤ã¨æœ€å¤§å€¤ã‚’è¨ˆç®—
        avg_cyclo, avg_cogn, max_cyclo, max_cogn = self.stats_calculator.calculate_averages(
            analysis_result.get('file_analyses', {})
        )
        
        return ComplexityStatistics(
            total_functions=total_functions,
            total_files=total_files,
            avg_cyclomatic=avg_cyclo,
            avg_cognitive=avg_cogn,
            max_cyclomatic=max_cyclo,
            max_cognitive=max_cogn,
            thresholds=thresholds,
            functions_above_threshold={
                'cyclomatic': analysis_result.get('high_complexity_functions_cyclomatic', 0),
                'cognitive': analysis_result.get('high_complexity_functions_cognitive', 0)
            },
            high_complexity_functions=high_complexity,
            warning_level_functions=warning_level
        )
    
    def _build_prompt(self, analysis_result: Dict[str, Any], stats: ComplexityStatistics) -> str:
        """OpenAI APIç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        
        # é«˜è¤‡é›‘åº¦é–¢æ•°ã®è©³ç´°ãƒªã‚¹ãƒˆ
        high_complexity_details = self._format_function_details(
            stats.high_complexity_functions,
            stats.warning_level_functions,
            stats.thresholds
        )
        
        # å…¨é–¢æ•°ã®æ¦‚è¦ã‚’è¿½åŠ 
        all_functions_summary = self._format_all_functions_summary(
            analysis_result.get('all_functions', []),
            stats.thresholds
        )
        
        # é–¾å€¤ã‚’è¶…ãˆã‚‹é–¢æ•°ãŒãªã„å ´åˆã®è¿½åŠ æŒ‡ç¤º
        no_complex_functions_instructions = ""
        if stats.functions_above_threshold['cognitive'] == 0 and stats.functions_above_threshold['cyclomatic'] == 0:
            no_complex_functions_instructions = """
# ç‰¹è¨˜äº‹é …
é–¾å€¤ã‚’è¶…ãˆã‚‹é–¢æ•°ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ä»¥ä¸‹ã®è¦³ç‚¹ã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š
- ç¾åœ¨ã®è‰¯å¥½ãªå®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å…·ä½“çš„ã«è©•ä¾¡
- æœ€ã‚‚è¤‡é›‘åº¦ãŒé«˜ã„é–¢æ•°ï¼ˆé–¾å€¤æœªæº€ã§ã‚‚ï¼‰ã«ã¤ã„ã¦ã€å°†æ¥çš„ãªæ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹ã‹æ¤œè¨
- ãƒãƒ¼ãƒ å…¨ä½“ã§å…±æœ‰ã™ã¹ããƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®æŠ½å‡º
- ä»Šå¾Œã®é–‹ç™ºã§ç¶­æŒã™ã¹ãå“è³ªåŸºæº–ã®ææ¡ˆ
"""
        
        prompt = f"""ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰è¤‡é›‘åº¦è§£æçµæœã«åŸºã¥ã„ã¦ã€GitHub PRã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

# è§£æçµæœã‚µãƒãƒªãƒ¼
- è§£æãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats.total_files}
- ç·é–¢æ•°æ•°: {stats.total_functions}
- å¹³å‡å¾ªç’°çš„è¤‡é›‘åº¦: {stats.avg_cyclomatic:.2f}
- å¹³å‡èªçŸ¥çš„è¤‡é›‘åº¦: {stats.avg_cognitive:.2f}
- æœ€å¤§å¾ªç’°çš„è¤‡é›‘åº¦: {stats.max_cyclomatic}
- æœ€å¤§èªçŸ¥çš„è¤‡é›‘åº¦: {stats.max_cognitive}

# è¨­å®šã•ã‚ŒãŸé–¾å€¤
- å¾ªç’°çš„è¤‡é›‘åº¦ã®é–¾å€¤: {stats.thresholds.cyclomatic} (è­¦å‘Šãƒ¬ãƒ™ãƒ«: {stats.thresholds.cyclomatic_warning})
- èªçŸ¥çš„è¤‡é›‘åº¦ã®é–¾å€¤: {stats.thresholds.cognitive} (è­¦å‘Šãƒ¬ãƒ™ãƒ«: {stats.thresholds.cognitive_warning})

# é–¾å€¤ã‚’è¶…ãˆã‚‹é–¢æ•°
- å¾ªç’°çš„è¤‡é›‘åº¦ãŒé–¾å€¤ã‚’è¶…ãˆã‚‹é–¢æ•°: {stats.functions_above_threshold['cyclomatic']}å€‹
- èªçŸ¥çš„è¤‡é›‘åº¦ãŒé–¾å€¤ã‚’è¶…ãˆã‚‹é–¢æ•°: {stats.functions_above_threshold['cognitive']}å€‹

# é–¢æ•°ã®è©³ç´°æƒ…å ±
{high_complexity_details}

# å…¨é–¢æ•°ã®æ¦‚è¦
{all_functions_summary}
{no_complex_functions_instructions}
# PRæƒ…å ±
- PRç•ªå·: #{analysis_result.get('pr_number', 'N/A')}
- ã‚¿ã‚¤ãƒˆãƒ«: {analysis_result.get('pr_title', 'N/A')}

ä»¥ä¸‹ã®å½¢å¼ã§Markdownã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

1. **è§£æã‚µãƒãƒªãƒ¼**: å…¨ä½“çš„ãªè©•ä¾¡ã‚’2-3æ–‡ã§ç°¡æ½”ã«ï¼ˆå¹³å‡å€¤ã¨æœ€å¤§å€¤ã«åŸºã¥ã„ã¦ï¼‰
   - å¹³å‡è¤‡é›‘åº¦ãŒä½ã„å ´åˆã¯ã€ãã®è‰¯å¥½ãªçŠ¶æ…‹ã‚’è©•ä¾¡
   - æœ€å¤§è¤‡é›‘åº¦ã‚‚é–¾å€¤å†…ã®å ´åˆã¯ã€ãã‚Œã‚‚æ˜è¨˜

2. **é‡è¦ãªç™ºè¦‹äº‹é …**:
   - ğŸš¨ **å„ªå…ˆçš„ã«å¯¾å¿œãŒå¿…è¦ãªé–¢æ•°**: èªçŸ¥çš„è¤‡é›‘åº¦ãŒé–¾å€¤ã‚’è¶…ãˆã‚‹é–¢æ•°ï¼ˆ{stats.thresholds.cognitive}ä»¥ä¸Šï¼‰ã‚’å…·ä½“çš„ã«ãƒªã‚¹ãƒˆã—ã€ãªãœè¤‡é›‘ãªã®ã‹ã€ã©ã†ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã™ã¹ãã‹ææ¡ˆ
   - âš ï¸ **æ³¨æ„ãŒå¿…è¦ãªé ˜åŸŸ**: è­¦å‘Šãƒ¬ãƒ™ãƒ«ï¼ˆèªçŸ¥çš„: {stats.thresholds.cognitive_warning}-{stats.thresholds.cognitive-1}ã€å¾ªç’°çš„: {stats.thresholds.cyclomatic_warning}-{stats.thresholds.cyclomatic-1}ï¼‰ã®é–¢æ•°ã‚’å…·ä½“çš„ã«ãƒªã‚¹ãƒˆ
   - âœ… **è‰¯å¥½ãªå®Ÿè£…**: ç‰¹ã«è¤‡é›‘åº¦ãŒä½ãã€è‰¯ã„å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ãªã£ã¦ã„ã‚‹é–¢æ•°ã‚’2-3å€‹å…·ä½“çš„ã«æŒ™ã’ã¦è©•ä¾¡

3. **å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ**: 
   - é«˜è¤‡é›‘åº¦é–¢æ•°ãŒã‚ã‚‹å ´åˆï¼š
     * é–¢æ•°ã®åˆ†å‰²ï¼ˆå˜ä¸€è²¬ä»»ã®åŸå‰‡ï¼‰
     * æ¡ä»¶åˆ†å²ã®ç°¡ç•¥åŒ–
     * ãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã®å‰Šæ¸›
     * æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ã®æ´»ç”¨
   - é«˜è¤‡é›‘åº¦é–¢æ•°ãŒãªã„å ´åˆï¼š
     * ç¾åœ¨ã®è‰¯å¥½ãªå®Ÿè£…ã‚’ç¶­æŒã™ã‚‹ãŸã‚ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
     * ã•ã‚‰ãªã‚‹æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹é–¢æ•°ã¸ã®ææ¡ˆï¼ˆã‚ã‚Œã°ï¼‰
     * ãƒãƒ¼ãƒ å…¨ä½“ã§å…±æœ‰ã™ã¹ãã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„

4. **ãƒ¡ãƒˆãƒªã‚¯ã‚¹è©³ç´°**: ä¸»è¦ãªæ•°å€¤ã‚’è¡¨å½¢å¼ã§ã¾ã¨ã‚ã‚‹
   | ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | å€¤ | è©•ä¾¡ |
   |----------|-----|------|
   | å¹³å‡èªçŸ¥çš„è¤‡é›‘åº¦ | X.XX | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |
   | å¹³å‡å¾ªç’°çš„è¤‡é›‘åº¦ | X.XX | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |
   | æœ€å¤§èªçŸ¥çš„è¤‡é›‘åº¦ | XX | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |
   | æœ€å¤§å¾ªç’°çš„è¤‡é›‘åº¦ | XX | ğŸŸ¢/ğŸŸ¡/ğŸ”´ |

5. **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: 
   - é«˜è¤‡é›‘åº¦é–¢æ•°ãŒã‚ã‚‹å ´åˆï¼šå„ªå…ˆé †ä½ä»˜ã‘ã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³é …ç›®
   - é«˜è¤‡é›‘åº¦é–¢æ•°ãŒãªã„å ´åˆï¼šå“è³ªã‚’ç¶­æŒã™ã‚‹ãŸã‚ã®æ¨å¥¨äº‹é …

é‡è¦ãªæ³¨æ„äº‹é …:
- å¿…ãšå…·ä½“çš„ãªé–¢æ•°åã¨è¤‡é›‘åº¦ã®æ•°å€¤ã‚’å«ã‚ã¦ãã ã•ã„
- è­¦å‘Šãƒ¬ãƒ™ãƒ«ã®é–¢æ•°ã‚‚å…·ä½“çš„ãªåå‰ã¨æ•°å€¤ã‚’å«ã‚ã¦è¨˜è¼‰ã—ã¦ãã ã•ã„
- èªçŸ¥çš„è¤‡é›‘åº¦ã‚’å¾ªç’°çš„è¤‡é›‘åº¦ã‚ˆã‚Šå„ªå…ˆã—ã¦èª¬æ˜ã—ã¦ãã ã•ã„ï¼ˆèªçŸ¥çš„è¤‡é›‘åº¦ã®æ–¹ãŒå®Ÿéš›ã®ç†è§£ã—ã‚„ã™ã•ã‚’è¡¨ã™ãŸã‚ï¼‰
- æ”¹å–„ææ¡ˆã¯å®Ÿè£…å¯èƒ½ã§å…·ä½“çš„ãªã‚‚ã®ã«ã—ã¦ãã ã•ã„
- é–¾å€¤ã‚’è¶…ãˆã‚‹é–¢æ•°ãŒãªã„å ´åˆã§ã‚‚ã€å»ºè¨­çš„ã§æœ‰ç”¨ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„
- ãƒˆãƒ¼ãƒ³ã¯å»ºè¨­çš„ã§å”åŠ›çš„ã«ä¿ã£ã¦ãã ã•ã„
- å‡ºåŠ›ã«ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯è¨˜å·ï¼ˆ```ï¼‰ã‚’å«ã‚ãªã„ã§ãã ã•ã„
- ç´”ç²‹ãªMarkdownå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆ```markdownãªã©ã®ã‚¿ã‚°ã¯ä¸è¦ï¼‰"""
        
        return prompt
    
    def _format_function_details(self, high_complexity_functions: List[Dict], 
                               warning_functions: List[Dict],
                               thresholds: ComplexityThresholds) -> str:
        """é–¢æ•°ã®è©³ç´°æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰"""
        if not high_complexity_functions and not warning_functions:
            return "## é–¾å€¤ã‚’è¶…ãˆã‚‹é–¢æ•°ãƒ»è­¦å‘Šãƒ¬ãƒ™ãƒ«ã®é–¢æ•°ã¯ã‚ã‚Šã¾ã›ã‚“"
        
        result = []
        
        # é«˜è¤‡é›‘åº¦é–¢æ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        if high_complexity_functions:
            result.extend(self._format_high_complexity_functions(high_complexity_functions, thresholds))
        
        # è­¦å‘Šãƒ¬ãƒ™ãƒ«é–¢æ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        if warning_functions:
            result.extend(self._format_warning_level_functions(warning_functions, thresholds))
        
        return "\n".join(result)
    
    def _format_all_functions_summary(self, all_functions: List[Dict], 
                                    thresholds: ComplexityThresholds) -> str:
        """å…¨é–¢æ•°ã®æ¦‚è¦ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not all_functions:
            return "é–¢æ•°ã®è©³ç´°æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        result = [f"ç·é–¢æ•°æ•°: {len(all_functions)}å€‹"]
        
        # è¤‡é›‘åº¦ã®åˆ†å¸ƒã‚’è¿½åŠ 
        result.extend(self._format_complexity_distribution(all_functions))
        
        # æœ€ã‚‚è¤‡é›‘ãªé–¢æ•°ã‚’è¿½åŠ 
        result.extend(self._format_most_complex_functions(all_functions))
        
        # æœ€ã‚‚å˜ç´”ãªé–¢æ•°ã‚’è¿½åŠ 
        result.extend(self._format_simplest_functions(all_functions))
        
        return "\n".join(result)
    
    def _format_complexity_distribution(self, all_functions: List[Dict]) -> List[str]:
        """è¤‡é›‘åº¦ã®åˆ†å¸ƒã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        distribution = self._calculate_complexity_distribution(all_functions)
        
        result = ["\nè¤‡é›‘åº¦ã®åˆ†å¸ƒ:"]
        for level, count in distribution.items():
            if count > 0:
                percentage = (count / len(all_functions)) * 100
                result.append(f"- {level}: {count}å€‹ ({percentage:.1f}%)")
        
        return result
    
    def _calculate_complexity_distribution(self, all_functions: List[Dict]) -> Dict[str, int]:
        """è¤‡é›‘åº¦ã®åˆ†å¸ƒã‚’è¨ˆç®—"""
        distribution = {
            'ä½ï¼ˆèªçŸ¥çš„ < 5ï¼‰': 0,
            'ä¸­ï¼ˆèªçŸ¥çš„ 5-9ï¼‰': 0,
            'é«˜ï¼ˆèªçŸ¥çš„ 10-14ï¼‰': 0,
            'è­¦å‘Šï¼ˆèªçŸ¥çš„ 15-19ï¼‰': 0,
            'å±é™ºï¼ˆèªçŸ¥çš„ 20+ï¼‰': 0
        }
        
        for func in all_functions:
            cognitive = func.get('cognitive', 0)
            if cognitive < 5:
                distribution['ä½ï¼ˆèªçŸ¥çš„ < 5ï¼‰'] += 1
            elif cognitive < 10:
                distribution['ä¸­ï¼ˆèªçŸ¥çš„ 5-9ï¼‰'] += 1
            elif cognitive < 15:
                distribution['é«˜ï¼ˆèªçŸ¥çš„ 10-14ï¼‰'] += 1
            elif cognitive < 20:
                distribution['è­¦å‘Šï¼ˆèªçŸ¥çš„ 15-19ï¼‰'] += 1
            else:
                distribution['å±é™ºï¼ˆèªçŸ¥çš„ 20+ï¼‰'] += 1
        
        return distribution
    
    def _format_most_complex_functions(self, all_functions: List[Dict]) -> List[str]:
        """æœ€ã‚‚è¤‡é›‘ãªé–¢æ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        # è¤‡é›‘åº¦ã§ã‚½ãƒ¼ãƒˆï¼ˆèªçŸ¥çš„è¤‡é›‘åº¦å„ªå…ˆï¼‰
        sorted_functions = sorted(all_functions, 
                                key=lambda x: (x.get('cognitive', 0), x.get('cyclomatic', 0)), 
                                reverse=True)
        
        result = ["\næœ€ã‚‚è¤‡é›‘ãªé–¢æ•°ï¼ˆä¸Šä½5å€‹ï¼‰:"]
        for i, func in enumerate(sorted_functions[:5], 1):
            result.append(self._format_function_summary(i, func))
        
        return result
    
    def _format_simplest_functions(self, all_functions: List[Dict]) -> List[str]:
        """æœ€ã‚‚å˜ç´”ãªé–¢æ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        # å˜ç´”ãªé–¢æ•°ã‚’ã‚½ãƒ¼ãƒˆ
        simple_functions = sorted(all_functions, 
                                key=lambda x: (x.get('cognitive', 0), x.get('cyclomatic', 0)))
        
        # éå¸¸ã«å˜ç´”ãªé–¢æ•°ï¼ˆèªçŸ¥çš„è¤‡é›‘åº¦ <= 3ï¼‰ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        very_simple_functions = [func for func in simple_functions if func.get('cognitive', 0) <= 3]
        
        if len(very_simple_functions) >= 3:
            result = ["\næœ€ã‚‚å˜ç´”ã§è‰¯å¥½ãªå®Ÿè£…ï¼ˆä¾‹ï¼‰:"]
            for i, func in enumerate(very_simple_functions[:3], 1):
                result.append(self._format_function_summary(i, func))
            return result
        
        return []
    
    def _format_function_summary(self, index: int, func: Dict[str, Any]) -> str:
        """å€‹åˆ¥ã®é–¢æ•°ã‚µãƒãƒªãƒ¼ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        name = func.get('name', 'Unknown')
        cognitive = func.get('cognitive', 0)
        cyclomatic = func.get('cyclomatic', 0)
        return f"{index}. `{name}` (èªçŸ¥çš„: {cognitive}, å¾ªç’°çš„: {cyclomatic})"
    
    def _format_high_complexity_functions(self, functions: List[Dict], 
                                        thresholds: ComplexityThresholds) -> List[str]:
        """é«˜è¤‡é›‘åº¦é–¢æ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        result = ["## ğŸ”´ é–¾å€¤ã‚’è¶…ãˆã‚‹é–¢æ•°ï¼ˆå„ªå…ˆçš„ãªå¯¾å¿œãŒå¿…è¦ï¼‰:"]
        
        sorted_functions = sorted(functions, key=lambda x: x.get('cognitive', 0), reverse=True)
        
        for i, func in enumerate(sorted_functions[:10], 1):
            result.extend(self.comment_formatter.format_function_header(func, i))
            result.extend(self.comment_formatter.format_complexity_metrics(func, thresholds))
        
        return result
    
    def _format_warning_level_functions(self, functions: List[Dict], 
                                      thresholds: ComplexityThresholds) -> List[str]:
        """è­¦å‘Šãƒ¬ãƒ™ãƒ«é–¢æ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        result = ["\n## ğŸŸ¡ è­¦å‘Šãƒ¬ãƒ™ãƒ«ã®é–¢æ•°ï¼ˆå°†æ¥çš„ãªæ”¹å–„ã‚’æ¤œè¨ï¼‰:"]
        
        sorted_functions = sorted(functions, key=lambda x: x.get('cognitive', 0), reverse=True)
        
        for i, func in enumerate(sorted_functions[:10], 1):
            result.extend(self.comment_formatter.format_function_header(func, i))
            result.extend(self.comment_formatter.format_warning_metrics(func, thresholds))
        
        return result
    
    def _generate_fallback_comment(self, analysis_result: Dict[str, Any], 
                                  stats: ComplexityStatistics) -> str:
        """APIã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰"""
        comment = []
        
        # ã‚µãƒãƒªãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        comment.extend(self.comment_formatter.create_summary_section(stats, analysis_result))
        
        # é–¾å€¤ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        comment.extend(self.comment_formatter.create_threshold_section(stats.thresholds))
        
        # é‡è¦ãªç™ºè¦‹äº‹é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        comment.extend(self._create_findings_section(stats))
        
        # æ¨å¥¨äº‹é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        has_complex = (stats.functions_above_threshold['cognitive'] > 0 or 
                      stats.functions_above_threshold['cyclomatic'] > 0)
        comment.extend(self.comment_formatter.create_recommendations_section(has_complex))
        
        return "\n".join(comment)
    
    def _create_findings_section(self, stats: ComplexityStatistics) -> List[str]:
        """ç™ºè¦‹äº‹é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        findings = ["## ğŸ¯ é‡è¦ãªç™ºè¦‹äº‹é …"]
        
        # é«˜è¤‡é›‘åº¦é–¢æ•°
        if stats.high_complexity_functions:
            findings.extend(self._format_critical_functions(stats))
        
        # è­¦å‘Šãƒ¬ãƒ™ãƒ«é–¢æ•°
        if stats.warning_level_functions:
            findings.extend(self._format_warning_functions(stats))
        
        # å…¨ã¦è‰¯å¥½ãªå ´åˆ
        if not stats.high_complexity_functions and not stats.warning_level_functions:
            findings.extend([
                "## âœ… è‰¯å¥½ãªå®Ÿè£…",
                "ã™ã¹ã¦ã®é–¢æ•°ã®è¤‡é›‘åº¦ãŒé©åˆ‡ã«ç®¡ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚",
                ""
            ])
        
        return findings
    
    def _format_critical_functions(self, stats: ComplexityStatistics) -> List[str]:
        """é‡è¦åº¦ã®é«˜ã„é–¢æ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        result = ["\n### ğŸš¨ å„ªå…ˆçš„ã«å¯¾å¿œãŒå¿…è¦ãªé–¢æ•°"]
        
        sorted_funcs = sorted(stats.high_complexity_functions, 
                            key=lambda x: x.get('cognitive', 0), reverse=True)
        
        for i, func in enumerate(sorted_funcs[:5], 1):
            result.extend([
                f"\n**{i}. {func.get('name', 'Unknown')}**",
                f"- èªçŸ¥çš„è¤‡é›‘åº¦: {func.get('cognitive', 0)} (é–¾å€¤: {stats.thresholds.cognitive})",
                f"- å¾ªç’°çš„è¤‡é›‘åº¦: {func.get('cyclomatic', 0)} (é–¾å€¤: {stats.thresholds.cyclomatic})",
                f"- ãƒ•ã‚¡ã‚¤ãƒ«: `{func.get('file', 'Unknown')}`",
                f"- æ”¹å–„ææ¡ˆ: ã“ã®é–¢æ•°ã¯è¤‡é›‘åº¦ãŒé«˜ã„ãŸã‚ã€æ©Ÿèƒ½ã”ã¨ã«å°ã•ãªé–¢æ•°ã«åˆ†å‰²ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
            ])
        
        return result
    
    def _format_warning_functions(self, stats: ComplexityStatistics) -> List[str]:
        """è­¦å‘Šãƒ¬ãƒ™ãƒ«ã®é–¢æ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        result = ["\n### âš ï¸ æ³¨æ„ãŒå¿…è¦ãªé ˜åŸŸ"]
        
        for i, func in enumerate(stats.warning_level_functions[:3], 1):
            result.append(
                f"{i}. `{func.get('name', 'Unknown')}` - "
                f"èªçŸ¥çš„: {func.get('cognitive', 0)}, "
                f"å¾ªç’°çš„: {func.get('cyclomatic', 0)}"
            )
        
        return result


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='PRè¤‡é›‘åº¦è§£æã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ')
    parser.add_argument('--analysis-result', required=True, help='è§£æçµæœJSONãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--output', required=True, help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--debug', action='store_true', help='ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–')
    parser.add_argument('--save-prompt', action='store_true', help='ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜')
    parser.add_argument('--show-prompt', action='store_true', help='ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤º')
    
    args = parser.parse_args()
    
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®è¨­å®š
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # è§£æçµæœã‚’èª­ã¿è¾¼ã¿
    logger.info(f"Loading analysis result from {args.analysis_result}")
    with open(args.analysis_result, 'r', encoding='utf-8') as f:
        analysis_result = json.load(f)
    
    # ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
    generator = PRComplexityCommentGenerator(
        debug_mode=args.debug,
        save_prompt=args.save_prompt
    )
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if args.show_prompt:
        generator.show_prompt = True
    
    comment = generator.generate_comment(analysis_result)
    
    # çµæœã‚’ä¿å­˜
    result = {
        'comment': comment,
        'generated_at': datetime.now().isoformat(),
        'analysis_summary': {
            'total_files_analyzed': analysis_result.get('total_files_analyzed', 0),
            'total_functions': analysis_result.get('total_functions', 0),
            'high_complexity_cyclomatic': analysis_result.get('high_complexity_functions_cyclomatic', 0),
            'high_complexity_cognitive': analysis_result.get('high_complexity_functions_cognitive', 0)
        },
        'generation_metadata': {
            'model': generator.config.model,
            'temperature': generator.config.temperature,
            'max_tokens': generator.config.max_tokens
        }
    }
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«å«ã‚ã‚‹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if args.save_prompt or args.show_prompt or args.debug:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å†ç”Ÿæˆã—ã¦çµæœã«å«ã‚ã‚‹
        stats = generator._prepare_statistics(analysis_result)
        prompt = generator._build_prompt(analysis_result, stats)
        result['generation_metadata']['prompt'] = prompt
        result['generation_metadata']['prompt_length'] = len(prompt)
        result['generation_metadata']['estimated_prompt_tokens'] = len(prompt) // 4
    
    logger.info(f"Saving comment to {args.output}")
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    # ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    print(f"\nComment generated successfully!")
    print(f"- Model used: {generator.config.model}")
    print(f"- Files analyzed: {result['analysis_summary']['total_files_analyzed']}")
    print(f"- Total functions: {result['analysis_summary']['total_functions']}")
    print(f"- High complexity functions (cyclomatic): {result['analysis_summary']['high_complexity_cyclomatic']}")
    print(f"- High complexity functions (cognitive): {result['analysis_summary']['high_complexity_cognitive']}")


if __name__ == '__main__':
    main()
