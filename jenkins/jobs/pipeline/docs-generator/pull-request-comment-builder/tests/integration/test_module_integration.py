"""
çµ±åˆãƒ†ã‚¹ãƒˆ: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“é€£æº

ãƒ†ã‚¹ãƒˆå¯¾è±¡:
- Statistics â†” TokenEstimator é€£æº
- Formatter â†” Models é€£æº
- è¤‡æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å”èª¿å‹•ä½œ
"""

import pytest
import logging
import tempfile
import os
from pr_comment_generator.models import PRInfo, FileChange
from pr_comment_generator.statistics import PRCommentStatistics
from pr_comment_generator.formatter import CommentFormatter
from pr_comment_generator.token_estimator import TokenEstimator
from pr_comment_generator.prompt_manager import PromptTemplateManager


class TestStatisticsTokenEstimatorIntegration:
    """Statistics â†” TokenEstimator é€£æºãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def logger(self):
        """ãƒ­ã‚¬ãƒ¼ã‚’ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã¨ã—ã¦æä¾›"""
        return logging.getLogger("test")

    @pytest.fixture
    def token_estimator(self, logger):
        """TokenEstimatorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æä¾›"""
        return TokenEstimator(logger=logger)

    @pytest.fixture
    def statistics(self, token_estimator, logger):
        """PRCommentStatisticsã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æä¾›"""
        return PRCommentStatistics(token_estimator=token_estimator, logger=logger)

    def test_ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºè¨ˆç®—ã¨ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šã®é€£æº(self, statistics, token_estimator):
        """
        Given: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒªã‚¹ãƒˆãŒã‚ã‚‹
        When: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã—ã€ãã®ãƒãƒ£ãƒ³ã‚¯ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®šã™ã‚‹
        Then: ãƒãƒ£ãƒ³ã‚¯ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒmax_tokensä»¥ä¸‹ã§ã‚ã‚‹
        """
        # Given
        files = [
            FileChange(
                filename=f"file{i}.py",
                status="modified",
                additions=10,
                deletions=5,
                changes=15,
                patch="test content " * 100
            )
            for i in range(10)
        ]
        max_tokens = 3000

        # When
        chunk_size = statistics.calculate_optimal_chunk_size(files, max_tokens)
        chunks = [files[i:i + chunk_size] for i in range(0, len(files), chunk_size)]

        # Then
        for chunk in chunks:
            chunk_tokens = statistics.estimate_chunk_tokens(chunk)
            # å„ãƒãƒ£ãƒ³ã‚¯ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒmax_tokensã‚’å¤§ããè¶…ãˆãªã„ã“ã¨ã‚’ç¢ºèª
            # (å®Œå…¨ãªä¿è¨¼ã¯ãªã„ãŒã€å¤§å¹…ãªè¶…éãŒãªã„ã“ã¨ã‚’ç¢ºèª)
            assert chunk_tokens < max_tokens * 2

    def test_çµ±è¨ˆè¨ˆç®—ã¨ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§(self, statistics):
        """
        Given: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒªã‚¹ãƒˆãŒã‚ã‚‹
        When: çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã™ã‚‹
        Then: çµ±è¨ˆæƒ…å ±ãŒãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒ‡ãƒ¼ã‚¿ã¨æ•´åˆã™ã‚‹
        """
        # Given
        files = [
            FileChange(filename="file1.py", status="modified", additions=10, deletions=5, changes=15, patch=None),
            FileChange(filename="file2.py", status="added", additions=50, deletions=0, changes=50, patch=None),
            FileChange(filename="file3.py", status="modified", additions=20, deletions=10, changes=30, patch=None),
        ]

        # When
        stats = statistics.calculate_statistics(files)

        # Then
        # æ‰‹å‹•è¨ˆç®—ã¨ä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert stats['file_count'] == len(files)
        assert stats['total_additions'] == sum(f.additions for f in files)
        assert stats['total_deletions'] == sum(f.deletions for f in files)
        assert stats['total_changes'] == sum(f.changes for f in files)


class TestFormatterModelsIntegration:
    """Formatter â†” Models é€£æºãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def formatter(self):
        """CommentFormatterã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æä¾›"""
        logger = logging.getLogger("test")
        return CommentFormatter(logger=logger)

    def test_ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨FileChangeãƒ¢ãƒ‡ãƒ«ã®é€£æº(self, formatter):
        """
        Given: FileChangeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆãŒã‚ã‚‹
        When: format_file_list()ã‚’å‘¼ã³å‡ºã™
        Then: FileChangeã®å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæ­£ã—ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«åæ˜ ã•ã‚Œã‚‹
        """
        # Given
        files = [
            FileChange(
                filename="src/main.py",
                status="modified",
                additions=15,
                deletions=8,
                changes=23,
                patch=None
            ),
            FileChange(
                filename="tests/test_new.py",
                status="added",
                additions=100,
                deletions=0,
                changes=100,
                patch=None
            ),
        ]

        # When
        formatted = formatter.format_file_list(files)

        # Then
        # ãƒ•ã‚¡ã‚¤ãƒ«åãŒå«ã¾ã‚Œã‚‹
        assert "src/main.py" in formatted
        assert "tests/test_new.py" in formatted

        # è¿½åŠ ãƒ»å‰Šé™¤è¡Œæ•°ãŒå«ã¾ã‚Œã‚‹
        assert "+15" in formatted
        assert "-8" in formatted
        assert "+100" in formatted
        assert "-0" in formatted

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¿œã˜ãŸçµµæ–‡å­—ãŒå«ã¾ã‚Œã‚‹
        assert "ğŸ“" in formatted  # modified
        assert "âœ¨" in formatted  # added

    def test_æœ€çµ‚ã‚³ãƒ¡ãƒ³ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®é€£æº(self, formatter):
        """
        Given: ã‚µãƒãƒªãƒ¼ã€ãƒãƒ£ãƒ³ã‚¯åˆ†æã€FileChangeãƒªã‚¹ãƒˆãŒã‚ã‚‹
        When: format_final_comment()ã‚’å‘¼ã³å‡ºã™
        Then: ã™ã¹ã¦ã®æƒ…å ±ãŒçµ±åˆã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆãŒç”Ÿæˆã•ã‚Œã‚‹
        """
        # Given
        summary = "This PR refactors the authentication module."
        chunk_analyses = [
            "Chunk 1: Refactored login logic",
            "Chunk 2: Added new authentication tests"
        ]
        files = [
            FileChange(filename="auth/login.py", status="modified", additions=50, deletions=30, changes=80, patch=None),
            FileChange(filename="tests/test_auth.py", status="added", additions=150, deletions=0, changes=150, patch=None),
        ]
        skipped_files = [
            FileChange(filename="large_file.txt", status="modified", additions=0, deletions=0, changes=2000, patch=None)
        ]

        # When
        comment = formatter.format_final_comment(summary, chunk_analyses, files, skipped_files)

        # Then
        # ã‚µãƒãƒªãƒ¼ãŒå«ã¾ã‚Œã‚‹
        assert summary in comment

        # ãƒãƒ£ãƒ³ã‚¯åˆ†æãŒå«ã¾ã‚Œã‚‹
        assert "Chunk 1" in comment
        assert "Chunk 2" in comment

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆãŒå«ã¾ã‚Œã‚‹
        assert "auth/login.py" in comment
        assert "tests/test_auth.py" in comment

        # ã‚¹ã‚­ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ãŒå«ã¾ã‚Œã‚‹
        assert "large_file.txt" in comment
        assert "ã‚¹ã‚­ãƒƒãƒ—" in comment


class TestMultiModuleIntegration:
    """è¤‡æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å”èª¿å‹•ä½œãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def logger(self):
        """ãƒ­ã‚¬ãƒ¼ã‚’ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã¨ã—ã¦æä¾›"""
        return logging.getLogger("test")

    @pytest.fixture
    def temp_template_dir(self):
        """ä¸€æ™‚ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        with tempfile.TemporaryDirectory() as tmpdir:
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            base_template = os.path.join(tmpdir, "base_template.md")
            with open(base_template, "w", encoding="utf-8") as f:
                f.write("PR #{pr_number}: {title}")

            chunk_template = os.path.join(tmpdir, "chunk_analysis_extension.md")
            with open(chunk_template, "w", encoding="utf-8") as f:
                f.write("Analyze chunk {chunk_index}")

            summary_template = os.path.join(tmpdir, "summary_extension.md")
            with open(summary_template, "w", encoding="utf-8") as f:
                f.write("Summary template")

            yield tmpdir

    def test_çµ±è¨ˆè¨ˆç®—ã‹ã‚‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¾ã§ã®å…¨ä½“ãƒ•ãƒ­ãƒ¼(self, logger, temp_template_dir):
        """
        Given: PRæƒ…å ±ã¨ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒªã‚¹ãƒˆãŒã‚ã‚‹
        When: çµ±è¨ˆè¨ˆç®—â†’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²â†’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ä¸€é€£ã®å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
        Then: æœ€çµ‚çš„ãªã‚³ãƒ¡ãƒ³ãƒˆãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã‚‹
        """
        # Given
        pr_info = PRInfo.from_json({
            "title": "Add authentication feature",
            "number": 123,
            "body": "This PR adds authentication",
            "user": {"login": "developer"},
            "base": {"ref": "main", "sha": "abc123"},
            "head": {"ref": "feature/auth", "sha": "def456"}
        })

        files = [
            FileChange(
                filename=f"module{i}.py",
                status="modified",
                additions=20,
                deletions=10,
                changes=30,
                patch="diff content " * 50
            )
            for i in range(5)
        ]

        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        token_estimator = TokenEstimator(logger=logger)
        statistics = PRCommentStatistics(token_estimator=token_estimator, logger=logger)
        formatter = CommentFormatter(logger=logger)
        prompt_manager = PromptTemplateManager(template_dir=temp_template_dir)

        # When
        # Step 1: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        chunk_size = statistics.calculate_optimal_chunk_size(files, max_tokens=3000)

        # Step 2: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
        chunks = [files[i:i + chunk_size] for i in range(0, len(files), chunk_size)]

        # Step 3: çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
        stats = statistics.calculate_statistics(files)

        # Step 4: ãƒãƒ£ãƒ³ã‚¯åˆ†æï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
        chunk_analyses = [f"Analysis for chunk {i+1}" for i in range(len(chunks))]

        # Step 5: æœ€çµ‚ã‚³ãƒ¡ãƒ³ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        summary = f"PR #{pr_info.number} by {pr_info.author}: {pr_info.title}"
        comment = formatter.format_final_comment(summary, chunk_analyses, files)

        # Then
        # PRæƒ…å ±ãŒå«ã¾ã‚Œã‚‹
        assert str(pr_info.number) in comment
        assert pr_info.title in comment

        # ãƒãƒ£ãƒ³ã‚¯åˆ†æãŒå«ã¾ã‚Œã‚‹
        for i in range(len(chunks)):
            assert f"Analysis for chunk {i+1}" in comment

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆãŒå«ã¾ã‚Œã‚‹
        for file in files:
            assert file.filename in comment

        # çµ±è¨ˆæƒ…å ±ãŒæ­£ã—ã„
        assert stats['file_count'] == len(files)
        assert stats['total_changes'] == sum(f.changes for f in files)

    def test_ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨å¾©æ—§(self, logger):
        """
        Given: ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆãŒã‚ã‚‹
        When: çµ±è¨ˆè¨ˆç®—ã‚’å®Ÿè¡Œã™ã‚‹
        Then: ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã€å‡¦ç†ãŒç¶™ç¶šã•ã‚Œã‚‹
        """
        # Given
        files = [
            FileChange(filename="valid.py", status="modified", additions=10, deletions=5, changes=15, patch="content"),
            FileChange(filename="no_patch.py", status="modified", additions=10, deletions=5, changes=15, patch=None),
            FileChange(filename="valid2.py", status="added", additions=50, deletions=0, changes=50, patch="content"),
        ]

        token_estimator = TokenEstimator(logger=logger)
        statistics = PRCommentStatistics(token_estimator=token_estimator, logger=logger)

        # When
        chunk_size = statistics.calculate_optimal_chunk_size(files)
        stats = statistics.calculate_statistics(files)

        # Then
        # ã‚¨ãƒ©ãƒ¼ãªãå‡¦ç†ãŒå®Œäº†
        assert chunk_size >= 1
        assert stats['file_count'] == len(files)
