# jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/src/pr_comment_generator/formatter.py
"""
ã‚³ãƒ¡ãƒ³ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€PRã‚³ãƒ¡ãƒ³ãƒˆã®Markdownãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

ä¸»è¦ãªã‚¯ãƒ©ã‚¹:
- CommentFormatter: ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†
"""

import os
import re
import logging
from typing import List, Dict, Any

from .models import FileChange


class CommentFormatter:
    """PRã‚³ãƒ¡ãƒ³ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, logger: logging.Logger = None):
        """åˆæœŸåŒ–

        Args:
            logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.logger = logger or logging.getLogger(__name__)

    def clean_markdown_format(self, text: str) -> str:
        """Markdownãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹

        Args:
            text: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            str: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãƒãƒ¼ã‚«ãƒ¼ã®å‰Šé™¤
        text = re.sub(r'^```markdown\s*\n', '', text)  # å…ˆé ­ã®```markdownã‚’å‰Šé™¤
        text = re.sub(r'\n```\s*$', '', text)          # æœ«å°¾ã®```ã‚’å‰Šé™¤

        # ä½™åˆ†ãªç©ºè¡Œã‚’å‰Šé™¤ï¼ˆ3è¡Œä»¥ä¸Šã®ç©ºè¡Œã‚’2è¡Œã«ï¼‰
        text = re.sub(r'\n{3,}', '\n\n', text)

        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®å‰å¾Œã®ç©ºè¡Œã‚’èª¿æ•´
        text = re.sub(r'\n+```', '\n```', text)
        text = re.sub(r'```\n+', '```\n', text)

        # æœ«å°¾ã®ç©ºç™½ã‚’å‰Šé™¤
        text = '\n'.join(line.rstrip() for line in text.split('\n'))

        return text.strip()

    def format_chunk_analyses(self, analyses: List[str]) -> str:
        """ãƒãƒ£ãƒ³ã‚¯åˆ†æçµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹

        Args:
            analyses: ãƒãƒ£ãƒ³ã‚¯åˆ†æçµæœã®ãƒªã‚¹ãƒˆ

        Returns:
            str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸåˆ†æçµæœ
        """
        if not analyses:
            return ""

        formatted_parts = []
        for i, analysis in enumerate(analyses, 1):
            # "...ä¸­ç•¥..."ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if analysis == '...ä¸­ç•¥...':
                formatted_parts.append(analysis)
                continue

            header = f"=== ãƒãƒ£ãƒ³ã‚¯ {i} ===\n"
            formatted_parts.append(header + analysis)

        result = "\n\n".join(formatted_parts)
        return self.clean_markdown_format(result)

    def format_file_list(self, files: List[FileChange]) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹

        Args:
            files: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒªã‚¹ãƒˆ

        Returns:
            str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
        """
        if not files:
            return "å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

        lines = ["## å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«\n"]
        for file in files:
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¿œã˜ãŸçµµæ–‡å­—ã‚’é¸æŠ
            status_emoji = {
                'added': 'âœ¨',
                'modified': 'ğŸ“',
                'removed': 'ğŸ—‘ï¸',
                'renamed': 'ğŸ“›'
            }.get(file.status, 'ğŸ“„')

            line = f"- {status_emoji} `{file.filename}` (+{file.additions} -{file.deletions})"
            lines.append(line)

        return "\n".join(lines)

    def format_skipped_files_info(
        self,
        skipped_files: List[FileChange],
        reason: str = "ã‚µã‚¤ã‚ºåˆ¶é™"
    ) -> str:
        """ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹

        Args:
            skipped_files: ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
            reason: ã‚¹ã‚­ãƒƒãƒ—ç†ç”±

        Returns:
            str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæƒ…å ±
        """
        if not skipped_files:
            return ""

        lines = [
            f"\n## âš ï¸ ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ« ({reason})\n",
            f"ä»¥ä¸‹ã®{len(skipped_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯{reason}ã«ã‚ˆã‚Šã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸï¼š\n"
        ]

        for file in skipped_files:
            lines.append(
                f"- `{file.filename}` ({file.additions} è¡Œè¿½åŠ , "
                f"{file.deletions} è¡Œå‰Šé™¤, åˆè¨ˆ {file.changes} è¡Œå¤‰æ›´)"
            )

        return "\n".join(lines)

    def rebuild_file_section(self, comment: str, original_file_paths: List[str]) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å†æ§‹ç¯‰ã™ã‚‹ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ­£è¦åŒ–ï¼‰

        ã‚³ãƒ¡ãƒ³ãƒˆå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ­£è¦åŒ–ã—ã€é‡è¤‡ã‚’å‰Šé™¤ã—ã¾ã™ã€‚

        Args:
            comment: ã‚³ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
            original_file_paths: å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ

        Returns:
            str: å†æ§‹ç¯‰ã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆ
        """
        # ä¿®æ­£ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢
        file_section_pattern = r'## ä¿®æ­£ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«.*?(?=##|$)'
        file_section_match = re.search(file_section_pattern, comment, re.DOTALL)

        if not file_section_match:
            self.logger.warning("File section not found in comment")
            return comment

        file_section = file_section_match.group(0)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŠ½å‡ºï¼ˆãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆã§å›²ã¾ã‚ŒãŸãƒ‘ã‚¹ï¼‰
        file_paths = re.findall(r'`([^`]+)`', file_section)

        # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‘ã‚¹ã®ã‚»ãƒƒãƒˆï¼ˆé‡è¤‡å‰Šé™¤ï¼‰
        normalized_paths = set()
        path_mapping = {}  # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‘ã‚¹ -> å…ƒã®ãƒ‘ã‚¹

        for path in file_paths:
            # ãƒ‘ã‚¹ã‚’æ­£è¦åŒ–ï¼ˆæœ«å°¾ã®ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚„ä½™åˆ†ãªç©ºç™½ã‚’å‰Šé™¤ï¼‰
            normalized = path.strip().rstrip('/')

            # å…ƒã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆã‹ã‚‰æœ€ã‚‚è¿‘ã„ãƒ‘ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹
            best_match = self._find_best_match(normalized, original_file_paths)
            if best_match:
                normalized_paths.add(best_match)
                path_mapping[normalized] = best_match

        # å…ƒã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆã‹ã‚‰æ¼ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ 
        for orig_path in original_file_paths:
            if orig_path not in normalized_paths:
                normalized_paths.add(orig_path)

        # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰
        new_file_section = "## ä¿®æ­£ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«\n"
        for path in sorted(normalized_paths):
            new_file_section += f"- `{path}`\n"

        # ã‚³ãƒ¡ãƒ³ãƒˆå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç½®æ›
        new_comment = re.sub(file_section_pattern, new_file_section, comment, flags=re.DOTALL)

        return new_comment

    def _find_best_match(self, path: str, candidates: List[str]) -> str:
        """å€™è£œãƒªã‚¹ãƒˆã‹ã‚‰æœ€ã‚‚è¿‘ã„ãƒ‘ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹

        Args:
            path: æ¤œç´¢å¯¾è±¡ã®ãƒ‘ã‚¹
            candidates: å€™è£œãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ

        Returns:
            str: æœ€ã‚‚è¿‘ã„ãƒ‘ã‚¹ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…ƒã®ãƒ‘ã‚¹ï¼‰
        """
        # å®Œå…¨ä¸€è‡´
        if path in candidates:
            return path

        # éƒ¨åˆ†ä¸€è‡´ï¼ˆæœ€ã‚‚é•·ã„å…±é€šéƒ¨åˆ†ï¼‰
        best_match = None
        max_common_len = 0

        for candidate in candidates:
            common_len = len(os.path.commonprefix([path, candidate]))
            if common_len > max_common_len:
                max_common_len = common_len
                best_match = candidate

        return best_match if best_match else path

    def format_final_comment(
        self,
        summary: str,
        chunk_analyses: List[str],
        files: List[FileChange],
        skipped_files: List[FileChange] = None
    ) -> str:
        """æœ€çµ‚çš„ãªPRã‚³ãƒ¡ãƒ³ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹

        Args:
            summary: ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ
            chunk_analyses: ãƒãƒ£ãƒ³ã‚¯åˆ†æçµæœ
            files: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒªã‚¹ãƒˆ
            skipped_files: ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ

        Returns:
            str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæœ€çµ‚ã‚³ãƒ¡ãƒ³ãƒˆ
        """
        parts = [
            "# å¤‰æ›´å†…å®¹ã‚µãƒãƒªãƒ¼\n",
            summary,
            "\n\n"
        ]

        # ãƒãƒ£ãƒ³ã‚¯åˆ†æã®è¿½åŠ ï¼ˆè¤‡æ•°ãƒãƒ£ãƒ³ã‚¯ã®å ´åˆã®ã¿ï¼‰
        if len(chunk_analyses) > 1:
            parts.append(self.format_chunk_analyses(chunk_analyses))
            parts.append("\n\n")

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã®è¿½åŠ 
        parts.append(self.format_file_list(files))

        # ã‚¹ã‚­ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®è¿½åŠ 
        if skipped_files:
            parts.append(self.format_skipped_files_info(skipped_files))

        result = "".join(parts)
        return self.clean_markdown_format(result)
