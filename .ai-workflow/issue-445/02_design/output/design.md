# è©³ç´°è¨­è¨ˆæ›¸: Issue #445

## æ–‡æ›¸æƒ…å ±

- **Issueç•ªå·**: #445
- **ã‚¿ã‚¤ãƒˆãƒ«**: [Refactor] ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®å‰Šæ¸›: pr_comment_generator.py
- **çŠ¶æ…‹**: open
- **URL**: https://github.com/tielec/infrastructure-as-code/issues/445
- **ä½œæˆæ—¥**: 2025å¹´1æœˆ
- **æœ€çµ‚æ›´æ–°æ—¥**: 2025å¹´1æœˆ

---

## 0. Planning & Requirements Documentã®ç¢ºèª

### Planning Phaseæˆæœç‰©ã®æ¦‚è¦

Planning Documentã§ç­–å®šã•ã‚ŒãŸä»¥ä¸‹ã®æˆ¦ç•¥ã‚’ç¢ºèªã—ã€æœ¬è¨­è¨ˆæ›¸ã«åæ˜ ã—ã¦ã„ã¾ã™ï¼š

#### å®Ÿè£…æˆ¦ç•¥: REFACTOR
- æ—¢å­˜ã®å¤§è¦æ¨¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ1985è¡Œã€89ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰ã‚’è¤‡æ•°ã®å°ã•ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«åˆ†å‰²
- æ–°è¦æ©Ÿèƒ½ã®è¿½åŠ ã§ã¯ãªãã€æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®æ§‹é€ æ”¹å–„ãŒç›®çš„
- å˜ä¸€è²¬ä»»ã®åŸå‰‡ï¼ˆSRPï¼‰ã«åŸºã¥ã„ã¦é–¢å¿ƒäº‹ã‚’åˆ†é›¢

#### ãƒ†ã‚¹ãƒˆæˆ¦ç•¥: ALL
- **ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ**: å„åˆ†å‰²ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ç‹¬ç«‹ã—ãŸæ©Ÿèƒ½ã‚’æ¤œè¨¼
- **ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ**: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®é€£æºã‚’æ¤œè¨¼
- **BDDãƒ†ã‚¹ãƒˆ**: ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’æ¤œè¨¼

#### ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰æˆ¦ç•¥: BOTH_TEST
- **CREATE_TEST**: æ–°è¦åˆ†å‰²ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç”¨ã®æ–°è¦ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
- **EXTEND_TEST**: æ—¢å­˜ã®çµ±åˆãƒ†ã‚¹ãƒˆã‚’æ›´æ–°ã—ã€äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ 

### Requirements Phaseæˆæœç‰©ã®æ¦‚è¦

è¦ä»¶å®šç¾©æ›¸ã§å®šç¾©ã•ã‚ŒãŸä»¥ä¸‹ã®æ©Ÿèƒ½è¦ä»¶ã‚’è¨­è¨ˆã«åæ˜ ã—ã¦ã„ã¾ã™ï¼š

- **FR-001**: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†å‰²ï¼ˆPRCommentStatisticsã€CommentFormatterã€OpenAIIntegrationã€PRCommentGeneratorï¼‰
- **FR-002**: äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å®Ÿè£…ï¼ˆFacadeãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
- **FR-003**: ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã®å®Ÿè£…ï¼ˆãƒ¦ãƒ‹ãƒƒãƒˆã€çµ±åˆã€BDDï¼‰
- **FR-004**: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆï¼ˆAPIä»•æ§˜æ›¸ã€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆå›³ã€ç§»è¡Œã‚¬ã‚¤ãƒ‰ï¼‰

---

## 1. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

### 1.1 ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“å›³

```mermaid
graph TD
    CLI[CLI Entry Point<br/>main.py] --> Facade[__init__.py<br/>Facade Layer]
    Facade --> Generator[PRCommentGenerator<br/>generator.py]

    Generator --> Statistics[PRCommentStatistics<br/>statistics.py]
    Generator --> Formatter[CommentFormatter<br/>formatter.py]
    Generator --> OpenAI[OpenAIIntegration<br/>openai_integration.py]
    Generator --> Models[Data Models<br/>models.py]

    OpenAI --> PromptMgr[PromptTemplateManager<br/>prompt_manager.py]
    OpenAI --> TokenEst[TokenEstimator<br/>token_estimator.py]

    Statistics --> Models
    Formatter --> Models

    Generator -.->|ä¾å­˜| GitHub[GitHubClient<br/>github_utils.py]

    Facade -.->|éæ¨å¥¨è­¦å‘Š| OldCode[æ—¢å­˜ã‚³ãƒ¼ãƒ‰]

    style Generator fill:#e8f5e9,stroke:#4caf50,stroke-width:2px
    style Statistics fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
    style Formatter fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
    style OpenAI fill:#e3f2fd,stroke:#2196f3,stroke-width:2px
    style Facade fill:#fff3e0,stroke:#ff9800,stroke-width:2px
    style Models fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px
    style PromptMgr fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px
    style TokenEst fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px
```

### 1.2 ç¾çŠ¶ã®ã‚¯ãƒ©ã‚¹æ§‹æˆï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å‰ï¼‰

**ç¾çŠ¶ã®å•é¡Œç‚¹**:
- 1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ1985è¡Œï¼‰ã«6ã¤ã®ã‚¯ãƒ©ã‚¹ã¨89ãƒ¡ã‚½ãƒƒãƒ‰ãŒæ··åœ¨
- `OpenAIClient`ã‚¯ãƒ©ã‚¹ã«66ãƒ¡ã‚½ãƒƒãƒ‰ãŒé›†ä¸­ï¼ˆè²¬å‹™ãŒä¸æ˜ç¢ºï¼‰
- çµ±è¨ˆå‡¦ç†ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€APIé€£æºãŒæ··åœ¨

**ç¾çŠ¶ã®ã‚¯ãƒ©ã‚¹æ§‹æˆ**:
```
pr_comment_generator.py (1985è¡Œ)
â”œâ”€ PRInfo (dataclass)
â”œâ”€ FileChange (dataclass)
â”œâ”€ PromptTemplateManager (10ãƒ¡ã‚½ãƒƒãƒ‰)
â”œâ”€ TokenEstimator (2ãƒ¡ã‚½ãƒƒãƒ‰)
â”œâ”€ OpenAIClient (66ãƒ¡ã‚½ãƒƒãƒ‰) â† è‚¥å¤§åŒ–
â””â”€ PRCommentGenerator (11ãƒ¡ã‚½ãƒƒãƒ‰)
```

### 1.3 ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆ

**ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œã®æ§‹æˆ**:
```
pr_comment_generator/ (ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–)
â”œâ”€ __init__.py                 # Facadeï¼ˆäº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼‰
â”œâ”€ models.py                   # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ï¼ˆPRInfo, FileChangeï¼‰
â”œâ”€ statistics.py               # PRCommentStatisticsï¼ˆçµ±è¨ˆå‡¦ç†ï¼‰
â”œâ”€ formatter.py                # CommentFormatterï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†ï¼‰
â”œâ”€ openai_integration.py       # OpenAIIntegrationï¼ˆAPIçµ±åˆï¼‰
â”œâ”€ generator.py                # PRCommentGeneratorï¼ˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
â”œâ”€ token_estimator.py          # TokenEstimatorï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šï¼‰
â””â”€ prompt_manager.py           # PromptTemplateManagerï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ï¼‰
```

### 1.4 ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“ã®é–¢ä¿‚

#### ä¾å­˜é–¢ä¿‚ã®éšå±¤

**ãƒ¬ã‚¤ãƒ¤ãƒ¼1: ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å±¤**
- `models.py`: ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ï¼ˆPRInfoã€FileChangeï¼‰
- ä»–ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰å‚ç…§ã•ã‚Œã‚‹åŸºç›¤

**ãƒ¬ã‚¤ãƒ¤ãƒ¼2: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£å±¤**
- `token_estimator.py`: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®š
- `prompt_manager.py`: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†
- `statistics.py`: çµ±è¨ˆè¨ˆç®—
- `formatter.py`: ã‚³ãƒ¡ãƒ³ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

**ãƒ¬ã‚¤ãƒ¤ãƒ¼3: çµ±åˆå±¤**
- `openai_integration.py`: OpenAI APIçµ±åˆï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼2ã«ä¾å­˜ï¼‰

**ãƒ¬ã‚¤ãƒ¤ãƒ¼4: ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¤**
- `generator.py`: ã‚³ã‚¢ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼2ã€3ã«ä¾å­˜ï¼‰

**ãƒ¬ã‚¤ãƒ¤ãƒ¼5: äº’æ›æ€§å±¤**
- `__init__.py`: Facadeï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼4ã‚’å†ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼‰

#### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant CLI as CLI/Jenkinsfile
    participant Gen as PRCommentGenerator
    participant Stat as PRCommentStatistics
    participant OAI as OpenAIIntegration
    participant Fmt as CommentFormatter

    CLI->>Gen: generate_comment(pr_info, diff_file)
    Gen->>Gen: _load_and_validate_data()
    Gen->>Stat: calculate_optimal_chunk_size()
    Stat-->>Gen: chunk_size
    Gen->>Gen: _preprocess_file_changes()
    Gen->>OAI: analyze_chunks(chunks)
    OAI-->>Gen: chunk_analyses
    Gen->>Fmt: format_chunk_analyses(analyses)
    Fmt-->>Gen: formatted_comment
    Gen->>OAI: generate_summary(analyses)
    OAI-->>Gen: summary
    Gen->>Fmt: format_final_comment(summary, chunks)
    Fmt-->>Gen: final_comment
    Gen-->>CLI: (comment, title)
```

---

## 2. å®Ÿè£…æˆ¦ç•¥åˆ¤æ–­

### å®Ÿè£…æˆ¦ç•¥: REFACTOR

**åˆ¤æ–­æ ¹æ‹ **:

1. **æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®æ§‹é€ æ”¹å–„ãŒä¸»ç›®çš„**
   - 1985è¡Œã€89ãƒ¡ã‚½ãƒƒãƒ‰ã®å¤§è¦æ¨¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¤‡æ•°ã®å°ã•ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«åˆ†å‰²
   - æ–°è¦æ©Ÿèƒ½ã®è¿½åŠ ã§ã¯ãªãã€æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®å†æ§‹æˆ

2. **å˜ä¸€è²¬ä»»ã®åŸå‰‡ï¼ˆSRPï¼‰ã¸ã®æº–æ‹ **
   - ç¾çŠ¶ã¯çµ±è¨ˆå‡¦ç†ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€APIé€£æºã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”ŸæˆãŒ1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«æ··åœ¨
   - å„é–¢å¿ƒäº‹ã‚’ç‹¬ç«‹ã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«åˆ†é›¢ã™ã‚‹ã“ã¨ã§ä¿å®ˆæ€§ã‚’å‘ä¸Š

3. **æ—¢å­˜ã®public APIã¨ã®äº’æ›æ€§ã‚’ç¶­æŒ**
   - Facadeãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚Šã€æ—¢å­˜ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆ`from pr_comment_generator import XXX`ï¼‰ã‚’æ®µéšçš„ã«ç§»è¡Œ
   - ç ´å£Šçš„å¤‰æ›´ã‚’æœ€å°åŒ–ã—ã€ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¸ã®å½±éŸ¿ã‚’è»½æ¸›

4. **ãƒ†ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£ã®å‘ä¸Š**
   - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†å‰²ã«ã‚ˆã‚Šã€å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç‹¬ç«‹ã—ã¦ãƒ†ã‚¹ãƒˆå¯èƒ½
   - ãƒ¢ãƒƒã‚¯åŒ–ãŒå®¹æ˜“ã«ãªã‚Šã€ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã®ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒå‘ä¸Š

**æŠ€è¡“çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**:
- Extract Module ãƒ‘ã‚¿ãƒ¼ãƒ³: é–¢é€£ã™ã‚‹é–¢æ•°ç¾¤ã‚’æ–°ã—ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«æŠ½å‡º
- Facade ãƒ‘ã‚¿ãƒ¼ãƒ³: æ—¢å­˜ã®public APIã¨ã®äº’æ›æ€§ç¶­æŒ
- Dependency Injection: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®ä¾å­˜é–¢ä¿‚ã‚’æ˜ç¤ºçš„ã«ç®¡ç†

---

## 3. ãƒ†ã‚¹ãƒˆæˆ¦ç•¥åˆ¤æ–­

### ãƒ†ã‚¹ãƒˆæˆ¦ç•¥: ALL

**åˆ¤æ–­æ ¹æ‹ **:

1. **ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã®å¿…è¦æ€§ï¼ˆé«˜ï¼‰**
   - å„åˆ†å‰²ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆStatisticsã€Formatterã€OpenAIIntegrationï¼‰ã®ç‹¬ç«‹ã—ãŸæ©Ÿèƒ½ã‚’æ¤œè¨¼
   - çµ±è¨ˆè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã®æ­£ç¢ºæ€§ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡ºåŠ›ã®æ­£ç¢ºæ€§ã€APIçµ±åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ãƒ†ã‚¹ãƒˆ
   - ãƒ¢ãƒƒã‚¯åŒ–ã«ã‚ˆã‚Šã€å¤–éƒ¨ä¾å­˜ï¼ˆOpenAI APIï¼‰ã‚’æ’é™¤ã—ãŸãƒ†ã‚¹ãƒˆãŒå¯èƒ½

2. **ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆã®å¿…è¦æ€§ï¼ˆé«˜ï¼‰**
   - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®é€£æºï¼ˆStatisticsâ†’Formatterã€Generatorâ†’OpenAIï¼‰ã‚’æ¤œè¨¼
   - çµ±åˆå¾Œã®å‹•ä½œã‚’ä¿è¨¼ã—ã€ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å‰å¾Œã®å‹•ä½œåŒä¸€æ€§ã‚’ç¢ºèª
   - äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆFacadeï¼‰ã®ãƒ†ã‚¹ãƒˆã‚‚å«ã‚€

3. **BDDãƒ†ã‚¹ãƒˆã®å¿…è¦æ€§ï¼ˆä¸­ï¼‰**
   - ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ï¼ˆã€ŒPRã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã™ã‚‹ã¨ã€é©åˆ‡ãªã‚³ãƒ¡ãƒ³ãƒˆãŒè¿”ã•ã‚Œã‚‹ã€ï¼‰ã‚’æ¤œè¨¼
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ¬ãƒ™ãƒ«ã®è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã‚‹ã‹ç¢ºèª
   - Jenkinsfileã‹ã‚‰ã®å®Ÿè¡Œã‚·ãƒŠãƒªã‚ªã‚’å†ç¾

4. **ãƒªã‚¹ã‚¯è»½æ¸›ã®ãŸã‚ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ**
   - å¤§è¦æ¨¡ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ï¼ˆé«˜ãƒªã‚¹ã‚¯ï¼‰ã®ãŸã‚ã€ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã§å“è³ªã‚’ä¿è¨¼
   - ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ï¼ˆé€€è¡Œï¼‰ã‚’é˜²ããŸã‚ã€æ—¢å­˜æ©Ÿèƒ½ã®å‹•ä½œä¿è¨¼ãŒå¿…é ˆ
   - ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™: å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«80%ä»¥ä¸Š

**ãƒ†ã‚¹ãƒˆã®å„ªå…ˆé †ä½**:
1. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆï¼ˆæœ€å„ªå…ˆï¼‰: å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åŸºæœ¬æ©Ÿèƒ½
2. ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆï¼ˆé«˜å„ªå…ˆï¼‰: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“é€£æº
3. BDDãƒ†ã‚¹ãƒˆï¼ˆä¸­å„ªå…ˆï¼‰: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒˆãƒ¼ãƒªãƒ¼æ¤œè¨¼

---

## 4. ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰æˆ¦ç•¥åˆ¤æ–­

### ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰æˆ¦ç•¥: BOTH_TEST

**åˆ¤æ–­æ ¹æ‹ **:

1. **CREATE_TESTï¼ˆæ–°è¦ãƒ†ã‚¹ãƒˆä½œæˆï¼‰ã®å¿…è¦æ€§**
   - æ–°è¦åˆ†å‰²ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ`statistics.py`ã€`formatter.py`ã€`openai_integration.py`ï¼‰ç”¨ã®æ–°è¦ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
   - å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è²¬å‹™ãŒæ˜ç¢ºã«ãªã‚‹ãŸã‚ã€å°‚ç”¨ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ç®¡ç†
   - ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ:
     - `tests/unit/test_statistics.py`
     - `tests/unit/test_formatter.py`
     - `tests/unit/test_openai_integration.py`
     - `tests/unit/test_generator.py`
     - `tests/unit/test_token_estimator.py`
     - `tests/unit/test_prompt_manager.py`

2. **EXTEND_TESTï¼ˆæ—¢å­˜ãƒ†ã‚¹ãƒˆæ‹¡å¼µï¼‰ã®å¿…è¦æ€§**
   - æ—¢å­˜ã®çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆ`PRCommentGenerator`ã«å¯¾ã™ã‚‹ãƒ†ã‚¹ãƒˆï¼‰ã‚’æ›´æ–°ã—ã€äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ 
   - äº’æ›æ€§æ¤œè¨¼ã®ãŸã‚ã€æ—¢å­˜ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ç¶­æŒã—ãªãŒã‚‰æ–°ã—ã„ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ 
   - ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ:
     - `tests/integration/test_generator_integration.py`ï¼ˆæ—¢å­˜ã¾ãŸã¯æ–°è¦ï¼‰
     - `tests/integration/test_compatibility_layer.py`ï¼ˆæ–°è¦ï¼‰

3. **ä¸¡æ–¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’çµ„ã¿åˆã‚ã›ã‚‹ç†ç”±**
   - æ–°è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ç‹¬ç«‹ã—ãŸãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ç®¡ç†ã™ã‚‹ã“ã¨ã§ã€ä¿å®ˆæ€§ã‚’å‘ä¸Š
   - æ—¢å­˜ã®çµ±åˆãƒ†ã‚¹ãƒˆã¯äº’æ›æ€§æ¤œè¨¼ã®ãŸã‚ã«ç¶­æŒã—ã€æ®µéšçš„ãªç§»è¡Œã‚’æ”¯æ´
   - ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å‰å¾Œã®å‹•ä½œåŒä¸€æ€§ã‚’ä¿è¨¼ã™ã‚‹ãŸã‚ã€ä¸¡æ–¹ã®ãƒ†ã‚¹ãƒˆãŒå¿…è¦

**ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ**:
```
tests/
â”œâ”€ unit/                                    # ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆï¼ˆæ–°è¦ä½œæˆï¼‰
â”‚  â”œâ”€ test_statistics.py
â”‚  â”œâ”€ test_formatter.py
â”‚  â”œâ”€ test_openai_integration.py
â”‚  â”œâ”€ test_generator.py
â”‚  â”œâ”€ test_token_estimator.py
â”‚  â””â”€ test_prompt_manager.py
â”œâ”€ integration/                             # çµ±åˆãƒ†ã‚¹ãƒˆ
â”‚  â”œâ”€ test_generator_integration.py         # æ—¢å­˜ã¾ãŸã¯æ–°è¦
â”‚  â””â”€ test_compatibility_layer.py           # æ–°è¦
â””â”€ bdd/                                     # BDDãƒ†ã‚¹ãƒˆï¼ˆæ–°è¦ä½œæˆï¼‰
   â””â”€ test_bdd_pr_comment_generation.py
```

---

## 5. å½±éŸ¿ç¯„å›²åˆ†æ

### 5.1 æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¸ã®å½±éŸ¿

#### ä¸»è¦ãªå½±éŸ¿

**ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²**:
- `pr_comment_generator.py`ï¼ˆ1985è¡Œï¼‰â†’ 7ã¤ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«åˆ†å‰²
  - `models.py`: ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ï¼ˆPRInfoã€FileChangeï¼‰
  - `statistics.py`: çµ±è¨ˆå‡¦ç†ï¼ˆç´„200è¡Œï¼‰
  - `formatter.py`: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†ï¼ˆç´„300è¡Œï¼‰
  - `openai_integration.py`: APIçµ±åˆï¼ˆç´„500è¡Œï¼‰
  - `generator.py`: ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç´„300è¡Œï¼‰
  - `token_estimator.py`: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šï¼ˆç´„100è¡Œï¼‰
  - `prompt_manager.py`: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ï¼ˆç´„200è¡Œï¼‰

**äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼**:
- `__init__.py`: Facadeã¨ã—ã¦å®Ÿè£…ã—ã€æ—§ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚’ã‚µãƒãƒ¼ãƒˆ
- éæ¨å¥¨è­¦å‘Šï¼ˆDeprecationWarningï¼‰ã‚’è¿½åŠ 

#### ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¸ã®å½±éŸ¿

**ç›´æ¥çš„ãªå½±éŸ¿ã‚’å—ã‘ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«**:
1. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/Jenkinsfile`
   - Line 266: `python pr_comment_generator.py ...`
   - **å½±éŸ¿**: CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã¯å¤‰æ›´ãªã—ï¼ˆå¾Œæ–¹äº’æ›æ€§ã‚ã‚Šï¼‰

2. ãã®ä»–ã®ä¾å­˜ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚‚ã—å­˜åœ¨ã™ã‚‹å ´åˆï¼‰
   - `from pr_comment_generator import PRCommentGenerator`ã®ã‚ˆã†ãªæ—§ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
   - **å½±éŸ¿**: äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«ã‚ˆã‚Šå‹•ä½œã¯ç¶­æŒã•ã‚Œã‚‹ãŒã€éæ¨å¥¨è­¦å‘ŠãŒè¡¨ç¤ºã•ã‚Œã‚‹

**é–“æ¥çš„ãªå½±éŸ¿**:
- ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰: ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã®æ›´æ–°ãŒå¿…è¦ï¼ˆæ–°ã—ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆã«å¯¾å¿œï¼‰
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆå›³ã€APIä»•æ§˜æ›¸ã®æ›´æ–°ãŒå¿…è¦

### 5.2 ä¾å­˜é–¢ä¿‚ã®å¤‰æ›´

#### æ–°è¦ä¾å­˜

**ãªã—**ï¼ˆæ—¢å­˜ã®ä¾å­˜é–¢ä¿‚ã‚’ä¿æŒï¼‰

#### æ—¢å­˜ä¾å­˜ã®å¤‰æ›´

**ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã®å¤‰æ›´**:

**æ—§ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å‰ï¼‰**:
```python
from pr_comment_generator import PRCommentGenerator, PRInfo, FileChange
```

**æ–°ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œï¼‰**:
```python
# æ¨å¥¨ã•ã‚Œã‚‹æ–°ã—ã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–¹æ³•
from pr_comment_generator.generator import PRCommentGenerator
from pr_comment_generator.models import PRInfo, FileChange
from pr_comment_generator.statistics import PRCommentStatistics
from pr_comment_generator.formatter import CommentFormatter
from pr_comment_generator.openai_integration import OpenAIIntegration
```

**äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«ã‚ˆã‚‹æ—§ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã®ã‚µãƒãƒ¼ãƒˆ**:
```python
# ç§»è¡ŒæœŸé–“ä¸­ã¯æ—§ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚‚å‹•ä½œã™ã‚‹
from pr_comment_generator import PRCommentGenerator  # éæ¨å¥¨è­¦å‘ŠãŒè¡¨ç¤ºã•ã‚Œã‚‹
```

#### å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¸ã®ä¾å­˜

**å¤‰æ›´ãªã—**:
- `openai`: OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
- æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: `argparse`ã€`json`ã€`logging`ã€`dataclasses`ã€`typing`

### 5.3 ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¦å¦

#### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›´

**ä¸è¦**ï¼ˆäº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«ã‚ˆã‚Šæ—¢å­˜è¨­å®šã‚’ã‚µãƒãƒ¼ãƒˆï¼‰

#### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã®å¤‰æ›´

**ä¸è¦**ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ä½¿ç”¨ã—ã¦ã„ãªã„ï¼‰

#### ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

**ä¸è¦**ï¼ˆæ®µéšçš„ç§»è¡Œã«ã‚ˆã‚Šã€é–‹ç™ºè€…ãŒä»»æ„ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§æ–°ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã«ç§»è¡Œå¯èƒ½ï¼‰

**æ¨å¥¨ã•ã‚Œã‚‹ç§»è¡Œæ‰‹é †**:
1. ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Œäº†å¾Œã€2é€±é–“ã®ç§»è¡ŒæœŸé–“ã‚’è¨­ã‘ã‚‹
2. ç§»è¡ŒæœŸé–“ä¸­ã¯æ—§ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã¨æ–°ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆ
3. éæ¨å¥¨è­¦å‘Šã‚’é€šã˜ã¦ã€é–‹ç™ºè€…ã«æ–°ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã¸ã®ç§»è¡Œã‚’ä¿ƒã™
4. ç§»è¡ŒæœŸé–“çµ‚äº†å¾Œã€äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’å‰Šé™¤ï¼ˆæŠ€è¡“çš„è² å‚µã®è§£æ¶ˆï¼‰

---

## 6. å¤‰æ›´ãƒ»è¿½åŠ ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ

### 6.1 æ–°è¦ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«

#### ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰

1. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/src/pr_comment_generator/__init__.py`
   - Facadeï¼ˆäº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼‰
   - æ—§ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã®å†ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

2. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/src/pr_comment_generator/models.py`
   - ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ï¼ˆPRInfoã€FileChangeï¼‰
   - æ—¢å­˜ã®`pr_comment_generator.py`ã‹ã‚‰æŠ½å‡º

3. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/src/pr_comment_generator/statistics.py`
   - PRCommentStatisticsã‚¯ãƒ©ã‚¹
   - çµ±è¨ˆè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯

4. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/src/pr_comment_generator/formatter.py`
   - CommentFormatterã‚¯ãƒ©ã‚¹
   - ã‚³ãƒ¡ãƒ³ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†

5. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/src/pr_comment_generator/openai_integration.py`
   - OpenAIIntegrationã‚¯ãƒ©ã‚¹
   - OpenAI APIçµ±åˆ

6. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/src/pr_comment_generator/generator.py`
   - PRCommentGeneratorã‚¯ãƒ©ã‚¹ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰
   - ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¤

7. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/src/pr_comment_generator/token_estimator.py`
   - TokenEstimatorã‚¯ãƒ©ã‚¹
   - ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®š

8. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/src/pr_comment_generator/prompt_manager.py`
   - PromptTemplateManagerã‚¯ãƒ©ã‚¹
   - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†

#### ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰

9. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/tests/unit/test_statistics.py`
   - PRCommentStatisticsã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

10. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/tests/unit/test_formatter.py`
    - CommentFormatterã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

11. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/tests/unit/test_openai_integration.py`
    - OpenAIIntegrationã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

12. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/tests/unit/test_generator.py`
    - PRCommentGeneratorã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

13. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/tests/unit/test_token_estimator.py`
    - TokenEstimatorã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

14. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/tests/unit/test_prompt_manager.py`
    - PromptTemplateManagerã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

15. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/tests/integration/test_generator_integration.py`
    - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“é€£æºã®çµ±åˆãƒ†ã‚¹ãƒˆ

16. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/tests/integration/test_compatibility_layer.py`
    - äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ†ã‚¹ãƒˆ

17. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/tests/bdd/test_bdd_pr_comment_generation.py`
    - BDDãƒ†ã‚¹ãƒˆï¼ˆGiven-When-Thenã‚·ãƒŠãƒªã‚ªï¼‰

18. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/tests/__init__.py`
    - ãƒ†ã‚¹ãƒˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®åˆæœŸåŒ–

19. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/tests/conftest.py`
    - pytestå…±é€šè¨­å®šï¼ˆãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£å®šç¾©ï¼‰

#### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

20. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/docs/api_specification.md`
    - APIä»•æ§˜æ›¸

21. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/docs/module_architecture.md`
    - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆå›³

22. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/docs/migration_guide.md`
    - ç§»è¡Œã‚¬ã‚¤ãƒ‰

### 6.2 ä¿®æ­£ãŒå¿…è¦ãªæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«

1. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/src/pr_comment_generator.py`
   - **å¤‰æ›´å†…å®¹**: ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–ã«ä¼´ã„ã€CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦å†æ§‹æˆ
   - **ç†ç”±**: `python pr_comment_generator.py`ã§ã®å®Ÿè¡Œã‚’ç¶­æŒã™ã‚‹ãŸã‚
   - **å…·ä½“çš„ãªå¤‰æ›´**:
     - `if __name__ == '__main__'`ãƒ–ãƒ­ãƒƒã‚¯ã®ã¿æ®‹ã™
     - å®Ÿéš›ã®å‡¦ç†ã¯`generator.py`ã®`PRCommentGenerator`ã«å§”è­²

2. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/src/requirements.txt`
   - **å¤‰æ›´å†…å®¹**: ãƒ†ã‚¹ãƒˆç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¿½åŠ 
   - **è¿½åŠ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸**:
     - `pytest>=7.0.0`
     - `pytest-cov>=4.0.0`
     - `pytest-mock>=3.10.0`
     - `responses>=0.23.0`ï¼ˆOpenAI APIã®ãƒ¢ãƒƒã‚¯ç”¨ï¼‰

3. `jenkins/jobs/pipeline/docs-generator/pull-request-comment-builder/README.md`ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
   - **å¤‰æ›´å†…å®¹**: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆã®èª¬æ˜ã‚’æ›´æ–°
   - **è¿½åŠ å†…å®¹**: æ–°ã—ã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã®èª¬æ˜ã€ç§»è¡Œã‚¬ã‚¤ãƒ‰ã¸ã®ãƒªãƒ³ã‚¯

### 6.3 å‰Šé™¤ãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«

**ãªã—**ï¼ˆæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯äº’æ›æ€§ã®ãŸã‚ä¿æŒï¼‰

**æ³¨æ„**: ç§»è¡ŒæœŸé–“çµ‚äº†å¾Œï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Œäº†ã‹ã‚‰2é€±é–“å¾Œï¼‰ã€ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã‚’æ¤œè¨ï¼š
- `pr_comment_generator/__init__.py`ã®äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼éƒ¨åˆ†ï¼ˆéæ¨å¥¨è­¦å‘Šã‚’å‰Šé™¤ã—ã€ã‚·ãƒ³ãƒ—ãƒ«ãªå†ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«å¤‰æ›´ï¼‰

---

## 7. è©³ç´°è¨­è¨ˆ

### 7.1 ã‚¯ãƒ©ã‚¹è¨­è¨ˆ

#### 7.1.1 models.py

**ç›®çš„**: ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã‚’å®šç¾©ã—ã€ä»–ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰å‚ç…§ã•ã‚Œã‚‹åŸºç›¤ã‚’æä¾›

```python
# models.py
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

@dataclass
class PRInfo:
    """PRã®åŸºæœ¬æƒ…å ±ã‚’ä¿æŒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    title: str
    number: int
    body: Optional[str]
    author: str
    base_branch: str
    head_branch: str
    base_sha: str
    head_sha: str

    @classmethod
    def from_json(cls, data: Dict[str, Any]) -> 'PRInfo':
        """JSONãƒ‡ãƒ¼ã‚¿ã‹ã‚‰PRInfoã‚’ä½œæˆã™ã‚‹"""
        return cls(
            title=data.get('title', ''),
            number=data.get('number', 0),
            body=data.get('body') or '',
            author=data.get('user', {}).get('login', ''),
            base_branch=data.get('base', {}).get('ref', ''),
            head_branch=data.get('head', {}).get('ref', ''),
            base_sha=data.get('base', {}).get('sha', ''),
            head_sha=data.get('head', {}).get('sha', '')
        )

@dataclass
class FileChange:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›´å†…å®¹ã‚’ä¿æŒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    filename: str
    status: str
    additions: int
    deletions: int
    changes: int
    patch: Optional[str] = None
    content_before: Optional[str] = None
    content_after: Optional[str] = None
    context_diff: Optional[Dict[str, Any]] = field(default_factory=dict)

    @classmethod
    def from_json(cls, data: Dict[str, Any]) -> 'FileChange':
        """JSONãƒ‡ãƒ¼ã‚¿ã‹ã‚‰FileChangeã‚’ä½œæˆã™ã‚‹"""
        return cls(
            filename=data.get('filename', ''),
            status=data.get('status', ''),
            additions=data.get('additions', 0),
            deletions=data.get('deletions', 0),
            changes=data.get('changes', 0),
            patch=data.get('patch')
        )
```

**è²¬å‹™**:
- PRæƒ…å ±ã¨ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æƒ…å ±ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’å®šç¾©
- JSONã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã¸ã®å¤‰æ›æ©Ÿèƒ½ã‚’æä¾›

**public API**:
- `PRInfo`: PRã®åŸºæœ¬æƒ…å ±
- `FileChange`: ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›´å†…å®¹

#### 7.1.2 token_estimator.py

**ç›®çš„**: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¨å®šæ©Ÿèƒ½ã‚’æä¾›

```python
# token_estimator.py
from typing import List
import logging

class TokenEstimator:
    """ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®šã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    AVERAGE_TOKEN_PER_CHAR_JA = 0.6  # æ—¥æœ¬èªã®å¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³/æ–‡å­—æ¯”ç‡
    AVERAGE_TOKEN_PER_CHAR_EN = 0.25  # è‹±èªã®å¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³/æ–‡å­—æ¯”ç‡

    def __init__(self, logger: logging.Logger = None):
        """
        åˆæœŸåŒ–
        Args:
            logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.logger = logger or logging.getLogger(__name__)

    def estimate_tokens(self, text: str) -> int:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®šã™ã‚‹

        Args:
            text: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®šã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        if not text:
            return 0

        # æ—¥æœ¬èªæ–‡å­—ã®å‰²åˆã‚’æ¨å®š
        ja_chars = sum(1 for c in text if ord(c) > 0x3000)
        en_chars = len(text) - ja_chars

        # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®š
        estimated_tokens = int(
            ja_chars * self.AVERAGE_TOKEN_PER_CHAR_JA +
            en_chars * self.AVERAGE_TOKEN_PER_CHAR_EN
        )

        return estimated_tokens

    def truncate_text(self, text: str, max_tokens: int) -> str:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ä»¥ä¸‹ã«åˆ‡ã‚Šè©°ã‚ã‚‹

        Args:
            text: åˆ‡ã‚Šè©°ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°

        Returns:
            åˆ‡ã‚Šè©°ã‚ã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        if self.estimate_tokens(text) <= max_tokens:
            return text

        # ãƒã‚¤ãƒŠãƒªã‚µãƒ¼ãƒã§é©åˆ‡ãªé•·ã•ã‚’è¦‹ã¤ã‘ã‚‹
        left, right = 0, len(text)
        while left < right:
            mid = (left + right + 1) // 2
            if self.estimate_tokens(text[:mid]) <= max_tokens:
                left = mid
            else:
                right = mid - 1

        truncated = text[:left]
        self.logger.warning(f"Text truncated from {len(text)} to {len(truncated)} chars")
        return truncated
```

**è²¬å‹™**:
- ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®š
- ãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ¶é™ã«åŸºã¥ã„ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚

**public API**:
- `estimate_tokens(text: str) -> int`: ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®š
- `truncate_text(text: str, max_tokens: int) -> str`: ãƒ†ã‚­ã‚¹ãƒˆåˆ‡ã‚Šè©°ã‚

#### 7.1.3 prompt_manager.py

**ç›®çš„**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ç®¡ç†æ©Ÿèƒ½ã‚’æä¾›

```python
# prompt_manager.py
import os
from typing import Dict

class PromptTemplateManager:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, template_dir: str = "templates"):
        """
        åˆæœŸåŒ–
        Args:
            template_dir: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
        """
        self.template_dir = template_dir
        self._load_templates()

    def _load_templates(self):
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        template_files = {
            'base': 'base_template.md',
            'chunk': 'chunk_analysis_extension.md',
            'summary': 'summary_extension.md'
        }

        self.templates = {}
        for key, filename in template_files.items():
            path = os.path.join(self.template_dir, filename)
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    self.templates[key] = f.read().strip()
            except FileNotFoundError:
                print(f"Warning: Template file {filename} not found")
                self.templates[key] = ""

    def get_base_prompt(self) -> str:
        """ãƒ™ãƒ¼ã‚¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ã™ã‚‹"""
        return self.templates.get('base', '')

    def get_chunk_analysis_prompt(self) -> str:
        """ãƒãƒ£ãƒ³ã‚¯åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ã™ã‚‹"""
        return self.templates.get('chunk', '')

    def get_summary_prompt(self) -> str:
        """ã‚µãƒãƒªãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ã™ã‚‹"""
        return self.templates.get('summary', '')

    def format_prompt(self, template_key: str, **kwargs) -> str:
        """
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹

        Args:
            template_key: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ã‚­ãƒ¼
            **kwargs: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç”¨ã®å¤‰æ•°

        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        template = self.templates.get(template_key, '')
        try:
            return template.format(**kwargs)
        except KeyError as e:
            print(f"Warning: Missing format variable: {e}")
            return template
```

**è²¬å‹™**:
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

**public API**:
- `get_base_prompt() -> str`: ãƒ™ãƒ¼ã‚¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—
- `get_chunk_analysis_prompt() -> str`: ãƒãƒ£ãƒ³ã‚¯åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—
- `get_summary_prompt() -> str`: ã‚µãƒãƒªãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—
- `format_prompt(template_key: str, **kwargs) -> str`: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

#### 7.1.4 statistics.py

**ç›®çš„**: çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®åé›†ãƒ»è¨ˆç®—æ©Ÿèƒ½ã‚’æä¾›

```python
# statistics.py
from typing import List, Dict, Any
import logging
from .models import FileChange
from .token_estimator import TokenEstimator

class PRCommentStatistics:
    """PRã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã®ãŸã‚ã®çµ±è¨ˆå‡¦ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""

    DEFAULT_MAX_CHUNK_TOKENS = 3000
    DEFAULT_MIN_CHUNK_SIZE = 1

    def __init__(self, token_estimator: TokenEstimator = None,
                 logger: logging.Logger = None):
        """
        åˆæœŸåŒ–
        Args:
            token_estimator: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šå™¨
            logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.token_estimator = token_estimator or TokenEstimator()
        self.logger = logger or logging.getLogger(__name__)

    def calculate_optimal_chunk_size(
        self,
        files: List[FileChange],
        max_tokens: int = DEFAULT_MAX_CHUNK_TOKENS
    ) -> int:
        """
        æœ€é©ãªãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã™ã‚‹

        Args:
            files: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒªã‚¹ãƒˆ
            max_tokens: ãƒãƒ£ãƒ³ã‚¯ã‚ãŸã‚Šã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°

        Returns:
            æœ€é©ãªãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æ•°ï¼‰
        """
        if not files:
            return self.DEFAULT_MIN_CHUNK_SIZE

        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®š
        file_tokens = []
        for file in files:
            content = file.patch or ""
            tokens = self.token_estimator.estimate_tokens(content)
            file_tokens.append(tokens)

        # ç´¯ç©ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’æ±ºå®š
        chunk_size = 0
        cumulative_tokens = 0

        for tokens in sorted(file_tokens):
            if cumulative_tokens + tokens > max_tokens:
                break
            cumulative_tokens += tokens
            chunk_size += 1

        # æœ€å°ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’ä¿è¨¼
        chunk_size = max(chunk_size, self.DEFAULT_MIN_CHUNK_SIZE)

        self.logger.info(f"Calculated optimal chunk size: {chunk_size} files")
        return chunk_size

    def estimate_chunk_tokens(self, chunk: List[FileChange]) -> int:
        """
        ãƒãƒ£ãƒ³ã‚¯ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®šã™ã‚‹

        Args:
            chunk: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã®ãƒãƒ£ãƒ³ã‚¯

        Returns:
            æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        total_tokens = 0
        for file in chunk:
            content = file.patch or ""
            total_tokens += self.token_estimator.estimate_tokens(content)

        return total_tokens

    def calculate_statistics(self, files: List[FileChange]) -> Dict[str, Any]:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã™ã‚‹

        Args:
            files: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒªã‚¹ãƒˆ

        Returns:
            çµ±è¨ˆæƒ…å ±ã®è¾æ›¸
        """
        total_additions = sum(f.additions for f in files)
        total_deletions = sum(f.deletions for f in files)
        total_changes = sum(f.changes for f in files)

        return {
            'file_count': len(files),
            'total_additions': total_additions,
            'total_deletions': total_deletions,
            'total_changes': total_changes,
            'avg_changes_per_file': total_changes / len(files) if files else 0
        }
```

**è²¬å‹™**:
- æœ€é©ãªãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®è¨ˆç®—
- ãƒãƒ£ãƒ³ã‚¯ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®š
- ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã®çµ±è¨ˆæƒ…å ±è¨ˆç®—

**public API**:
- `calculate_optimal_chunk_size(files: List[FileChange], max_tokens: int) -> int`
- `estimate_chunk_tokens(chunk: List[FileChange]) -> int`
- `calculate_statistics(files: List[FileChange]) -> Dict[str, Any]`

#### 7.1.5 formatter.py

**ç›®çš„**: ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†æ©Ÿèƒ½ã‚’æä¾›

```python
# formatter.py
import re
from typing import List, Dict, Any
import logging
from .models import FileChange

class CommentFormatter:
    """PRã‚³ãƒ¡ãƒ³ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, logger: logging.Logger = None):
        """
        åˆæœŸåŒ–
        Args:
            logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.logger = logger or logging.getLogger(__name__)

    def clean_markdown_format(self, text: str) -> str:
        """
        Markdownãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹

        Args:
            text: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        # ä½™åˆ†ãªç©ºè¡Œã‚’å‰Šé™¤
        text = re.sub(r'\n{3,}', '\n\n', text)

        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®å‰å¾Œã®ç©ºè¡Œã‚’èª¿æ•´
        text = re.sub(r'\n+```', '\n```', text)
        text = re.sub(r'```\n+', '```\n', text)

        # æœ«å°¾ã®ç©ºç™½ã‚’å‰Šé™¤
        text = '\n'.join(line.rstrip() for line in text.split('\n'))

        return text.strip()

    def format_chunk_analyses(self, analyses: List[str]) -> str:
        """
        ãƒãƒ£ãƒ³ã‚¯åˆ†æçµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹

        Args:
            analyses: ãƒãƒ£ãƒ³ã‚¯åˆ†æçµæœã®ãƒªã‚¹ãƒˆ

        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸåˆ†æçµæœ
        """
        if not analyses:
            return ""

        formatted_parts = []
        for i, analysis in enumerate(analyses, 1):
            header = f"## ãƒãƒ£ãƒ³ã‚¯ {i} ã®åˆ†æ\n\n"
            formatted_parts.append(header + analysis)

        result = "\n\n".join(formatted_parts)
        return self.clean_markdown_format(result)

    def format_file_list(self, files: List[FileChange]) -> str:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹

        Args:
            files: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒªã‚¹ãƒˆ

        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
        """
        if not files:
            return "å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

        lines = ["## å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«\n"]
        for file in files:
            status_emoji = {
                'added': 'âœ¨',
                'modified': 'ğŸ“',
                'removed': 'ğŸ—‘ï¸',
                'renamed': 'ğŸ“›'
            }.get(file.status, 'ğŸ“„')

            line = f"- {status_emoji} `{file.filename}` (+{file.additions} -{file.deletions})"
            lines.append(line)

        return "\n".join(lines)

    def format_skipped_files_info(
        self,
        skipped_files: List[FileChange],
        reason: str = "ã‚µã‚¤ã‚ºåˆ¶é™"
    ) -> str:
        """
        ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹

        Args:
            skipped_files: ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
            reason: ã‚¹ã‚­ãƒƒãƒ—ç†ç”±

        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæƒ…å ±
        """
        if not skipped_files:
            return ""

        lines = [
            f"\n## âš ï¸ ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ« ({reason})\n",
            f"ä»¥ä¸‹ã®{len(skipped_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯{reason}ã«ã‚ˆã‚Šã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸï¼š\n"
        ]

        for file in skipped_files:
            lines.append(f"- `{file.filename}`")

        return "\n".join(lines)

    def rebuild_file_section(self, comment: str, files: List[FileChange]) -> str:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å†æ§‹ç¯‰ã™ã‚‹ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ­£è¦åŒ–ï¼‰

        Args:
            comment: ã‚³ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
            files: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒªã‚¹ãƒˆ

        Returns:
            å†æ§‹ç¯‰ã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆ
        """
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æ­£è¦åŒ–ãƒ­ã‚¸ãƒƒã‚¯
        # ï¼ˆå®Ÿè£…ã®è©³ç´°ã¯çœç•¥ï¼‰
        return comment

    def format_final_comment(
        self,
        summary: str,
        chunk_analyses: List[str],
        files: List[FileChange],
        skipped_files: List[FileChange] = None
    ) -> str:
        """
        æœ€çµ‚çš„ãªPRã‚³ãƒ¡ãƒ³ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹

        Args:
            summary: ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ
            chunk_analyses: ãƒãƒ£ãƒ³ã‚¯åˆ†æçµæœ
            files: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãƒªã‚¹ãƒˆ
            skipped_files: ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ

        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæœ€çµ‚ã‚³ãƒ¡ãƒ³ãƒˆ
        """
        parts = [
            "# å¤‰æ›´å†…å®¹ã‚µãƒãƒªãƒ¼\n",
            summary,
            "\n\n",
            self.format_chunk_analyses(chunk_analyses),
            "\n\n",
            self.format_file_list(files)
        ]

        if skipped_files:
            parts.append(self.format_skipped_files_info(skipped_files))

        result = "".join(parts)
        return self.clean_markdown_format(result)
```

**è²¬å‹™**:
- Markdownãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
- ãƒãƒ£ãƒ³ã‚¯åˆ†æçµæœã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
- ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
- ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
- æœ€çµ‚ã‚³ãƒ¡ãƒ³ãƒˆã®çµ„ã¿ç«‹ã¦

**public API**:
- `clean_markdown_format(text: str) -> str`
- `format_chunk_analyses(analyses: List[str]) -> str`
- `format_file_list(files: List[FileChange]) -> str`
- `format_skipped_files_info(skipped_files: List[FileChange], reason: str) -> str`
- `format_final_comment(summary: str, chunk_analyses: List[str], files: List[FileChange], skipped_files: List[FileChange]) -> str`

#### 7.1.6 openai_integration.py

**ç›®çš„**: OpenAI APIã¨ã®çµ±åˆæ©Ÿèƒ½ã‚’æä¾›

```python
# openai_integration.py
import os
import time
import logging
from typing import List, Dict, Any, Optional, Tuple
from openai import OpenAI
from .models import PRInfo, FileChange
from .prompt_manager import PromptTemplateManager
from .token_estimator import TokenEstimator

class OpenAIIntegration:
    """OpenAI APIã¨ã®çµ±åˆã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    DEFAULT_MAX_RETRIES = 5
    DEFAULT_INITIAL_BACKOFF = 2
    DEFAULT_MAX_BACKOFF = 60

    def __init__(
        self,
        prompt_manager: PromptTemplateManager,
        token_estimator: TokenEstimator = None,
        retry_config: Dict[str, int] = None,
        logger: logging.Logger = None
    ):
        """
        åˆæœŸåŒ–

        Args:
            prompt_manager: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
            token_estimator: ãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šå™¨
            retry_config: ãƒªãƒˆãƒ©ã‚¤è¨­å®š
            logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        api_key = os.getenv('OPENAI_API_KEY')
        model_name = os.getenv('OPENAI_MODEL_NAME', 'gpt-4.1')

        if not api_key:
            raise ValueError("Missing required environment variable: OPENAI_API_KEY")

        self.model = model_name
        self.prompt_manager = prompt_manager
        self.token_estimator = token_estimator or TokenEstimator()
        self.logger = logger or logging.getLogger(__name__)

        self.retry_config = retry_config or {
            'max_retries': self.DEFAULT_MAX_RETRIES,
            'initial_backoff': self.DEFAULT_INITIAL_BACKOFF,
            'max_backoff': self.DEFAULT_MAX_BACKOFF
        }

        self.client = OpenAI(api_key=api_key)
        self.usage_stats = {
            'prompt_tokens': 0,
            'completion_tokens': 0,
            'retries': 0,
            'skipped_files': 0
        }

        self.pr_info = None  # å¾Œã§è¨­å®š

    def set_pr_info(self, pr_info: PRInfo):
        """PRæƒ…å ±ã‚’è¨­å®šã™ã‚‹"""
        self.pr_info = pr_info

    def analyze_chunk(
        self,
        chunk: List[FileChange],
        chunk_index: int
    ) -> str:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ£ãƒ³ã‚¯ã‚’åˆ†æã™ã‚‹

        Args:
            chunk: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã®ãƒãƒ£ãƒ³ã‚¯
            chunk_index: ãƒãƒ£ãƒ³ã‚¯ç•ªå·

        Returns:
            åˆ†æçµæœã®ãƒ†ã‚­ã‚¹ãƒˆ
        """
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆ
        prompt = self._build_chunk_analysis_prompt(chunk)

        # OpenAI APIã®å‘¼ã³å‡ºã—
        response = self._call_openai_api(prompt)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨çµæœã®ä¿å­˜
        self._save_prompt_and_result(prompt, response, chunk_index, "chunk")

        return response

    def generate_summary(
        self,
        chunk_analyses: List[str]
    ) -> str:
        """
        ãƒãƒ£ãƒ³ã‚¯åˆ†æçµæœã‹ã‚‰ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã™ã‚‹

        Args:
            chunk_analyses: ãƒãƒ£ãƒ³ã‚¯åˆ†æçµæœã®ãƒªã‚¹ãƒˆ

        Returns:
            ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ
        """
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆ
        prompt = self._build_summary_prompt(chunk_analyses)

        # OpenAI APIã®å‘¼ã³å‡ºã—
        response = self._call_openai_api(prompt)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨çµæœã®ä¿å­˜
        self._save_prompt_and_result(prompt, response, 0, "summary")

        return response

    def generate_title(self, summary: str) -> str:
        """
        ã‚µãƒãƒªãƒ¼ã‹ã‚‰PRã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹

        Args:
            summary: ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«
        """
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆ
        prompt = self._build_title_prompt(summary)

        # OpenAI APIã®å‘¼ã³å‡ºã—
        response = self._call_openai_api(prompt)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨çµæœã®ä¿å­˜
        self._save_prompt_and_result(prompt, response, 0, "title")

        return response.strip()

    def _build_chunk_analysis_prompt(self, chunk: List[FileChange]) -> str:
        """ãƒãƒ£ãƒ³ã‚¯åˆ†æç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹"""
        # å®Ÿè£…ã®è©³ç´°ï¼ˆçœç•¥ï¼‰
        base_prompt = self.prompt_manager.get_chunk_analysis_prompt()
        file_info = "\n".join([f"- {f.filename}: +{f.additions} -{f.deletions}" for f in chunk])
        return f"{base_prompt}\n\n{file_info}"

    def _build_summary_prompt(self, chunk_analyses: List[str]) -> str:
        """ã‚µãƒãƒªãƒ¼ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹"""
        # å®Ÿè£…ã®è©³ç´°ï¼ˆçœç•¥ï¼‰
        base_prompt = self.prompt_manager.get_summary_prompt()
        analyses = "\n\n".join(chunk_analyses)
        return f"{base_prompt}\n\n{analyses}"

    def _build_title_prompt(self, summary: str) -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹"""
        # å®Ÿè£…ã®è©³ç´°ï¼ˆçœç•¥ï¼‰
        return f"ä»¥ä¸‹ã®ã‚µãƒãƒªãƒ¼ã‹ã‚‰ç°¡æ½”ãªPRã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š\n\n{summary}"

    def _call_openai_api(self, prompt: str) -> str:
        """
        OpenAI APIã‚’å‘¼ã³å‡ºã™ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰

        Args:
            prompt: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ
        """
        retry_count = 0
        backoff = self.retry_config['initial_backoff']

        while retry_count < self.retry_config['max_retries']:
            try:
                response = self._make_api_request(prompt)
                return self._process_successful_response(response)

            except Exception as e:
                if self._is_rate_limit_error(e):
                    retry_count += 1
                    self.usage_stats['retries'] += 1
                    self._handle_rate_limit_error(e, retry_count, backoff)
                    backoff = min(backoff * 2, self.retry_config['max_backoff'])
                else:
                    self.logger.error(f"API call failed: {e}")
                    raise

        raise Exception(f"Max retries ({self.retry_config['max_retries']}) exceeded")

    def _make_api_request(self, prompt: str) -> Any:
        """å®Ÿéš›ã®API ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹"""
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ]
        )
        return response

    def _process_successful_response(self, response: Any) -> str:
        """æˆåŠŸã—ãŸAPIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†ã™ã‚‹"""
        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²
        self._record_token_usage(response)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        content = response.choices[0].message.content
        return content

    def _record_token_usage(self, response: Any):
        """ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²ã™ã‚‹"""
        usage = response.usage
        self.usage_stats['prompt_tokens'] += usage.prompt_tokens
        self.usage_stats['completion_tokens'] += usage.completion_tokens

    def _is_rate_limit_error(self, error: Exception) -> bool:
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹"""
        error_message = str(error).lower()
        return 'rate limit' in error_message or 'rate_limit' in error_message

    def _handle_rate_limit_error(self, error: Exception, retry_count: int, backoff: int):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ã™ã‚‹"""
        self.logger.warning(
            f"Rate limit error (attempt {retry_count}): {error}. "
            f"Retrying in {backoff} seconds..."
        )
        self._wait_before_retry(backoff)

    def _wait_before_retry(self, backoff: int):
        """ãƒªãƒˆãƒ©ã‚¤å‰ã«å¾…æ©Ÿã™ã‚‹"""
        time.sleep(backoff)

    def _save_prompt_and_result(
        self,
        prompt: str,
        result: str,
        chunk_index: int = 0,
        phase: str = "chunk"
    ):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãã®å®Ÿè¡Œçµæœã‚’ä¿å­˜ã™ã‚‹"""
        # ç’°å¢ƒå¤‰æ•°ã§è¨­å®šã‚’å–å¾—
        save_prompts = os.getenv('SAVE_PROMPTS', 'true').lower() == 'true'
        if not save_prompts:
            return

        # ä¿å­˜å‡¦ç†ï¼ˆå®Ÿè£…ã®è©³ç´°ã¯çœç•¥ï¼‰
        self.logger.info(f"Saved prompt and result for {phase} (chunk {chunk_index})")

    def get_usage_stats(self) -> Dict[str, int]:
        """ä½¿ç”¨çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹"""
        return {
            **self.usage_stats,
            'total_tokens': self.usage_stats['prompt_tokens'] + self.usage_stats['completion_tokens']
        }
```

**è²¬å‹™**:
- OpenAI APIã¨ã®é€šä¿¡
- ãƒªãƒˆãƒ©ã‚¤å‡¦ç†ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®è¨˜éŒ²
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨çµæœã®ä¿å­˜

**public API**:
- `set_pr_info(pr_info: PRInfo)`: PRæƒ…å ±ã®è¨­å®š
- `analyze_chunk(chunk: List[FileChange], chunk_index: int) -> str`: ãƒãƒ£ãƒ³ã‚¯åˆ†æ
- `generate_summary(chunk_analyses: List[str]) -> str`: ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
- `generate_title(summary: str) -> str`: ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
- `get_usage_stats() -> Dict[str, int]`: ä½¿ç”¨çµ±è¨ˆå–å¾—

#### 7.1.7 generator.py

**ç›®çš„**: ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã¨ã—ã¦å…¨ä½“ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼ã‚’åˆ¶å¾¡

```python
# generator.py
import json
import time
import logging
from typing import List, Tuple, Dict, Any
from .models import PRInfo, FileChange
from .statistics import PRCommentStatistics
from .formatter import CommentFormatter
from .openai_integration import OpenAIIntegration
from .prompt_manager import PromptTemplateManager
from .token_estimator import TokenEstimator

class PRCommentGenerator:
    """PRã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ï¼ˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼‰"""

    def __init__(
        self,
        template_dir: str = "templates",
        logger: logging.Logger = None
    ):
        """
        åˆæœŸåŒ–

        Args:
            template_dir: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
            logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.logger = logger or logging.getLogger(__name__)

        # ä¾å­˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–
        self.token_estimator = TokenEstimator(logger=self.logger)
        self.prompt_manager = PromptTemplateManager(template_dir=template_dir)
        self.statistics = PRCommentStatistics(
            token_estimator=self.token_estimator,
            logger=self.logger
        )
        self.formatter = CommentFormatter(logger=self.logger)
        self.openai_integration = OpenAIIntegration(
            prompt_manager=self.prompt_manager,
            token_estimator=self.token_estimator,
            logger=self.logger
        )

    def generate_comment(
        self,
        pr_info_path: str,
        diff_file_path: str
    ) -> Tuple[str, str, Dict[str, Any]]:
        """
        PRã‚³ãƒ¡ãƒ³ãƒˆã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹

        Args:
            pr_info_path: PRæƒ…å ±JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            diff_file_path: å·®åˆ†JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            (comment, title, metadata)ã®ã‚¿ãƒ—ãƒ«
        """
        start_time = time.time()

        try:
            # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼
            pr_info, files = self._load_and_validate_data(pr_info_path, diff_file_path)

            # PRæƒ…å ±ã‚’OpenAIçµ±åˆã«è¨­å®š
            self.openai_integration.set_pr_info(pr_info)

            # ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰å‡¦ç†
            processed_files, skipped_files = self._preprocess_file_changes(files)

            # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®è¨ˆç®—
            chunk_size = self.statistics.calculate_optimal_chunk_size(processed_files)

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
            chunks = self._split_into_chunks(processed_files, chunk_size)

            # å„ãƒãƒ£ãƒ³ã‚¯ã‚’åˆ†æ
            chunk_analyses = self._perform_chunk_analyses(chunks)

            # ã‚µãƒãƒªãƒ¼ã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
            summary, title = self._generate_summary_and_title(chunk_analyses)

            # æœ€çµ‚ã‚³ãƒ¡ãƒ³ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            comment = self.formatter.format_final_comment(
                summary=summary,
                chunk_analyses=chunk_analyses,
                files=processed_files,
                skipped_files=skipped_files
            )

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
            metadata = self._build_metadata(
                pr_info=pr_info,
                processed_files=processed_files,
                skipped_files=skipped_files,
                start_time=start_time
            )

            return comment, title, metadata

        except Exception as e:
            self.logger.error(f"Comment generation failed: {e}")
            raise

    def _load_and_validate_data(
        self,
        pr_info_path: str,
        diff_file_path: str
    ) -> Tuple[PRInfo, List[FileChange]]:
        """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§æ¤œè¨¼ã™ã‚‹"""
        # PRæƒ…å ±ã®èª­ã¿è¾¼ã¿
        with open(pr_info_path, 'r', encoding='utf-8') as f:
            pr_info_data = json.load(f)
        pr_info = PRInfo.from_json(pr_info_data)

        # å·®åˆ†æƒ…å ±ã®èª­ã¿è¾¼ã¿
        with open(diff_file_path, 'r', encoding='utf-8') as f:
            diff_data = json.load(f)
        files = [FileChange.from_json(f) for f in diff_data]

        self.logger.info(f"Loaded PR #{pr_info.number} with {len(files)} files")
        return pr_info, files

    def _preprocess_file_changes(
        self,
        files: List[FileChange]
    ) -> Tuple[List[FileChange], List[FileChange]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚’å‰å‡¦ç†ã™ã‚‹ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãªã©ï¼‰"""
        # å®Ÿè£…ã®è©³ç´°ï¼ˆçœç•¥ï¼‰
        # ä¾‹: å¤§ãã™ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—
        processed = []
        skipped = []

        for file in files:
            if self._should_skip_file(file):
                skipped.append(file)
            else:
                processed.append(file)

        self.logger.info(f"Processed {len(processed)} files, skipped {len(skipped)} files")
        return processed, skipped

    def _should_skip_file(self, file: FileChange) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã¹ãã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹"""
        # å®Ÿè£…ã®è©³ç´°ï¼ˆçœç•¥ï¼‰
        # ä¾‹: å¤‰æ›´è¡Œæ•°ãŒ1000è¡Œã‚’è¶…ãˆã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        return file.changes > 1000

    def _split_into_chunks(
        self,
        files: List[FileChange],
        chunk_size: int
    ) -> List[List[FileChange]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã™ã‚‹"""
        chunks = []
        for i in range(0, len(files), chunk_size):
            chunk = files[i:i + chunk_size]
            chunks.append(chunk)

        self.logger.info(f"Split {len(files)} files into {len(chunks)} chunks")
        return chunks

    def _perform_chunk_analyses(
        self,
        chunks: List[List[FileChange]]
    ) -> List[str]:
        """å„ãƒãƒ£ãƒ³ã‚¯ã‚’åˆ†æã™ã‚‹"""
        analyses = []
        for i, chunk in enumerate(chunks, 1):
            self.logger.info(f"Analyzing chunk {i}/{len(chunks)}")
            analysis = self.openai_integration.analyze_chunk(chunk, i)
            analyses.append(analysis)

        return analyses

    def _generate_summary_and_title(
        self,
        chunk_analyses: List[str]
    ) -> Tuple[str, str]:
        """ã‚µãƒãƒªãƒ¼ã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹"""
        self.logger.info("Generating summary...")
        summary = self.openai_integration.generate_summary(chunk_analyses)

        self.logger.info("Generating title...")
        title = self.openai_integration.generate_title(summary)

        return summary, title

    def _build_metadata(
        self,
        pr_info: PRInfo,
        processed_files: List[FileChange],
        skipped_files: List[FileChange],
        start_time: float
    ) -> Dict[str, Any]:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã™ã‚‹"""
        execution_time = time.time() - start_time
        usage_stats = self.openai_integration.get_usage_stats()
        file_stats = self.statistics.calculate_statistics(processed_files)

        return {
            'pr_number': pr_info.number,
            'file_count': len(processed_files) + len(skipped_files),
            'processed_file_count': len(processed_files),
            'skipped_file_count': len(skipped_files),
            'execution_time_seconds': round(execution_time, 2),
            'usage': usage_stats,
            'statistics': file_stats
        }
```

**è²¬å‹™**:
- å…¨ä½“ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®åˆ¶å¾¡ï¼ˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
- ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼
- ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰å‡¦ç†
- å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¸ã®å‡¦ç†å§”è­²
- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰

**public API**:
- `generate_comment(pr_info_path: str, diff_file_path: str) -> Tuple[str, str, Dict[str, Any]]`

#### 7.1.8 __init__.pyï¼ˆFacadeï¼‰

**ç›®çš„**: äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ã—ã¦æ—¢å­˜ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚’ã‚µãƒãƒ¼ãƒˆ

```python
# __init__.py
import warnings
from .models import PRInfo, FileChange
from .generator import PRCommentGenerator
from .statistics import PRCommentStatistics
from .formatter import CommentFormatter
from .openai_integration import OpenAIIntegration
from .prompt_manager import PromptTemplateManager
from .token_estimator import TokenEstimator

# éæ¨å¥¨è­¦å‘Šã‚’è¡¨ç¤º
def _show_deprecation_warning():
    """éæ¨å¥¨è­¦å‘Šã‚’è¡¨ç¤ºã™ã‚‹"""
    warnings.warn(
        "ç›´æ¥ 'from pr_comment_generator import ...' ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã¯éæ¨å¥¨ã§ã™ã€‚"
        "æ–°ã—ã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„:\n"
        "  from pr_comment_generator.generator import PRCommentGenerator\n"
        "  from pr_comment_generator.models import PRInfo, FileChange\n"
        "ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯å°†æ¥ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å‰Šé™¤ã•ã‚Œã‚‹äºˆå®šã§ã™ã€‚",
        DeprecationWarning,
        stacklevel=3
    )

# æ—§ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã®ã‚µãƒãƒ¼ãƒˆï¼ˆéæ¨å¥¨ï¼‰
_show_deprecation_warning()

# å…¬é–‹ã™ã‚‹API
__all__ = [
    'PRInfo',
    'FileChange',
    'PRCommentGenerator',
    'PRCommentStatistics',
    'CommentFormatter',
    'OpenAIIntegration',
    'PromptTemplateManager',
    'TokenEstimator'
]

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
__version__ = '2.0.0'
```

**è²¬å‹™**:
- æ—§ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã®å†ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
- éæ¨å¥¨è­¦å‘Šã®è¡¨ç¤º
- ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã®æä¾›

**public API**:
- ã™ã¹ã¦ã®ã‚¯ãƒ©ã‚¹ã‚’å†ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆéæ¨å¥¨ï¼‰

### 7.2 é–¢æ•°è¨­è¨ˆï¼ˆä¸»è¦ãªé–¢æ•°ã®ã¿ï¼‰

ä¸»è¦ãªé–¢æ•°ã®è¨­è¨ˆã¯ä¸Šè¨˜ã®ã‚¯ãƒ©ã‚¹è¨­è¨ˆã«å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚è¿½åŠ ã®é–¢æ•°è¨­è¨ˆã¯ä»¥ä¸‹ã®é€šã‚Šï¼š

#### 7.2.1 CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆpr_comment_generator.pyï¼‰

```python
# pr_comment_generator.pyï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œï¼‰
"""
PRã‚³ãƒ¡ãƒ³ãƒˆè‡ªå‹•ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™ã€‚
"""
import argparse
import json
import sys
import logging
from pr_comment_generator.generator import PRCommentGenerator

def setup_logging(log_level: str = "INFO"):
    """ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š"""
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

def parse_arguments():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹"""
    parser = argparse.ArgumentParser(description='PR Comment Generator')
    parser.add_argument('--pr-info', required=True, help='PRæƒ…å ±JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--pr-diff', required=True, help='PRå·®åˆ†JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--output', required=True, help='å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--template-dir', default='templates', help='ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹')
    parser.add_argument('--save-prompts', action='store_true', help='ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨çµæœã‚’ä¿å­˜')
    parser.add_argument('--prompt-output-dir', default='/prompts', help='ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--log-level', default='INFO', help='ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«')
    return parser.parse_args()

def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    # å¼•æ•°ã®ãƒ‘ãƒ¼ã‚¹
    args = parse_arguments()

    # ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
    setup_logging(args.log_level)
    logger = logging.getLogger(__name__)

    try:
        # PRã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆå™¨ã®åˆæœŸåŒ–
        generator = PRCommentGenerator(
            template_dir=args.template_dir,
            logger=logger
        )

        # ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
        logger.info("Starting PR comment generation...")
        comment, title, metadata = generator.generate_comment(
            pr_info_path=args.pr_info,
            diff_file_path=args.pr_diff
        )

        # çµæœã®ä¿å­˜
        output = {
            'comment': comment,
            'suggested_title': title,
            **metadata
        }

        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        logger.info(f"Comment generation completed. Output saved to {args.output}")
        return 0

    except Exception as e:
        logger.error(f"Comment generation failed: {e}", exc_info=True)
        return 1

if __name__ == '__main__':
    sys.exit(main())
```

### 7.3 ãƒ‡ãƒ¼ã‚¿æ§‹é€ è¨­è¨ˆ

ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¯ä¸Šè¨˜ã®`models.py`ã«å®šç¾©ã•ã‚Œã¦ã„ã¾ã™ï¼š

- **PRInfo**: PRæƒ…å ±ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€ç•ªå·ã€æœ¬æ–‡ã€ä½œè€…ã€ãƒ–ãƒ©ãƒ³ãƒã€SHAï¼‰
- **FileChange**: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æƒ…å ±ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã€è¿½åŠ è¡Œæ•°ã€å‰Šé™¤è¡Œæ•°ã€ãƒ‘ãƒƒãƒï¼‰

### 7.4 ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¨­è¨ˆ

#### ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

```mermaid
classDiagram
    class PRCommentGenerator {
        +generate_comment(pr_info_path, diff_file_path) Tuple~str, str, Dict~
    }

    class PRCommentStatistics {
        +calculate_optimal_chunk_size(files, max_tokens) int
        +estimate_chunk_tokens(chunk) int
        +calculate_statistics(files) Dict
    }

    class CommentFormatter {
        +clean_markdown_format(text) str
        +format_chunk_analyses(analyses) str
        +format_file_list(files) str
        +format_final_comment(summary, chunk_analyses, files, skipped_files) str
    }

    class OpenAIIntegration {
        +set_pr_info(pr_info)
        +analyze_chunk(chunk, chunk_index) str
        +generate_summary(chunk_analyses) str
        +generate_title(summary) str
        +get_usage_stats() Dict
    }

    class TokenEstimator {
        +estimate_tokens(text) int
        +truncate_text(text, max_tokens) str
    }

    class PromptTemplateManager {
        +get_base_prompt() str
        +get_chunk_analysis_prompt() str
        +get_summary_prompt() str
        +format_prompt(template_key, **kwargs) str
    }

    PRCommentGenerator --> PRCommentStatistics
    PRCommentGenerator --> CommentFormatter
    PRCommentGenerator --> OpenAIIntegration
    OpenAIIntegration --> PromptTemplateManager
    OpenAIIntegration --> TokenEstimator
    PRCommentStatistics --> TokenEstimator
```

---

## 8. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …

### 8.1 èªè¨¼ãƒ»èªå¯

**OpenAI APIã‚­ãƒ¼ã®ç®¡ç†**:
- ç’°å¢ƒå¤‰æ•°ï¼ˆ`OPENAI_API_KEY`ï¼‰ã‹ã‚‰å–å¾—
- ã‚³ãƒ¼ãƒ‰å†…ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ãªã„
- Jenkinsã®ã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ«ã‚¹ãƒˆã‚¢ã§ç®¡ç†

**GitHubèªè¨¼**:
- GitHub Appèªè¨¼ã¾ãŸã¯PATã‚’ä½¿ç”¨
- github_utils.pyã§ç®¡ç†ï¼ˆæœ¬ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã®å¯¾è±¡å¤–ï¼‰

### 8.2 ãƒ‡ãƒ¼ã‚¿ä¿è­·

**æ©Ÿå¯†æƒ…å ±ã®ãƒ­ã‚°å‡ºåŠ›**:
- APIã‚­ãƒ¼ã‚’ãƒ­ã‚°ã«å‡ºåŠ›ã—ãªã„
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿å­˜æ©Ÿèƒ½ã¯ç’°å¢ƒå¤‰æ•°ï¼ˆ`SAVE_PROMPTS`ï¼‰ã§åˆ¶å¾¡å¯èƒ½
- ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯é©åˆ‡ãªæ¨©é™ã§ä¿è­·

**å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼**:
- ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æ¤œè¨¼ï¼ˆãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«æ”»æ’ƒã®é˜²æ­¢ï¼‰
- JSONå…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼

### 8.3 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã¨å¯¾ç­–

**ãƒªã‚¹ã‚¯1: APIã‚­ãƒ¼ã®æ¼æ´©**
- **å¯¾ç­–**: ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹ç®¡ç†ã€ãƒ­ã‚°ã¸ã®å‡ºåŠ›ç¦æ­¢
- **å®Ÿè£…**: `os.getenv('OPENAI_API_KEY')`ã§å–å¾—

**ãƒªã‚¹ã‚¯2: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³**
- **å¯¾ç­–**: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
- **å®Ÿè£…**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§å›ºå®šéƒ¨åˆ†ã¨å¤‰æ•°éƒ¨åˆ†ã‚’åˆ†é›¢

**ãƒªã‚¹ã‚¯3: å¤§é‡ã®APIãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆã‚³ã‚¹ãƒˆï¼‰**
- **å¯¾ç­–**: ãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ¶é™ã€ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®æœ€é©åŒ–ã€ãƒªãƒˆãƒ©ã‚¤å›æ•°ã®åˆ¶é™
- **å®Ÿè£…**: `calculate_optimal_chunk_size`ã€`DEFAULT_MAX_RETRIES`

---

## 9. éæ©Ÿèƒ½è¦ä»¶ã¸ã®å¯¾å¿œ

### 9.1 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

**NFR-001-1: å®Ÿè¡Œæ™‚é–“ã®ç¶­æŒ**
- **è¦ä»¶**: ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å‰å¾Œã§å®Ÿè¡Œæ™‚é–“ã®å·®ãŒ10%ä»¥å†…
- **å¯¾å¿œ**:
  - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†å‰²ã«ã‚ˆã‚‹ä½™åˆ†ãªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’æœ€å°åŒ–
  - ä¾å­˜æ³¨å…¥ã«ã‚ˆã‚‹é…å»¶åˆæœŸåŒ–ã®å›é¿
  - æ¸¬å®š: `time.time()`ã§å®Ÿè¡Œæ™‚é–“ã‚’è¨˜éŒ²

**NFR-001-2: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ ã®ç¶­æŒ**
- **è¦ä»¶**: å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ 30ç§’ä»¥å†…
- **å¯¾å¿œ**:
  - OpenAI APIå‘¼ã³å‡ºã—å›æ•°ã¯å¤‰æ›´ãªã—
  - ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®æœ€é©åŒ–ã«ã‚ˆã‚Šç„¡é§„ãªAPIã‚³ãƒ¼ãƒ«ã‚’å‰Šæ¸›

### 9.2 ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£

**å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã®æ‹¡å¼µ**:
- ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã«ã‚ˆã‚Šã€å¤§é‡ã®ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã«ã‚‚å¯¾å¿œå¯èƒ½
- ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã«ã‚ˆã‚Šã€OpenAI APIã®åˆ¶ç´„å†…ã§å‹•ä½œ

**ä¸¦åˆ—å‡¦ç†ã®ä½™åœ°**:
- å°†æ¥çš„ã«`_perform_chunk_analyses`ã‚’ä¸¦åˆ—åŒ–å¯èƒ½
- å„ãƒãƒ£ãƒ³ã‚¯ã®åˆ†æã¯ç‹¬ç«‹ã—ã¦ã„ã‚‹ãŸã‚ã€`concurrent.futures`ã§ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½

### 9.3 ä¿å®ˆæ€§

**NFR-004-1: ã‚³ãƒ¼ãƒ‰ã®å¯èª­æ€§**
- **è¦ä»¶**: å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒ500è¡Œä»¥å†…ã€å„é–¢æ•°ãŒ50è¡Œä»¥å†…
- **å¯¾å¿œ**:
  - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†å‰²ã«ã‚ˆã‚Šã€å„ãƒ•ã‚¡ã‚¤ãƒ«ãŒ200-500è¡Œç¨‹åº¦
  - å„é–¢æ•°ãŒæ˜ç¢ºãªè²¬å‹™ã‚’æŒã¡ã€50è¡Œä»¥å†…

**NFR-004-2: ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸**
- **è¦ä»¶**: å…¨ä½“ã®ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ80%ä»¥ä¸Š
- **å¯¾å¿œ**:
  - ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã€çµ±åˆãƒ†ã‚¹ãƒˆã€BDDãƒ†ã‚¹ãƒˆã®å®Ÿè£…
  - `pytest-cov`ã§ã‚«ãƒãƒ¬ãƒƒã‚¸æ¸¬å®š

**NFR-004-3: ä¾å­˜é–¢ä¿‚ã®ç®¡ç†**
- **è¦ä»¶**: Dependency Injectionã€å¾ªç’°ä¾å­˜ã®å›é¿
- **å¯¾å¿œ**:
  - ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§ä¾å­˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ³¨å…¥
  - ãƒ¬ã‚¤ãƒ¤ãƒ¼æ§‹é€ ã«ã‚ˆã‚Šå¾ªç’°ä¾å­˜ã‚’æ’é™¤

---

## 10. å®Ÿè£…ã®é †åº

### Phase 1: ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£å±¤ï¼ˆ1é€±é–“ï¼‰

**ç›®çš„**: åŸºç›¤ã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚’å®Ÿè£…

**å®Ÿè£…é †åº**:
1. `models.py`ã®ä½œæˆï¼ˆPRInfoã€FileChangeï¼‰
2. `token_estimator.py`ã®ä½œæˆ
3. `prompt_manager.py`ã®ä½œæˆ
4. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã®ä½œæˆï¼ˆ`test_token_estimator.py`ã€`test_prompt_manager.py`ï¼‰

**å®Œäº†åˆ¤å®š**:
- [ ] ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ãŒæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã‹ã‚‰æ­£ã—ãæŠ½å‡ºã•ã‚Œã¦ã„ã‚‹
- [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆãŒã™ã¹ã¦æˆåŠŸ
- [ ] ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ80%ä»¥ä¸Š

### Phase 2: çµ±è¨ˆã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå±¤ï¼ˆ1é€±é–“ï¼‰

**ç›®çš„**: çµ±è¨ˆå‡¦ç†ã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†ã‚’åˆ†é›¢

**å®Ÿè£…é †åº**:
1. `statistics.py`ã®ä½œæˆï¼ˆPRCommentStatisticsï¼‰
2. `formatter.py`ã®ä½œæˆï¼ˆCommentFormatterï¼‰
3. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã®ä½œæˆï¼ˆ`test_statistics.py`ã€`test_formatter.py`ï¼‰

**å®Œäº†åˆ¤å®š**:
- [ ] çµ±è¨ˆè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ãŒæ­£ã—ãå‹•ä½œ
- [ ] ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡¦ç†ãŒæ­£ã—ãå‹•ä½œ
- [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆãŒã™ã¹ã¦æˆåŠŸ
- [ ] ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ80%ä»¥ä¸Š

### Phase 3: APIçµ±åˆå±¤ï¼ˆ1é€±é–“ï¼‰

**ç›®çš„**: OpenAI APIçµ±åˆã‚’åˆ†é›¢

**å®Ÿè£…é †åº**:
1. `openai_integration.py`ã®ä½œæˆï¼ˆOpenAIIntegrationï¼‰
2. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã®ä½œæˆï¼ˆ`test_openai_integration.py`ï¼‰
   - ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦APIã‚³ãƒ¼ãƒ«ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
   - ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆ

**å®Œäº†åˆ¤å®š**:
- [ ] APIå‘¼ã³å‡ºã—ãƒ­ã‚¸ãƒƒã‚¯ãŒæ­£ã—ãå‹•ä½œ
- [ ] ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ãŒæ­£ã—ãå‹•ä½œ
- [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆãŒã™ã¹ã¦æˆåŠŸï¼ˆãƒ¢ãƒƒã‚¯ä½¿ç”¨ï¼‰
- [ ] ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ80%ä»¥ä¸Š

### Phase 4: ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã¨äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆ1é€±é–“ï¼‰

**ç›®çš„**: ã‚³ã‚¢ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã¨äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å®Ÿè£…

**å®Ÿè£…é †åº**:
1. `generator.py`ã®ä½œæˆï¼ˆPRCommentGeneratorï¼‰
2. `__init__.py`ã®ä½œæˆï¼ˆFacadeï¼‰
3. `pr_comment_generator.py`ã®æ›´æ–°ï¼ˆCLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼‰
4. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã®ä½œæˆï¼ˆ`test_generator.py`ï¼‰
5. çµ±åˆãƒ†ã‚¹ãƒˆã®ä½œæˆï¼ˆ`test_generator_integration.py`ã€`test_compatibility_layer.py`ï¼‰
6. BDDãƒ†ã‚¹ãƒˆã®ä½œæˆï¼ˆ`test_bdd_pr_comment_generation.py`ï¼‰

**å®Œäº†åˆ¤å®š**:
- [ ] ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ãŒæ­£ã—ãå‹•ä½œ
- [ ] äº’æ›æ€§ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒæ­£ã—ãå‹•ä½œ
- [ ] ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ¦ãƒ‹ãƒƒãƒˆã€çµ±åˆã€BDDï¼‰ãŒæˆåŠŸ
- [ ] ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ80%ä»¥ä¸Š
- [ ] CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å®Ÿè¡Œå¯èƒ½

### Phase 5: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆã¨æœ€çµ‚æ¤œè¨¼ï¼ˆ0.5é€±é–“ï¼‰

**ç›®çš„**: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆã¨æœ€çµ‚æ¤œè¨¼

**å®Ÿè£…é †åº**:
1. APIä»•æ§˜æ›¸ã®ä½œæˆï¼ˆ`docs/api_specification.md`ï¼‰
2. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆå›³ã®ä½œæˆï¼ˆ`docs/module_architecture.md`ï¼‰
3. ç§»è¡Œã‚¬ã‚¤ãƒ‰ã®ä½œæˆï¼ˆ`docs/migration_guide.md`ï¼‰
4. README.mdã®æ›´æ–°
5. å›å¸°ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
6. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ

**å®Œäº†åˆ¤å®š**:
- [ ] ã™ã¹ã¦ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒä½œæˆã•ã‚Œã¦ã„ã‚‹
- [ ] å›å¸°ãƒ†ã‚¹ãƒˆãŒã™ã¹ã¦æˆåŠŸ
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã§å®Ÿè¡Œæ™‚é–“ã®å·®ãŒ10%ä»¥å†…
- [ ] Jenkinsfileã‹ã‚‰ã®å®Ÿè¡ŒãŒæ­£å¸¸ã«å‹•ä½œ

### å®Ÿè£…é †åºã®ä¾å­˜é–¢ä¿‚

```mermaid
gantt
    title ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Ÿè£…ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
    dateFormat  YYYY-MM-DD
    section Phase 1
    ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å±¤          :p1, 2025-01-20, 7d
    section Phase 2
    çµ±è¨ˆãƒ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå±¤    :p2, after p1, 7d
    section Phase 3
    APIçµ±åˆå±¤              :p3, after p2, 7d
    section Phase 4
    ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¤  :p4, after p3, 7d
    section Phase 5
    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»æ¤œè¨¼      :p5, after p4, 3d
```

---

## 11. å“è³ªã‚²ãƒ¼ãƒˆç¢ºèª

æœ¬è¨­è¨ˆæ›¸ã¯ã€Phase 2ã®å“è³ªã‚²ãƒ¼ãƒˆã‚’æº€ãŸã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ãŸï¼š

- [x] **å®Ÿè£…æˆ¦ç•¥ã®åˆ¤æ–­æ ¹æ‹ ãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹**: ã‚»ã‚¯ã‚·ãƒ§ãƒ³2ã§ã€ŒREFACTORã€ã‚’é¸æŠã—ã€4ã¤ã®å…·ä½“çš„ãªåˆ¤æ–­æ ¹æ‹ ã‚’è¨˜è¼‰
- [x] **ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã®åˆ¤æ–­æ ¹æ‹ ãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹**: ã‚»ã‚¯ã‚·ãƒ§ãƒ³3ã§ã€ŒALLã€ã‚’é¸æŠã—ã€4ã¤ã®å…·ä½“çš„ãªåˆ¤æ–­æ ¹æ‹ ã‚’è¨˜è¼‰
- [x] **ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰æˆ¦ç•¥ã®åˆ¤æ–­æ ¹æ‹ ãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹**: ã‚»ã‚¯ã‚·ãƒ§ãƒ³4ã§ã€ŒBOTH_TESTã€ã‚’é¸æŠã—ã€3ã¤ã®å…·ä½“çš„ãªåˆ¤æ–­æ ¹æ‹ ã‚’è¨˜è¼‰
- [x] **æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¸ã®å½±éŸ¿ç¯„å›²ãŒåˆ†æã•ã‚Œã¦ã„ã‚‹**: ã‚»ã‚¯ã‚·ãƒ§ãƒ³5ã§ã€ä¸»è¦ãªå½±éŸ¿ã€ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¸ã®å½±éŸ¿ã€ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¦å¦ã‚’è©³ç´°ã«åˆ†æ
- [x] **å¤‰æ›´ãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã•ã‚Œã¦ã„ã‚‹**: ã‚»ã‚¯ã‚·ãƒ§ãƒ³6ã§ã€æ–°è¦ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ22ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã€ä¿®æ­£ãŒå¿…è¦ãªæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ3ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’å…·ä½“çš„ã«ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
- [x] **è¨­è¨ˆãŒå®Ÿè£…å¯èƒ½ã§ã‚ã‚‹**: ã‚»ã‚¯ã‚·ãƒ§ãƒ³7ã§ã‚¯ãƒ©ã‚¹è¨­è¨ˆã€é–¢æ•°è¨­è¨ˆã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¨­è¨ˆã‚’è©³ç´°ã«è¨˜è¼‰ã—ã€å®Ÿè£…å¯èƒ½æ€§ã‚’ç¢ºä¿

---

## 12. æ‰¿èª

- **ä½œæˆè€…**: Claude Code
- **ä½œæˆæ—¥**: 2025å¹´1æœˆ
- **ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼**: ï¼ˆã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚·ãƒ³ã‚­ãƒ³ã‚°ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿæ–½å¾Œã«è¨˜è¼‰ï¼‰
- **æ‰¿èªæ—¥**: ï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼æ‰¿èªå¾Œã«è¨˜è¼‰ï¼‰

---

## ä»˜éŒ²A: ç”¨èªé›†

- **Facade ãƒ‘ã‚¿ãƒ¼ãƒ³**: è¤‡é›‘ãªã‚µãƒ–ã‚·ã‚¹ãƒ†ãƒ ã¸ã®çµ±ä¸€ã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›ã™ã‚‹è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³
- **Dependency Injection**: ä¾å­˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¤–éƒ¨ã‹ã‚‰æ³¨å…¥ã™ã‚‹è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³
- **ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: è¤‡æ•°ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å”èª¿å‹•ä½œã•ã›ã‚‹åˆ¶å¾¡å±¤
- **ãƒãƒ£ãƒ³ã‚¯**: ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€å®šã®ã‚µã‚¤ã‚ºã«åˆ†å‰²ã—ãŸå˜ä½
- **ãƒˆãƒ¼ã‚¯ãƒ³**: OpenAI APIã§ä½¿ç”¨ã•ã‚Œã‚‹èª²é‡‘å˜ä½ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®æ–­ç‰‡ï¼‰

## ä»˜éŒ²B: å‚è€ƒè³‡æ–™

- **Python PEP 8**: https://peps.python.org/pep-0008/
- **SOLIDåŸå‰‡**: https://en.wikipedia.org/wiki/SOLID
- **Clean Architecture**: https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html
- **Facade ãƒ‘ã‚¿ãƒ¼ãƒ³**: https://refactoring.guru/design-patterns/facade
- **Dependency Injection**: https://en.wikipedia.org/wiki/Dependency_injection
