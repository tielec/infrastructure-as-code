{"type":"thread.started","thread_id":"0199e816-d5a9-7d00-8341-7bb4f9281150"}
{"type":"turn.started"}
{"type":"item.started","item":{"id":"item_0","type":"command_execution","command":"bash -lc ls","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_0","type":"command_execution","command":"bash -lc ls","aggregated_output":"ARCHITECTURE.md\nCLAUDE.md\nCONTRIBUTION.md\nLICENSE\nREADME.md\nansible\nbootstrap\ndocs\njenkins\npulumi\nrun_tests_issue_322.sh\nscripts\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_1","type":"command_execution","command":"bash -lc \"sed -n '1,220p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_1","type":"command_execution","command":"bash -lc \"sed -n '1,220p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"@Library('jenkins-shared-lib') _\n\ndef regionList = []\ndef regionSummaries = [:]\ndef pipelineContext = [\n    metadataBasePath: \"/jenkins/${params.ENVIRONMENT}/backup\",\n]\n\nnode('ec2-fleet') {\n    timestamps {\n        def ssmHomeRegion = env.SSM_HOME_REGION ?: 'ap-northeast-1'\n        def workDirRelative = \"backup-work\"\n        def dataDirRelative = \"${workDirRelative}/data\"\n        def scriptDirRelative = \"${workDirRelative}/scripts\"\n        def workDir = \"${env.WORKSPACE}/${workDirRelative}\"\n        def dataDir = \"${env.WORKSPACE}/${dataDirRelative}\"\n        def scriptDir = \"${env.WORKSPACE}/${scriptDirRelative}\"\n        def envFilter = \"/${params.ENVIRONMENT}/\"\n        env.SSM_HOME_REGION = ssmHomeRegion\n        env.WORK_DIR = workDir\n        env.DATA_DIR = dataDir\n        env.SCRIPT_DIR = scriptDir\n        env.ENV_FILTER = envFilter\n\n        try {\n            stage('Initialize') {\n                env.BACKUP_DATE = sh(script: \"date '+%Y-%m-%d'\", returnStdout: true).trim()\n                env.BACKUP_TIMESTAMP = sh(script: \"date '+%Y%m%d_%H%M%S'\", returnStdout: true).trim()\n\n                sh \"\"\"\n                    rm -rf ${workDir}\n                    mkdir -p ${dataDir}\n                    mkdir -p ${scriptDir}\n                \"\"\"\n\n                def regionListJson = sh(\n                    script: \"\"\"\n                        aws ssm get-parameter \\\\\n                            --name \"${pipelineContext.metadataBasePath}/region-list\" \\\\\n                            --query 'Parameter.Value' \\\\\n                            --output text \\\\\n                            --region ${ssmHomeRegion} 2>/dev/null || echo \"\"\n                    \"\"\",\n                    returnStdout: true\n                ).trim()\n\n                if (!regionListJson?.trim()) {\n                    error(\"Region list parameter '${pipelineContext.metadataBasePath}/region-list' is missing or empty.\")\n                }\n\n                regionList = readJSON(text: regionListJson)\n                if (!(regionList instanceof List) || regionList.isEmpty()) {\n                    error(\"Region list is empty. Pulumi config must define at least one region.\")\n                }\n\n                regionList = regionList.collect { it.toString() }\n\n                def defaultRegionValue = sh(\n                    script: \"\"\"\n                        aws ssm get-parameter \\\\\n                            --name \"${pipelineContext.metadataBasePath}/default-region\" \\\\\n                            --query 'Parameter.Value' \\\\\n                            --output text \\\\\n                            --region ${ssmHomeRegion} 2>/dev/null || echo \"\"\n                    \"\"\",\n                    returnStdout: true\n                ).trim()\n\n                if (!defaultRegionValue) {\n                    error(\"Default region parameter '${pipelineContext.metadataBasePath}/default-region' is missing.\")\n                }\n\n                if (!regionList.contains(defaultRegionValue)) {\n                    error(\"Default region '${defaultRegionValue}' is not part of configured region list ${regionList}.\")\n                }\n\n                env.DEFAULT_REGION = defaultRegionValue\n\n                def legacyBucket = sh(\n                    script: \"\"\"\n                        aws ssm get-parameter \\\\\n                            --name \"${pipelineContext.metadataBasePath}/s3-bucket-name\" \\\\\n                            --query 'Parameter.Value' \\\\\n                            --output text \\\\\n                            --region ${ssmHomeRegion} 2>/dev/null || echo \"\"\n                    \"\"\",\n                    returnStdout: true\n                ).trim()\n\n                if (legacyBucket) {\n                    env.BACKUP_BUCKET = legacyBucket\n                }\n\n                currentBuild.displayName = \"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\"\n                currentBuild.description = \"Regions=${regionList.join(',')} | Default=${defaultRegionValue}\"\n\n                echo \"\"\"\n                =============================================\n                SSM Parameter Store Backup (Multi-Region)\n                =============================================\n                Environment      : ${params.ENVIRONMENT}\n                Regions          : ${regionList.join(', ')}\n                Default Region   : ${defaultRegionValue}\n                Dry Run          : ${params.DRY_RUN}\n                Backup Date      : ${env.BACKUP_DATE}\n                Timestamp        : ${env.BACKUP_TIMESTAMP}\n                SSM Home Region  : ${ssmHomeRegion}\n                Work Directory   : ${workDir}\n                =============================================\n                \"\"\".stripIndent()\n\n                env.REGION_LIST = regionList.join(',')\n                pipelineContext.timeoutMinutes = Math.max(regionList.size() * 10 + 30, 30)\n            }\n\n            timeout(time: pipelineContext.timeoutMinutes as int, unit: 'MINUTES') {\n                stage('Prepare Scripts') {\n                    sh \"rm -rf jenkins-repo\"\n                    dir('jenkins-repo') {\n                        checkout([\n                            $class: 'GitSCM',\n                            branches: [[name: \"${params.JENKINSFILE_BRANCH}\"]],\n                            userRemoteConfigs: [[\n                                url: 'https://github.com/tielec/infrastructure-as-code',\n                                credentialsId: 'github-app-credentials'\n                            ]]\n                        ])\n                    }\n\n                    sh \"\"\"\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${scriptDir}/\n                        chmod +x ${scriptDir}/collect_parameters.sh\n                        ls -la ${scriptDir}/\n                    \"\"\"\n                }\n\n                boolean dryRun = params.DRY_RUN as boolean\n\n                regionList.each { region ->\n                    stage(\"Backup ${region}\") {\n                        def ctx = loadRegionContext(\n                            params.ENVIRONMENT,\n                            region,\n                            pipelineContext.metadataBasePath,\n                            ssmHomeRegion,\n                            dataDir\n                        )\n\n                        def stageStart = System.currentTimeMillis()\n\n                        try {\n                            def result = runBackupForRegion(\n                                ctx + [\n                                    defaultRegion: env.DEFAULT_REGION,\n                                    scriptDir: scriptDir,\n                                    envFilter: env.ENV_FILTER,\n                                    backupDate: env.BACKUP_DATE,\n                                    backupTimestamp: env.BACKUP_TIMESTAMP,\n                                ],\n                                dryRun\n                            )\n\n                            def durationSeconds = ((System.currentTimeMillis() - stageStart) / 1000) as long\n\n                            regionSummaries[region] = [\n                                status          : 'SUCCESS',\n                                parameterCount  : result.parameterCount,\n                                bucket          : ctx.bucketName,\n                                s3Key           : result.s3Key,\n                                dryRun          : dryRun,\n                                durationSeconds : durationSeconds,\n                            ]\n\n                            echo \"Backup for ${region} completed (parameters=${result.parameterCount}, dryRun=${dryRun})\"\n                        } catch (Throwable t) {\n                            def durationSeconds = ((System.currentTimeMillis() - stageStart) / 1000) as long\n                            regionSummaries[region] = [\n                                status          : 'FAILED',\n                                message         : t.getMessage(),\n                                durationSeconds : durationSeconds,\n                            ]\n                            throw t\n                        }\n                    }\n                }\n\n                stage('Finalize Report') {\n                    def summaryFile = \"${workDirRelative}/region_summaries.json\"\n                    writeJSON file: summaryFile, json: regionSummaries, pretty: 4\n                    archiveArtifacts artifacts: summaryFile, fingerprint: true\n                    env.REGION_SUMMARY_PATH = \"${workDir}/${summaryFile.split('/', 2).last()}\"\n                    echo \"Region summary stored at ${summaryFile}\"\n                }\n            }\n\n            currentBuild.result = currentBuild.result ?: 'SUCCESS'\n        } catch (Throwable err) {\n            currentBuild.result = currentBuild.result ?: 'FAILURE'\n            throw err\n        } finally {\n            stage('Post Actions') {\n                emitRunSummary(regionSummaries, params.ENVIRONMENT, params.DRY_RUN as boolean)\n                if (currentBuild.result == 'SUCCESS') {\n                    echo \"✅ SSMパラメータのバックアップが正常に完了しました\"\n                } else if (currentBuild.result == 'UNSTABLE') {\n                    echo \"⚠️ バックアップは完了しましたが、警告があります\"\n                } else {\n                    echo \"❌ バックアップが失敗しました。ログを確認してください\"\n                }\n\n                sh \"rm -rf ${workDir} jenkins-repo || true\"\n            }\n        }\n    }\n}\n\ndef loadRegionContext(String environment, String region, String metadataBasePath, String ssmHomeRegion, String dataDirRoot) {\n    def parameterName = \"${metadataBasePath}/${region}/s3-bucket-name\"\n    def bucketName = sh(\n        script: \"\"\"\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_2","type":"command_execution","command":"bash -lc \"sed -n '220,480p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_2","type":"command_execution","command":"bash -lc \"sed -n '220,480p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"        script: \"\"\"\n            aws ssm get-parameter \\\\\n                --name \"${parameterName}\" \\\\\n                --query 'Parameter.Value' \\\\\n                --output text \\\\\n                --region ${ssmHomeRegion} 2>/dev/null || echo \"\"\n        \"\"\",\n        returnStdout: true\n    ).trim()\n\n    if (!bucketName) {\n        error(\"Bucket definition missing for region ${region}. Expected SSM parameter ${parameterName}.\")\n    }\n\n    def regionDataDir = \"${dataDirRoot}/${region}\"\n    sh \"\"\"\n        rm -rf ${regionDataDir}\n        mkdir -p ${regionDataDir}\n    \"\"\"\n\n    return [\n        environment   : environment,\n        region        : region,\n        bucketName    : bucketName,\n        regionDataDir : regionDataDir,\n    ]\n}\n\ndef runBackupForRegion(Map ctx, boolean dryRun) {\n    def envFilter = ctx.envFilter\n    def scriptDir = ctx.scriptDir\n    def backupDate = ctx.backupDate\n    def backupTimestamp = ctx.backupTimestamp\n    def environment = ctx.environment\n    def region = ctx.region\n    def regionDataDir = ctx.regionDataDir\n    def bucketName = ctx.bucketName\n    def defaultRegion = ctx.defaultRegion\n\n    def backupJsonPath = \"${regionDataDir}/backup.json\"\n    def backupFileName = \"ssm-backup-${environment}-${region}-${backupTimestamp}.json\"\n    def backupFilePath = \"${regionDataDir}/${backupFileName}\"\n    def s3Key = \"${backupDate}/${region}/${backupFileName}\"\n\n    withEnv([\n        \"ENVIRONMENT=${environment}\",\n        \"ENV_FILTER=${envFilter}\",\n        \"AWS_REGION=${region}\",\n        \"BACKUP_DATE=${backupDate}\",\n        \"BACKUP_TIMESTAMP=${backupTimestamp}\",\n        \"DATA_DIR=${regionDataDir}\",\n        \"TARGET_REGION=${region}\",\n    ]) {\n        sh \"\"\"\n            rm -f ${regionDataDir}/*\n            ${scriptDir}/collect_parameters.sh\n        \"\"\"\n    }\n\n    if (!fileExists(backupJsonPath)) {\n        error(\"Backup file was not created for region ${region}.\")\n    }\n\n    sh \"cp ${backupJsonPath} ${backupFilePath}\"\n\n    def backupData = readJSON file: backupJsonPath\n    def parameterCount = (backupData.parameter_count ?: backupData.parameterCount ?: 0) as int\n\n    def summaryPath = \"${regionDataDir}/summary.json\"\n    writeJSON file: summaryPath, json: [\n        region         : region,\n        parameterCount : parameterCount,\n        s3Key          : s3Key,\n        dryRun         : dryRun,\n    ], pretty: 4\n\n    if (!dryRun && parameterCount > 0) {\n        sh \"\"\"\n            aws s3 cp ${backupFilePath} \\\n                s3://${bucketName}/${s3Key} \\\n                --sse AES256 \\\n                --region ${region}\n        \"\"\"\n\n        sh \"\"\"\n            echo '${s3Key}' | aws s3 cp - s3://${bucketName}/latest-${region}.txt \\\n                --sse AES256 \\\n                --region ${region}\n        \"\"\"\n\n        if (region == defaultRegion) {\n            sh \"\"\"\n                echo '${s3Key}' | aws s3 cp - s3://${bucketName}/latest.txt \\\n                    --sse AES256 \\\n                    --region ${region}\n            \"\"\"\n        }\n\n        def objectInfo = sh(\n            script: \"\"\"\n                aws s3api head-object \\\\\n                    --bucket ${bucketName} \\\\\n                    --key ${s3Key} \\\\\n                    --query '[ContentLength, LastModified]' \\\\\n                    --output text \\\\\n                    --region ${region}\n            \"\"\",\n            returnStdout: true\n        ).trim()\n\n        echo \"S3 Object Info [${region}]: ${objectInfo}\"\n    } else if (dryRun) {\n        echo \"[DRY RUN] Skipped S3 upload for ${region}. Planned key: ${s3Key}\"\n    } else {\n        echo \"No parameters to upload for ${region}. Skipping S3 upload.\"\n    }\n\n    return [\n        parameterCount : parameterCount,\n        s3Key          : s3Key,\n        backupFilePath : backupFilePath,\n        summaryPath    : summaryPath,\n    ]\n}\n\ndef emitRunSummary(Map regionSummaries, String environment, boolean dryRun) {\n    echo \"\"\"\n    =============================================\n    SSM Parameter Store Backup Summary\n    =============================================\n    Build       : #${env.BUILD_NUMBER}\n    Status      : ${currentBuild.result ?: 'UNKNOWN'}\n    Environment : ${environment}\n    Dry Run     : ${dryRun}\n    Regions     : ${env.REGION_LIST ?: 'N/A'}\n    Summary File: ${env.REGION_SUMMARY_PATH ?: 'N/A'}\n    =============================================\n    \"\"\".stripIndent()\n\n    regionSummaries.each { region, summary ->\n        echo \"Region: ${region} => ${summary}\"\n    }\n}\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_3","type":"command_execution","command":"bash -lc \"sed -n '1,200p' .ai-workflow/issue-391/02_design/output/design.md\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_3","type":"command_execution","command":"bash -lc \"sed -n '1,200p' .ai-workflow/issue-391/02_design/output/design.md\"","aggregated_output":"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\n\n## 1. アーキテクチャ設計\n\n### 1.1 システム全体図\n```mermaid\nflowchart TD\n    subgraph Jenkins[\"Jenkins (CI)\"]\n        DSL[\"Groovy DSL\\nadmin_ssm_backup_job.groovy\"]\n        Pipeline[\"Scripted Pipeline\\nJenkinsfile\"]\n        Script[\"collect_parameters.sh\"]\n    end\n\n    subgraph AWS[\"AWS Account\"]\n        SSM[\"SSM Parameter Store\\n(env-scoped metadata)\"]\n        subgraph Regions[\"対象リージョン (config-driven)\"]\n            BucketA[\"S3 Backup Bucket\\n(ap-northeast-1)\"]\n            BucketB[\"S3 Backup Bucket\\n(us-west-2)\"]\n            BucketC[\"S3 Backup Bucket\\n(... more)\"]\n        end\n    end\n\n    subgraph Pulumi[\"Pulumi Stack (TypeScript)\"]\n        Config[\"Pulumi Config\\n(project/env/regions)\"]\n        IaC[\"index.ts\\nmulti-region resource factory\"]\n        Tests[\"Jest-based unit tests\"]\n    end\n\n    DSL -->|SCM sync| Pipeline\n    Pipeline -->|fetch| Script\n    Pipeline -->|Read config & region list| SSM\n    Pipeline -->|Loop regions\\ninvoke AWS CLI| BucketA\n    Pipeline --> BucketB\n    Pipeline --> BucketC\n    Pulumi -->|pulumi up| Regions\n    Pulumi -->|write bucket metadata\\n& region list| SSM\n    Tests --> IaC\n```\n\n### 1.2 コンポーネント間の関係\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\n\n### 1.3 データフロー\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\"Backup ${region}\")` を生成し、各ステージ内で\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\n\n## 2. 実装戦略: EXTEND\n\n**判断根拠**:\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\n\n## 3. テスト戦略: UNIT_INTEGRATION\n\n**判断根拠**:\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\n\n## 4. テストコード戦略: CREATE_TEST\n\n**判断根拠**:\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\n\n## 5. 影響範囲分析\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\n\n## 6. 変更・追加ファイルリスト\n| 区分 | ファイル/パス | 目的 |\n| ---- | ------------- | ---- |\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\n\n## 7. 詳細設計\n\n### 7.1 Pulumi (IaC) 詳細\n- **Config インターフェース**  \n  ```yaml\n  # Pulumi.<stack>.yaml\n  config:\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\n    jenkins-ssm-backup-s3:environment: dev\n    jenkins-ssm-backup-s3:regions:\n      - ap-northeast-1\n      - us-west-2\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\n  ```\n- **主要関数設計**\n  | 関数/スコープ | 役割 |\n  | ------------- | ---- |\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\n- **命名規則／タグ**  \n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\n- **プロバイダー管理**  \n  `const provider = new aws.Provider(\\`region-${region}\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\n- **非同期処理**  \n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\n- **エクスポート**  \n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\n\n### 7.2 Jenkins Pipeline 詳細\n- **パイプライン方式**\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\"Backup ${region}\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\n- **グローバル変数**\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \"${env.DATA_DIR}/${region}\"` を付与。\n- **リージョンコンテキスト取得**\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\"Bucket definition missing for ${region}\")`。\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\n- **ステージ構成**\n  1. `stage('Initialize')`\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\n  2. `stage('Prepare Scripts')`\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\n  3. `for (region in regionList) { stage(\"Backup ${region}\") { ... } }`\n     - `withEnv([\"TARGET_REGION=${region}\", \"AWS_REGION=${region}\", \"REGION_DATA_DIR=${env.DATA_DIR}/${region}\"])` で環境を切り替え。\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \"[DRY RUN] Skipped upload for ${region}\"` のみ出力。\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\n  4. `stage('Finalize Report')`\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\n- **エラー制御**\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\n- **メトリクス／ログ**\n  - `collect_parameters.sh` は `summary.json` に `{\"parameterCount\": 123, \"executionTimeSec\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\n\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\n\n### 7.4 `collect_parameters.sh`\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\n\n### 7.5 テスト設計詳細\n- **Pulumi (Jest)**  \n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\"ap-northeast-1\", \"us-west-2\"]` を与えて `require(\"../index\")`。  \n  - 期待事項:  \n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \n    - `bucketMap` エクスポートが全リージョンを包含。\n- **Jenkins (jenkinsfile-runner)**  \n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \n  - 検証点:  \n    - Scripted Pipeline がリージョン配列から `stage(\"Backup ${region}\")` を順次生成する。  \n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\n- **Manual テスト**  \n  - `pulumi preview` で各リージョンの差分を確認。  \n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\n\n### 7.6 トレーサビリティ\n| 要件ID | 設計上の対応箇所 |\n| ------ | ---------------- |\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_4","type":"command_execution","command":"bash -lc 'rg \"7.7\" -n .ai-workflow/issue-391/02_design/output/design.md'","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_4","type":"command_execution","command":"bash -lc 'rg \"7.7\" -n .ai-workflow/issue-391/02_design/output/design.md'","aggregated_output":"bash: line 1: rg: command not found\n","exit_code":127,"status":"failed"}}
{"type":"item.started","item":{"id":"item_5","type":"command_execution","command":"bash -lc 'grep -n \"7.7\" -n .ai-workflow/issue-391/02_design/output/design.md'","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_5","type":"command_execution","command":"bash -lc 'grep -n \"7.7\" -n .ai-workflow/issue-391/02_design/output/design.md'","aggregated_output":"54:5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\n200:| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\n202:### 7.7 通知計画 (FR-5)\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_6","type":"command_execution","command":"bash -lc \"sed -n '202,260p' .ai-workflow/issue-391/02_design/output/design.md\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_6","type":"command_execution","command":"bash -lc \"sed -n '202,260p' .ai-workflow/issue-391/02_design/output/design.md\"","aggregated_output":"### 7.7 通知計画 (FR-5)\n- **対象者**  \n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \n  - CLI 経由でバックアップ結果を参照する開発チーム  \n- **チャネル**  \n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \n- **タイミング**  \n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \n- **責任者**  \n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \n- **テスト/検証**  \n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \n- **Runbook 更新**  \n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\n\n## 8. セキュリティ考慮事項\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\n\n## 9. 非機能要件への対応\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\n\n## 10. 実装の順序\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\n\n---\n\n### 品質ゲート確認\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\n- ✅ 既存コードへの影響範囲を分析\n- ✅ 必要な変更ファイルをリストアップ\n- ✅ 実装手順と詳細設計で実現可能性を担保\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_7","type":"command_execution","command":"bash -lc \"sed -n '1,200p' docs/runbooks/ssm-backup.md\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_7","type":"command_execution","command":"bash -lc \"sed -n '1,200p' docs/runbooks/ssm-backup.md\"","aggregated_output":"# SSM Parameter Store Backup Runbook\n\n## 概要\n- 対象ジョブ: `Admin_Jobs/admin_ssm_backup_job`\n- 目的: Pulumi が生成した各リージョンの S3 バケットへ、SSM Parameter Store の内容を暗号化した JSON として日次バックアップする。\n- リージョン構成: Pulumi Config (`pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml`) の `regions` 配列に従い動的に決定。\n- メタデータ保管: `/jenkins/<env>/backup/` プレフィックスの SSM パラメータ（`region-list`, `default-region`, `s3-bucket-name`, `<region>/s3-bucket-name`）。\n\n## 運用手順\n1. Jenkins ジョブが自動実行（毎日 JST 22:00）。開始時に `Initialize` ステージでリージョン一覧とデフォルトリージョンを SSM から取得。\n2. `Backup <region>` ステージがリージョンごとに逐次実行され、`collect_parameters.sh` を用いて SSM パラメータを収集。\n3. 取得した JSON は `s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json` にアップロードされ、`latest-<region>.txt`（デフォルトリージョンは互換用に `latest.txt` も更新）を発行。\n4. 実行結果は `backup-work/region_summaries.json` に出力され、アーティファクトとして保存。Slack/メール通知には同ファイルの要約を添付。\n\n## リージョン追加・削除手順\n1. `pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml` の `regions` 配列を更新し、`defaultRegion` と `ssmHomeRegion` を必要に応じて調整。\n2. Pulumi スタックディレクトリで `npm install`（依存未導入時）後、`npm run build` → `pulumi preview` を実施し差分を確認。\n3. 変更内容をレビュー後、`pulumi up` を本番／ステージング順に適用。\n4. Jenkins ジョブをドライラン（`DRY_RUN=true`）で実行し、`Backup <region>` ステージが追加リージョンを認識することを確認。\n5. 運用チームへ Slack `#infra-announcements` でリージョン変更点と実施日時を共有。\n\n## ロールバック手順\n1. Pulumi Config を直前のコミットへ戻し `pulumi up` を実行。不要になった S3 バケットと SSM パラメータが削除されることを `pulumi preview` で確認。\n2. Jenkins ジョブを手動実行し、`region_summaries.json` に旧構成のみが記録されることを確認。\n3. 影響が大きい場合は Runbook の通知テンプレートを利用し、CLI 利用者とオンコール SRE へ速やかに連絡。\n\n## 監視・通知\n- 成功時: Slack `#infra-backup-alerts` にリージョン別件数・処理時間を通知。メール `ops-alerts@example.com` に同内容のサマリーを送付。\n- 失敗時: 失敗リージョンの `message` が通知ペイロードに含まれる。30 分以内に一次報告、復旧後 1 営業日以内に事後報告を行う。\n- 参照ログ: Jenkins 実行ログ・`backup-work/region_summaries.json`・S3 バケットの `latest-<region>.txt`。\n\n## トラブルシューティング\n| 症状 | 対処 |\n| ---- | ---- |\n| `Region list parameter ... is missing` | Pulumi スタックが未適用。`pulumi config get regions` と SSM の `/backup/region-list` を確認。 |\n| `Bucket definition missing for region` | `/backup/<region>/s3-bucket-name` の作成漏れ。Pulumi Config のリージョン一覧と SSM を照合。 |\n| `Backup file was not created` | `collect_parameters.sh` の AWS 認証／フィルタ設定を確認。`DATA_DIR/<region>` に生成物があるか検証。 |\n| S3 アップロードに失敗 | `aws s3 cp` コマンドのエラー詳細をログで確認。IAM 権限またはリージョン設定を見直し。 |\n\n## 参考コマンド\n```bash\n# Pulumi Stack でリージョンを確認\npulumi config get regions --path --stack <env>\n\n# Jenkins アーティファクトからサマリーを取得\naws s3 cp s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json ./\n```\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_8","type":"command_execution","command":"bash -lc \"sed -n '1,220p' jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_8","type":"command_execution","command":"bash -lc \"sed -n '1,220p' jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\"","aggregated_output":"#!/bin/bash\n# SSM Parameter Collection and Backup Script\n# SSMパラメータを収集してバックアップファイルを作成\n# \n# 使用方法:\n#   このスクリプトは環境変数を通じて設定を受け取ります\n#   必須環境変数:\n#     - ENVIRONMENT: バックアップ対象の環境 (dev/prod)\n#     - ENV_FILTER: パラメータフィルタ文字列 (/dev/, /prod/)\n#     - AWS_REGION: AWSリージョン\n#     - BACKUP_DATE: バックアップ日付 (YYYY-MM-DD)\n#     - BACKUP_TIMESTAMP: バックアップタイムスタンプ\n#     - DATA_DIR: データ出力ディレクトリ\n#\n# 戻り値:\n#   0: 正常終了\n#   1: エラー発生\n\nset -euo pipefail\n\necho \"======================================\"\necho \"SSM Parameter Collection Script\"\necho \"======================================\"\necho \"Environment: ${ENVIRONMENT}\"\necho \"Filter: ${ENV_FILTER}\"\necho \"Region: ${AWS_REGION}\"\necho \"Backup Date: ${BACKUP_DATE}\"\necho \"Backup Timestamp: ${BACKUP_TIMESTAMP}\"\necho \"Target Region: ${AWS_REGION}\"\necho \"======================================\"\n\nmkdir -p \"${DATA_DIR}\"\nrm -f \"${DATA_DIR}/\"*\n\n# AWS認証情報の確認\necho \"Checking AWS credentials...\"\nif ! aws sts get-caller-identity --region ${AWS_REGION}; then\n    echo \"Error: Failed to get AWS credentials. Please check IAM role or credentials.\"\n    exit 1\nfi\necho \"AWS credentials verified.\"\n\n# AWS API呼び出しのリトライ機能\naws_cli_with_retry() {\n    local max_retries=5\n    local retry_delay=3  # 初期待機時間を長めに設定\n    local retry_count=0\n    \n    while [ $retry_count -lt $max_retries ]; do\n        # AWS CLIを実行（環境変数で制御）\n        if output=$(AWS_PAGER=\"\" AWS_CLI_AUTO_PROMPT=off \"$@\" 2>&1); then\n            echo \"$output\"\n            return 0\n        else\n            if echo \"$output\" | grep -q \"ThrottlingException\\|Rate exceeded\"; then\n                retry_count=$((retry_count + 1))\n                echo \"  Rate limit hit. Retry ${retry_count}/${max_retries} after ${retry_delay}s...\" >&2\n                sleep $retry_delay\n                retry_delay=$((retry_delay * 2))  # Exponential backoff\n                if [ $retry_delay -gt 60 ]; then\n                    retry_delay=60  # Max delay 60s\n                fi\n            else\n                echo \"Error: $output\" >&2\n                return 1\n            fi\n        fi\n    done\n    \n    echo \"Error: Max retries reached\" >&2\n    return 1\n}\n\n# パラメータ一覧の取得（ページネーション対応、フィルタリング最適化）\nfetch_all_parameters() {\n    local next_token=\"\"\n    local page=1\n    local all_params=\"[]\"\n    \n    # 初回実行前に待機（レート制限対策）\n    echo \"Waiting 2 seconds before API calls to avoid rate limiting...\" >&2\n    sleep 2\n    \n    while true; do\n        echo \"Fetching page ${page}...\" >&2\n        \n        # AWS CLIコマンドの実行とエラーハンドリング\n        local result\n        local error_msg\n        \n        if [ -n \"$next_token\" ]; then\n            echo \"  Executing: aws ssm describe-parameters with filter --region ${AWS_REGION}\" >&2\n            # パラメータフィルタの値を変数に格納\n            local filter_value=\"${ENV_FILTER:1:-1}\"  # /dev/ -> dev\n            # リトライ機能を使用（--next-tokenを使用）\n            if ! result=$(aws_cli_with_retry aws ssm describe-parameters \\\n                --next-token \"$next_token\" \\\n                --max-results 50 \\\n                --parameter-filters \"Key=Name,Option=Contains,Values=$filter_value\" \\\n                --output json \\\n                --region ${AWS_REGION}); then\n                echo \"Error: Failed to describe parameters\" >&2\n                echo '{\"Parameters\": [], \"NextToken\": null}'\n                return 1\n            fi\n        else\n            echo \"  Executing: aws ssm describe-parameters with filter --region ${AWS_REGION}\" >&2\n            # パラメータフィルタの値を変数に格納\n            local filter_value=\"${ENV_FILTER:1:-1}\"  # /dev/ -> dev\n            # リトライ機能を使用\n            if ! result=$(aws_cli_with_retry aws ssm describe-parameters \\\n                --max-results 50 \\\n                --parameter-filters \"Key=Name,Option=Contains,Values=$filter_value\" \\\n                --output json \\\n                --region ${AWS_REGION}); then\n                echo \"Error: Failed to describe parameters\" >&2\n                echo '{\"Parameters\": [], \"NextToken\": null}'\n                return 1\n            fi\n        fi\n        \n        # 結果が空またはエラーメッセージの場合の処理\n        if [ -z \"$result\" ]; then\n            echo \"Warning: Empty response received\" >&2\n            result='{\"Parameters\": [], \"NextToken\": null}'\n        elif ! echo \"$result\" | jq empty 2>/dev/null; then\n            echo \"Warning: Invalid JSON response: ${result:0:100}...\" >&2\n            result='{\"Parameters\": [], \"NextToken\": null}'\n        fi\n        \n        # デバッグ: パラメータ数を表示\n        local param_count=$(echo \"$result\" | jq '.Parameters | length' 2>/dev/null || echo \"0\")\n        echo \"  Found ${param_count} parameters on page ${page}\" >&2\n        \n        # パラメータを追加\n        local params\n        if params=$(echo \"$result\" | jq '.Parameters // []' 2>/dev/null); then\n            if [ \"$params\" != \"null\" ] && [ \"$params\" != \"[]\" ] && [ -n \"$params\" ]; then\n                all_params=$(echo \"$all_params\" | jq --argjson new_params \"$params\" '. + $new_params')\n                echo \"  Total accumulated parameters: $(echo \"$all_params\" | jq 'length')\" >&2\n            fi\n        else\n            echo \"Warning: Failed to parse parameters from response\" >&2\n        fi\n        \n        # 次のトークンを確認（NextTokenフィールドを直接参照）\n        next_token=$(echo \"$result\" | jq -r '.NextToken // empty' 2>/dev/null || echo \"\")\n        \n        if [ -z \"$next_token\" ]; then\n            break\n        fi\n        \n        page=$((page + 1))\n        \n        # APIレート制限対策（ページ間の待機時間を長めに）\n        sleep 2\n    done\n    \n    echo \"$all_params\"\n}\n\n# メイン処理\necho \"Starting parameter collection...\"\n\n# AWS CLIのページネーション設定を無効化\nexport AWS_PAGER=\"\"\n\n# フィルタリングされたパラメータを取得（API側でフィルタリング済み）\nFILTERED_PARAMS=$(fetch_all_parameters)\nif [ $? -ne 0 ] || [ -z \"$FILTERED_PARAMS\" ]; then\n    echo \"Warning: fetch_all_parameters failed or returned empty\" >&2\n    FILTERED_PARAMS='[]'\nfi\n\n# JSONの検証\nif ! echo \"$FILTERED_PARAMS\" | jq empty 2>/dev/null; then\n    echo \"Warning: Invalid JSON received from fetch_all_parameters\" >&2\n    echo \"Received data (first 200 chars): ${FILTERED_PARAMS:0:200}\" >&2\n    FILTERED_PARAMS='[]'\nfi\n\nPARAM_COUNT=$(echo \"$FILTERED_PARAMS\" | jq 'length' 2>/dev/null || echo \"0\")\necho \"Found ${PARAM_COUNT} parameters for environment ${ENVIRONMENT}\"\n\nif [ \"$PARAM_COUNT\" = \"0\" ]; then\n    echo \"WARNING: No parameters found matching filter '${ENV_FILTER}'\"\n    # 空のバックアップファイルを作成\n    jq -n \\\n        --arg date \"${BACKUP_DATE}\" \\\n        --arg timestamp \"${BACKUP_TIMESTAMP}\" \\\n        --arg environment \"${ENVIRONMENT}\" \\\n        '{\n            backup_date: $date,\n            backup_timestamp: $timestamp,\n            environment: $environment,\n            parameter_count: 0,\n            parameters: []\n        }' > ${DATA_DIR}/backup.json\n    exit 0\nfi\n\n# パラメータ名の一覧を保存\necho \"$FILTERED_PARAMS\" | jq -r '.[].Name' > ${DATA_DIR}/parameter_names.txt\n\n# パラメータ取得前に待機（レート制限対策）\necho \"Waiting before fetching parameter values...\"\nsleep 2\n\n# パラメータを取得してバックアップデータを作成（バッチ処理で高速化）\necho \"Fetching parameter values...\"\nBACKUP_DATA=\"[]\"\nBATCH_SIZE=10  # AWS APIの制限により最大10個\nFAILED_COUNT=0\nFAILED_PARAMS=()\n\n# パラメータ名を配列に読み込み\nmapfile -t PARAM_NAMES < ${DATA_DIR}/parameter_names.txt\nTOTAL_PARAMS=${#PARAM_NAMES[@]}\n\n# バッチ処理でパラメータを取得\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_9","type":"command_execution","command":"bash -lc \"sed -n '220,440p' jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_9","type":"command_execution","command":"bash -lc \"sed -n '220,440p' jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\"","aggregated_output":"# バッチ処理でパラメータを取得\nfor ((i=0; i<$TOTAL_PARAMS; i+=BATCH_SIZE)); do\n    # バッチの終了インデックスを計算\n    end=$((i + BATCH_SIZE))\n    if [ $end -gt $TOTAL_PARAMS ]; then\n        end=$TOTAL_PARAMS\n    fi\n    \n    # 進捗表示\n    echo \"Fetching parameters $((i + 1))-$end of ${TOTAL_PARAMS}...\"\n    \n    # バッチ用のパラメータ名を準備\n    batch_params=()\n    for ((j=i; j<end; j++)); do\n        batch_params+=(\"${PARAM_NAMES[$j]}\")\n    done\n    \n    # get-parameters（複数形）でバッチ取得\n    if [ ${#batch_params[@]} -gt 0 ]; then\n        # AWS CLIコマンドを直接実行（xargsを使わない）\n        BATCH_RESULT=$(aws ssm get-parameters \\\n            --names \"${batch_params[@]}\" \\\n            --with-decryption \\\n            --output json \\\n            --region ${AWS_REGION} 2>/dev/null || echo '{\"Parameters\": [], \"InvalidParameters\": []}')\n        \n        # 取得成功したパラメータを追加\n        VALID_PARAMS=$(echo \"$BATCH_RESULT\" | jq '.Parameters // []')\n        if [ \"$VALID_PARAMS\" != \"[]\" ] && [ \"$VALID_PARAMS\" != \"null\" ]; then\n            BACKUP_DATA=$(echo \"$BACKUP_DATA\" | jq --argjson new_params \"$VALID_PARAMS\" '. + $new_params')\n        fi\n        \n        # 取得失敗したパラメータを記録\n        INVALID_PARAMS=$(echo \"$BATCH_RESULT\" | jq -r '.InvalidParameters[]?' 2>/dev/null)\n        if [ -n \"$INVALID_PARAMS\" ]; then\n            while IFS= read -r invalid_param; do\n                echo \"Warning: Failed to get parameter: $invalid_param\"\n                FAILED_PARAMS+=(\"$invalid_param\")\n                FAILED_COUNT=$((FAILED_COUNT + 1))\n            done <<< \"$INVALID_PARAMS\"\n        fi\n    fi\n    \n    # APIレート制限対策（バッチ間の待機時間を長めに）\n    if [ $end -lt $TOTAL_PARAMS ]; then\n        sleep 2\n    fi\ndone\n\nCOUNTER=$TOTAL_PARAMS\n\necho \"Successfully fetched $((COUNTER - FAILED_COUNT)) parameters\"\nif [ \"$FAILED_COUNT\" -gt 0 ]; then\n    echo \"Failed to fetch ${FAILED_COUNT} parameters\"\nfi\n\n# バックアップファイルの作成\necho \"Creating backup file...\"\nBACKUP_JSON=$(jq -n \\\n    --arg date \"${BACKUP_DATE}\" \\\n    --arg timestamp \"${BACKUP_TIMESTAMP}\" \\\n    --arg environment \"${ENVIRONMENT}\" \\\n    --arg count \"$((COUNTER - FAILED_COUNT))\" \\\n    --argjson parameters \"$BACKUP_DATA\" \\\n    '{\n        backup_date: $date,\n        backup_timestamp: $timestamp,\n        environment: $environment,\n        parameter_count: $count | tonumber,\n        parameters: $parameters\n    }')\n\necho \"$BACKUP_JSON\" | jq '.' > ${DATA_DIR}/backup.json\n\necho \"======================================\"\necho \"Backup Summary\"\necho \"======================================\"\necho \"Backup file created: ${DATA_DIR}/backup.json\"\necho \"Total parameters backed up: $(echo \"$BACKUP_JSON\" | jq '.parameter_count')\"\necho \"Failed parameters: ${FAILED_COUNT}\"\necho \"======================================\"\n\n# サマリーファイルを生成して上位パイプラインで参照できるようにする\necho \"Creating summary file...\"\njq -n \\\n    --arg environment \"${ENVIRONMENT}\" \\\n    --arg region \"${AWS_REGION}\" \\\n    --arg backup_date \"${BACKUP_DATE}\" \\\n    --arg backup_timestamp \"${BACKUP_TIMESTAMP}\" \\\n    --argjson parameter_count \"$(echo \"$BACKUP_JSON\" | jq '.parameter_count')\" \\\n    --argjson failed_count $FAILED_COUNT \\\n    '{\n        environment: $environment,\n        region: $region,\n        backup_date: $backup_date,\n        backup_timestamp: $backup_timestamp,\n        parameter_count: $parameter_count,\n        failed_count: $failed_count\n    }' > \"${DATA_DIR}/summary.json\"\n\necho \"Summary file created: ${DATA_DIR}/summary.json\"\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_10","type":"command_execution","command":"bash -lc 'grep -n \"ops-alerts\" -R'","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_10","type":"command_execution","command":"bash -lc 'grep -n \"ops-alerts\" -R'","aggregated_output":"docs/runbooks/ssm-backup.md:28:- 成功時: Slack `#infra-backup-alerts` にリージョン別件数・処理時間を通知。メール `ops-alerts@example.com` に同内容のサマリーを送付。\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:392:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_22\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '120,220p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` 内で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` で取得し、存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `collect_parameters.sh` 実行結果 (`results/summary.json`) から `parameterCount` を読み取り、S3 へアップロードするアーティファクトパスを返す。\\n  - 取得結果は `return [bucket: ..., dataDir: ..., summaryPath: ...]` のように Map で返却し、ループ内で使い回す。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `loadRegionContext(region)` を呼び出し、取得したバケット名でアップロード。DRY_RUN 時は `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: ctx.parameterCount, artifactPath: ctx.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、同梱の簡易 HTTP サーバで受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:405:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_31\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '120,220p'\\\"\",\"aggregated_output\":\"   120\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n   121\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n   122\\t- **プロバイダー管理**  \\n   123\\t  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n   124\\t- **非同期処理**  \\n   125\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n   126\\t- **エクスポート**  \\n   127\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n   128\\t\\n   129\\t### 7.2 Jenkins Pipeline 詳細\\n   130\\t- **パイプライン方式**\\n   131\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n   132\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n   133\\t- **グローバル変数**\\n   134\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n   135\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n   136\\t- **リージョンコンテキスト取得**\\n   137\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n   138\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n   139\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n   140\\t- **ステージ構成**\\n   141\\t  1. `stage('Initialize')`\\n   142\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n   143\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n   144\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n   145\\t  2. `stage('Prepare Scripts')`\\n   146\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n   147\\t  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n   148\\t     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n   149\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n   150\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n   151\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n   152\\t  4. `stage('Finalize Report')`\\n   153\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n   154\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n   155\\t- **エラー制御**\\n   156\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n   157\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n   158\\t- **メトリクス／ログ**\\n   159\\t  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n   160\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n   161\\t\\n   162\\t### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n   163\\t- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n   164\\t- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n   165\\t- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n   166\\t\\n   167\\t### 7.4 `collect_parameters.sh`\\n   168\\t- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n   169\\t- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n   170\\t- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n   171\\t\\n   172\\t### 7.5 テスト設計詳細\\n   173\\t- **Pulumi (Jest)**  \\n   174\\t  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n   175\\t  - 期待事項:  \\n   176\\t    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n   177\\t    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n   178\\t    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n   179\\t    - `bucketMap` エクスポートが全リージョンを包含。\\n   180\\t- **Jenkins (jenkinsfile-runner)**  \\n   181\\t  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n   182\\t  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n   183\\t  - 検証点:  \\n   184\\t    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n   185\\t    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n   186\\t    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n   187\\t- **Manual テスト**  \\n   188\\t  - `pulumi preview` で各リージョンの差分を確認。  \\n   189\\t  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n   190\\t  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n   191\\t  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n   192\\t\\n   193\\t### 7.6 トレーサビリティ\\n   194\\t| 要件ID | 設計上の対応箇所 |\\n   195\\t| ------ | ---------------- |\\n   196\\t| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n   197\\t| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n   198\\t| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n   199\\t| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n   200\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n   201\\t\\n   202\\t### 7.7 通知計画 (FR-5)\\n   203\\t- **対象者**  \\n   204\\t  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n   205\\t  - CLI 経由でバックアップ結果を参照する開発チーム  \\n   206\\t- **チャネル**  \\n   207\\t  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n   208\\t  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n   209\\t- **タイミング**  \\n   210\\t  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n   211\\t  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n   212\\t  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n   213\\t- **責任者**  \\n   214\\t  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n   215\\t  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n   216\\t  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n   217\\t- **テスト/検証**  \\n   218\\t  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n   219\\t  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n   220\\t- **Runbook 更新**  \\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:407:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_32\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '200,320p'\\\"\",\"aggregated_output\":\"   200\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n   201\\t\\n   202\\t### 7.7 通知計画 (FR-5)\\n   203\\t- **対象者**  \\n   204\\t  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n   205\\t  - CLI 経由でバックアップ結果を参照する開発チーム  \\n   206\\t- **チャネル**  \\n   207\\t  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n   208\\t  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n   209\\t- **タイミング**  \\n   210\\t  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n   211\\t  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n   212\\t  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n   213\\t- **責任者**  \\n   214\\t  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n   215\\t  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n   216\\t  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n   217\\t- **テスト/検証**  \\n   218\\t  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n   219\\t  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n   220\\t- **Runbook 更新**  \\n   221\\t  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n   222\\t  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n   223\\t\\n   224\\t## 8. セキュリティ考慮事項\\n   225\\t- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n   226\\t- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n   227\\t- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n   228\\t\\n   229\\t## 9. 非機能要件への対応\\n   230\\t- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n   231\\t- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n   232\\t- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n   233\\t- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n   234\\t\\n   235\\t## 10. 実装の順序\\n   236\\t1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n   237\\t2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n   238\\t3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n   239\\t4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n   240\\t5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n   241\\t6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n   242\\t7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n   243\\t8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n   244\\t\\n   245\\t---\\n   246\\t\\n   247\\t### 品質ゲート確認\\n   248\\t- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n   249\\t- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n   250\\t- ✅ 既存コードへの影響範囲を分析\\n   251\\t- ✅ 必要な変更ファイルをリストアップ\\n   252\\t- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:442:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_5\",\"type\":\"command_execution\",\"command\":\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\",\"aggregated_output\":\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体図\\n```mermaid\\nflowchart TD\\n    subgraph Jenkins[\\\"Jenkins (CI)\\\"]\\n        DSL[\\\"Groovy DSL\\\\nadmin_ssm_backup_job.groovy\\\"]\\n        Pipeline[\\\"Scripted Pipeline\\\\nJenkinsfile\\\"]\\n        Script[\\\"collect_parameters.sh\\\"]\\n    end\\n\\n    subgraph AWS[\\\"AWS Account\\\"]\\n        SSM[\\\"SSM Parameter Store\\\\n(env-scoped metadata)\\\"]\\n        subgraph Regions[\\\"対象リージョン (config-driven)\\\"]\\n            BucketA[\\\"S3 Backup Bucket\\\\n(ap-northeast-1)\\\"]\\n            BucketB[\\\"S3 Backup Bucket\\\\n(us-west-2)\\\"]\\n            BucketC[\\\"S3 Backup Bucket\\\\n(... more)\\\"]\\n        end\\n    end\\n\\n    subgraph Pulumi[\\\"Pulumi Stack (TypeScript)\\\"]\\n        Config[\\\"Pulumi Config\\\\n(project/env/regions)\\\"]\\n        IaC[\\\"index.ts\\\\nmulti-region resource factory\\\"]\\n        Tests[\\\"Jest-based unit tests\\\"]\\n    end\\n\\n    DSL -->|SCM sync| Pipeline\\n    Pipeline -->|fetch| Script\\n    Pipeline -->|Read config & region list| SSM\\n    Pipeline -->|Loop regions\\\\ninvoke AWS CLI| BucketA\\n    Pipeline --> BucketB\\n    Pipeline --> BucketC\\n    Pulumi -->|pulumi up| Regions\\n    Pulumi -->|write bucket metadata\\\\n& region list| SSM\\n    Tests --> IaC\\n```\\n\\n### 1.2 コンポーネント間の関係\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\n\\n### 1.3 データフロー\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\"Backup ${region}\\\")` を生成し、各ステージ内で\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\n\\n## 2. 実装戦略: EXTEND\\n\\n**判断根拠**:\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\n\\n## 3. テスト戦略: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\n\\n## 4. テストコード戦略: CREATE_TEST\\n\\n**判断根拠**:\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\n\\n## 5. 影響範囲分析\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\n\\n## 6. 変更・追加ファイルリスト\\n| 区分 | ファイル/パス | 目的 |\\n| ---- | ------------- | ---- |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\n\\n## 7. 詳細設計\\n\\n### 7.1 Pulumi (IaC) 詳細\\n- **Config インターフェース**  \\n  ```yaml\\n  # Pulumi.<stack>.yaml\\n  config:\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\n    jenkins-ssm-backup-s3:environment: dev\\n    jenkins-ssm-backup-s3:regions:\\n      - ap-northeast-1\\n      - us-west-2\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\n  ```\\n- **主要関数設計**\\n  | 関数/スコープ | 役割 |\\n  | ------------- | ---- |\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\n- **命名規則／タグ**  \\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:446:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_7\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '200,360p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:448:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_8\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '120,260p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:452:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_10\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '180,280p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:456:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_12\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '160,320p'\\\"\",\"aggregated_output\":\"   160\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n   161\\t\\n   162\\t### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n   163\\t- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n   164\\t- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n   165\\t- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n   166\\t\\n   167\\t### 7.4 `collect_parameters.sh`\\n   168\\t- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n   169\\t- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n   170\\t- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n   171\\t\\n   172\\t### 7.5 テスト設計詳細\\n   173\\t- **Pulumi (Jest)**  \\n   174\\t  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n   175\\t  - 期待事項:  \\n   176\\t    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n   177\\t    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n   178\\t    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n   179\\t    - `bucketMap` エクスポートが全リージョンを包含。\\n   180\\t- **Jenkins (jenkinsfile-runner)**  \\n   181\\t  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n   182\\t  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n   183\\t  - 検証点:  \\n   184\\t    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n   185\\t    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n   186\\t    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n   187\\t- **Manual テスト**  \\n   188\\t  - `pulumi preview` で各リージョンの差分を確認。  \\n   189\\t  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n   190\\t  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n   191\\t  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n   192\\t\\n   193\\t### 7.6 トレーサビリティ\\n   194\\t| 要件ID | 設計上の対応箇所 |\\n   195\\t| ------ | ---------------- |\\n   196\\t| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n   197\\t| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n   198\\t| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n   199\\t| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n   200\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n   201\\t\\n   202\\t### 7.7 通知計画 (FR-5)\\n   203\\t- **対象者**  \\n   204\\t  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n   205\\t  - CLI 経由でバックアップ結果を参照する開発チーム  \\n   206\\t- **チャネル**  \\n   207\\t  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n   208\\t  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n   209\\t- **タイミング**  \\n   210\\t  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n   211\\t  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n   212\\t  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n   213\\t- **責任者**  \\n   214\\t  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n   215\\t  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n   216\\t  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n   217\\t- **テスト/検証**  \\n   218\\t  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n   219\\t  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n   220\\t- **Runbook 更新**  \\n   221\\t  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n   222\\t  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n   223\\t\\n   224\\t## 8. セキュリティ考慮事項\\n   225\\t- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n   226\\t- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n   227\\t- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n   228\\t\\n   229\\t## 9. 非機能要件への対応\\n   230\\t- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n   231\\t- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n   232\\t- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n   233\\t- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n   234\\t\\n   235\\t## 10. 実装の順序\\n   236\\t1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n   237\\t2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n   238\\t3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n   239\\t4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n   240\\t5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n   241\\t6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n   242\\t7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n   243\\t8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n   244\\t\\n   245\\t---\\n   246\\t\\n   247\\t### 品質ゲート確認\\n   248\\t- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n   249\\t- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n   250\\t- ✅ 既存コードへの影響範囲を分析\\n   251\\t- ✅ 必要な変更ファイルをリストアップ\\n   252\\t- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:492:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_4\",\"type\":\"command_execution\",\"command\":\"bash -lc 'cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && cat .ai-workflow/issue-391/02_design/output/design.md'\",\"aggregated_output\":\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体図\\n```mermaid\\nflowchart TD\\n    subgraph Jenkins[\\\"Jenkins (CI)\\\"]\\n        DSL[\\\"Groovy DSL\\\\nadmin_ssm_backup_job.groovy\\\"]\\n        Pipeline[\\\"Scripted Pipeline\\\\nJenkinsfile\\\"]\\n        Script[\\\"collect_parameters.sh\\\"]\\n    end\\n\\n    subgraph AWS[\\\"AWS Account\\\"]\\n        SSM[\\\"SSM Parameter Store\\\\n(env-scoped metadata)\\\"]\\n        subgraph Regions[\\\"対象リージョン (config-driven)\\\"]\\n            BucketA[\\\"S3 Backup Bucket\\\\n(ap-northeast-1)\\\"]\\n            BucketB[\\\"S3 Backup Bucket\\\\n(us-west-2)\\\"]\\n            BucketC[\\\"S3 Backup Bucket\\\\n(... more)\\\"]\\n        end\\n    end\\n\\n    subgraph Pulumi[\\\"Pulumi Stack (TypeScript)\\\"]\\n        Config[\\\"Pulumi Config\\\\n(project/env/regions)\\\"]\\n        IaC[\\\"index.ts\\\\nmulti-region resource factory\\\"]\\n        Tests[\\\"Jest-based unit tests\\\"]\\n    end\\n\\n    DSL -->|SCM sync| Pipeline\\n    Pipeline -->|fetch| Script\\n    Pipeline -->|Read config & region list| SSM\\n    Pipeline -->|Loop regions\\\\ninvoke AWS CLI| BucketA\\n    Pipeline --> BucketB\\n    Pipeline --> BucketC\\n    Pulumi -->|pulumi up| Regions\\n    Pulumi -->|write bucket metadata\\\\n& region list| SSM\\n    Tests --> IaC\\n```\\n\\n### 1.2 コンポーネント間の関係\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\n\\n### 1.3 データフロー\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\"Backup ${region}\\\")` を生成し、各ステージ内で\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\n\\n## 2. 実装戦略: EXTEND\\n\\n**判断根拠**:\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\n\\n## 3. テスト戦略: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\n\\n## 4. テストコード戦略: CREATE_TEST\\n\\n**判断根拠**:\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\n\\n## 5. 影響範囲分析\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\n\\n## 6. 変更・追加ファイルリスト\\n| 区分 | ファイル/パス | 目的 |\\n| ---- | ------------- | ---- |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\n\\n## 7. 詳細設計\\n\\n### 7.1 Pulumi (IaC) 詳細\\n- **Config インターフェース**  \\n  ```yaml\\n  # Pulumi.<stack>.yaml\\n  config:\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\n    jenkins-ssm-backup-s3:environment: dev\\n    jenkins-ssm-backup-s3:regions:\\n      - ap-northeast-1\\n      - us-west-2\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\n  ```\\n- **主要関数設計**\\n  | 関数/スコープ | 役割 |\\n  | ------------- | ---- |\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\n- **命名規則／タグ**  \\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:500:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_8\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && sed -n '160,320p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:575:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_1\",\"type\":\"command_execution\",\"command\":\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\",\"aggregated_output\":\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体図\\n```mermaid\\nflowchart TD\\n    subgraph Jenkins[\\\"Jenkins (CI)\\\"]\\n        DSL[\\\"Groovy DSL\\\\nadmin_ssm_backup_job.groovy\\\"]\\n        Pipeline[\\\"Scripted Pipeline\\\\nJenkinsfile\\\"]\\n        Script[\\\"collect_parameters.sh\\\"]\\n    end\\n\\n    subgraph AWS[\\\"AWS Account\\\"]\\n        SSM[\\\"SSM Parameter Store\\\\n(env-scoped metadata)\\\"]\\n        subgraph Regions[\\\"対象リージョン (config-driven)\\\"]\\n            BucketA[\\\"S3 Backup Bucket\\\\n(ap-northeast-1)\\\"]\\n            BucketB[\\\"S3 Backup Bucket\\\\n(us-west-2)\\\"]\\n            BucketC[\\\"S3 Backup Bucket\\\\n(... more)\\\"]\\n        end\\n    end\\n\\n    subgraph Pulumi[\\\"Pulumi Stack (TypeScript)\\\"]\\n        Config[\\\"Pulumi Config\\\\n(project/env/regions)\\\"]\\n        IaC[\\\"index.ts\\\\nmulti-region resource factory\\\"]\\n        Tests[\\\"Jest-based unit tests\\\"]\\n    end\\n\\n    DSL -->|SCM sync| Pipeline\\n    Pipeline -->|fetch| Script\\n    Pipeline -->|Read config & region list| SSM\\n    Pipeline -->|Loop regions\\\\ninvoke AWS CLI| BucketA\\n    Pipeline --> BucketB\\n    Pipeline --> BucketC\\n    Pulumi -->|pulumi up| Regions\\n    Pulumi -->|write bucket metadata\\\\n& region list| SSM\\n    Tests --> IaC\\n```\\n\\n### 1.2 コンポーネント間の関係\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\n\\n### 1.3 データフロー\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\"Backup ${region}\\\")` を生成し、各ステージ内で\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\n\\n## 2. 実装戦略: EXTEND\\n\\n**判断根拠**:\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\n\\n## 3. テスト戦略: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\n\\n## 4. テ���トコード戦略: CREATE_TEST\\n\\n**判断根拠**:\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\n\\n## 5. 影響範囲分析\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\n\\n## 6. 変更・追加ファイルリスト\\n| 区分 | ファイル/パス | 目的 |\\n| ---- | ------------- | ---- |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\n\\n## 7. 詳細設計\\n\\n### 7.1 Pulumi (IaC) 詳細\\n- **Config インターフェース**  \\n  ```yaml\\n  # Pulumi.<stack>.yaml\\n  config:\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\n    jenkins-ssm-backup-s3:environment: dev\\n    jenkins-ssm-backup-s3:regions:\\n      - ap-northeast-1\\n      - us-west-2\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\n  ```\\n- **主要関数設計**\\n  | 関数/スコープ | 役割 |\\n  | ------------- | ---- |\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\n- **命名規則／タグ**  \\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:609:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_18\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '110,210p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\n  ```\\n- **主要関数設計**\\n  | 関数/スコープ | 役割 |\\n  | ------------- | ---- |\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\n- **命名規則／タグ**  \\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:623:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_25\",\"type\":\"command_execution\",\"command\":\"bash -lc 'grep -R \\\"SSM Parameter Store Backup\\\" -n'\",\"aggregated_output\":\"scripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:16:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_1\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,160p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:20:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"@Library('jenkins-shared-lib') _\\\\n\\\\n/**\\\\n * SSM Parameter Store Backup Pipeline\\\\n * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\\\\n */\\\\npipeline {\\\\n    agent {\\\\n        label 'ec2-fleet'\\\\n    }\\\\n    \\\\n    options {\\\\n        timestamps()\\\\n        timeout(time: 1, unit: 'HOURS')\\\\n        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\\\\n        disableConcurrentBuilds()\\\\n    }\\\\n    \\\\n    environment {\\\\n        // AWS設定\\\\n        AWS_REGION = 'ap-northeast-1'\\\\n        \\\\n        // タイムスタンプ\\\\n        BACKUP_DATE = sh(script: \\\\\\\"date '+%Y-%m-%d'\\\\\\\", returnStdout: true).trim()\\\\n        BACKUP_TIMESTAMP = sh(script: \\\\\\\"date '+%Y%m%d_%H%M%S'\\\\\\\", returnStdout: true).trim()\\\\n        \\\\n        // ディレクトリ構造\\\\n        WORK_DIR = \\\\\\\"${WORKSPACE}/backup-work\\\\\\\"\\\\n        DATA_DIR = \\\\\\\"${WORK_DIR}/data\\\\\\\"\\\\n        SCRIPT_DIR = \\\\\\\"${WORKSPACE}/scripts\\\\\\\"\\\\n        \\\\n        // 環境フィルタ（環境に含まれる文字列）\\\\n        ENV_FILTER = \\\\\\\"/${params.ENVIRONMENT}/\\\\\\\"\\\\n    }\\\\n    \\\\n    stages {\\\\n        stage('Initialize') {\\\\n            steps {\\\\n                script {\\\\n                    // ビルド表示名を設定\\\\n                    currentBuild.displayName = \\\\\\\"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\\\\\\\"\\\\n                    currentBuild.description = \\\\\\\"Backup at ${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    SSM Parameter Store Backup\\\\n                    =============================================\\\\n                    Environment: ${params.ENVIRONMENT}\\\\n                    Filter: Parameters containing '${env.ENV_FILTER}'\\\\n                    Dry Run: ${params.DRY_RUN}\\\\n                    Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                    Date: ${env.BACKUP_DATE}\\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // 作業ディレクトリの準備\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        rm -rf ${WORK_DIR}\\\\n                        mkdir -p ${DATA_DIR}\\\\n                        mkdir -p ${SCRIPT_DIR}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // S3バケット名の取得\\\\n                    env.BACKUP_BUCKET = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws ssm get-parameter \\\\\\\\\\\\n                                --name \\\\\\\"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\\\\\\\" \\\\\\\\\\\\n                                --query 'Parameter.Value' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION} 2>/dev/null || echo \\\\\\\"\\\\\\\"\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    if (!env.BACKUP_BUCKET) {\\\\n                        error(\\\\\\\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\\\\\\\")\\\\n                    }\\\\n                    \\\\n                    echo \\\\\\\"Backup S3 Bucket: ${env.BACKUP_BUCKET}\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Prepare Scripts') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Preparing Collection Scripts ===\\\\\\\"\\\\n                    \\\\n                    // Jenkinsリポジトリをチェックアウト\\\\n                    dir('jenkins-repo') {\\\\n                        checkout([\\\\n                            $class: 'GitSCM',\\\\n                            branches: [[name: \\\\\\\"${params.JENKINSFILE_BRANCH}\\\\\\\"]],\\\\n                            userRemoteConfigs: [[\\\\n                                url: 'https://github.com/tielec/infrastructure-as-code',\\\\n                                credentialsId: 'github-app-credentials'\\\\n                            ]]\\\\n                        ])\\\\n                    }\\\\n                    \\\\n                    // スクリプトをコピー\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\\\\n                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\\\\n                        \\\\n                        echo \\\\\\\"Script copied and made executable\\\\\\\"\\\\n                        ls -la ${SCRIPT_DIR}/\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Collect Parameters') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Collecting SSM Parameters ===\\\\\\\"\\\\n                    \\\\n                    // スクリプトの実行\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        # 環境変数を設定\\\\n                        export ENVIRONMENT=\\\\\\\"${params.ENVIRONMENT}\\\\\\\"\\\\n                        export ENV_FILTER=\\\\\\\"${env.ENV_FILTER}\\\\\\\"\\\\n                        export AWS_REGION=\\\\\\\"${AWS_REGION}\\\\\\\"\\\\n                        export BACKUP_DATE=\\\\\\\"${env.BACKUP_DATE}\\\\\\\"\\\\n                        export BACKUP_TIMESTAMP=\\\\\\\"${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                        export DATA_DIR=\\\\\\\"${DATA_DIR}\\\\\\\"\\\\n                        \\\\n                        # スクリプト実行\\\\n                        ${SCRIPT_DIR}/collect_parameters.sh\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの確認\\\\n                    if (fileExists(\\\\\\\"${DATA_DIR}/backup.json\\\\\\\")) {\\\\n                        def backupData = readJSON file: \\\\\\\"${DATA_DIR}/backup.json\\\\\\\"\\\\n                        env.PARAM_COUNT = backupData.parameter_count.toString()\\\\n                        \\\\n                        if (backupData.parameter_count == 0) {\\\\n                            echo \\\\\\\"WARNING: No parameters found for backup\\\\\\\"\\\\n                            currentBuild.result = 'UNSTABLE'\\\\n                        } else {\\\\n                            echo \\\\\\\"Backup file contains ${backupData.parameter_count} parameters\\\\\\\"\\\\n                        }\\\\n                    } else {\\\\n                        error(\\\\\\\"Backup file was not created\\\\\\\")\\\\n                    }\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Upload to S3') {\\\\n            when {\\\\n                expression { \\\\n                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\\\\n                }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Uploading Backup to S3 ===\\\\\\\"\\\\n                    \\\\n                    def backupFileName = \\\\\\\"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\\\\"\\\\n                    def s3Key = \\\\\\\"${env.BACKUP_DATE}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの名前を変更\\\\n                    sh \\\\\\\"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // S3へアップロード（暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\\\\\\\\\\n                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\\\\\\\"\\\\n                    \\\\n                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        echo '${s3Key}' | \\\\\\\\\\\\n                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // アップロード確認\\\\n                    def s3ObjectInfo = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws s3api head-object \\\\\\\\\\\\n                                --bucket ${env.BACKUP_BUCKET} \\\\\\\\\\\\n                                --key ${s3Key} \\\\\\\\\\\\n                                --query '[ContentLength, LastModified]' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION}\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    echo \\\\\\\"S3 Object Info: ${s3ObjectInfo}\\\\\\\"\\\\n                    \\\\n                    // セキュリティ上の理由によりアーティファクトとしては保存しない\\\\n                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:22:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '200,400p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Dry Run Report') {\\\\n            when {\\\\n                expression { params.DRY_RUN }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    def paramCount = env.PARAM_COUNT ?: '0'\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    DRY RUN - バックアップ実行レポート\\\\n                    =============================================\\\\n                    \\\\n                    このドライランでは実際のS3アップロードは行われませんでした。\\\\n                    \\\\n                    バックアップ対象:\\\\n                    - 環境: ${params.ENVIRONMENT}\\\\n                    - パラメータ数: ${paramCount}\\\\n                    - バックアップ日時: ${env.BACKUP_TIMESTAMP}\\\\n                    \\\\n                    実行時の動作:\\\\n                    - S3バケット: ${env.BACKUP_BUCKET}\\\\n                    - S3パス: ${env.BACKUP_DATE}/\\\\n                    - ファイル名: ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\n                    \\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // セキュリティ上の理由によりドライラン時もアーティファクトとして保存しない\\\\n                }\\\\n            }\\\\n        }\\\\n    }\\\\n    \\\\n    post {\\\\n        always {\\\\n            script {\\\\n                def paramCount = env.PARAM_COUNT ?: '0'\\\\n                \\\\n                // 実行サマリーの表示\\\\n                echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                =============================================\\\\n                SSM Parameter Store Backup Summary\\\\n                =============================================\\\\n                Build: #${env.BUILD_NUMBER}\\\\n                Status: ${currentBuild.result ?: 'SUCCESS'}\\\\n                Environment: ${params.ENVIRONMENT}\\\\n                Parameters: ${paramCount}\\\\n                Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                Dry Run: ${params.DRY_RUN}\\\\n                =============================================\\\\n                \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n            }\\\\n        }\\\\n        \\\\n        success {\\\\n            echo \\\\\\\"✅ SSMパラメータのバックアップが正常に完了しました\\\\\\\"\\\\n        }\\\\n        \\\\n        failure {\\\\n            echo \\\\\\\"❌ バックアップが失敗しました。ログを確認してください\\\\\\\"\\\\n        }\\\\n        \\\\n        unstable {\\\\n            echo \\\\\\\"⚠️ バックアップは完了しましたが、警告があります\\\\\\\"\\\\n        }\\\\n        \\\\n        cleanup {\\\\n            // 作業ディレクトリのクリーンアップ\\\\n            sh \\\\\\\"rm -rf ${WORK_DIR} ${SCRIPT_DIR} jenkins-repo || true\\\\\\\"\\\\n        }\\\\n    }\\\\n}\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:41:[DEBUG][Codex][5] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_1\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,160p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:45:[DEBUG][Codex][9] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"@Library('jenkins-shared-lib') _\\\\n\\\\n/**\\\\n * SSM Parameter Store Backup Pipeline\\\\n * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\\\\n */\\\\npipeline {\\\\n    agent {\\\\n        label 'ec2-fleet'\\\\n    }\\\\n    \\\\n    options {\\\\n        timestamps()\\\\n        timeout(time: 1, unit: 'HOURS')\\\\n        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\\\\n        disableConcurrentBuilds()\\\\n    }\\\\n    \\\\n    environment {\\\\n        // AWS設定\\\\n        AWS_REGION = 'ap-northeast-1'\\\\n        \\\\n        // タイムスタンプ\\\\n        BACKUP_DATE = sh(script: \\\\\\\"date '+%Y-%m-%d'\\\\\\\", returnStdout: true).trim()\\\\n        BACKUP_TIMESTAMP = sh(script: \\\\\\\"date '+%Y%m%d_%H%M%S'\\\\\\\", returnStdout: true).trim()\\\\n        \\\\n        // ディレクトリ構造\\\\n        WORK_DIR = \\\\\\\"${WORKSPACE}/backup-work\\\\\\\"\\\\n        DATA_DIR = \\\\\\\"${WORK_DIR}/data\\\\\\\"\\\\n        SCRIPT_DIR = \\\\\\\"${WORKSPACE}/scripts\\\\\\\"\\\\n        \\\\n        // 環境フィルタ（環境に含まれる文字列）\\\\n        ENV_FILTER = \\\\\\\"/${params.ENVIRONMENT}/\\\\\\\"\\\\n    }\\\\n    \\\\n    stages {\\\\n        stage('Initialize') {\\\\n            steps {\\\\n                script {\\\\n                    // ビルド表示名を設定\\\\n                    currentBuild.displayName = \\\\\\\"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\\\\\\\"\\\\n                    currentBuild.description = \\\\\\\"Backup at ${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    SSM Parameter Store Backup\\\\n                    =============================================\\\\n                    Environment: ${params.ENVIRONMENT}\\\\n                    Filter: Parameters containing '${env.ENV_FILTER}'\\\\n                    Dry Run: ${params.DRY_RUN}\\\\n                    Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                    Date: ${env.BACKUP_DATE}\\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // 作業ディレクトリの準備\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        rm -rf ${WORK_DIR}\\\\n                        mkdir -p ${DATA_DIR}\\\\n                        mkdir -p ${SCRIPT_DIR}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // S3バケット名の取得\\\\n                    env.BACKUP_BUCKET = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws ssm get-parameter \\\\\\\\\\\\n                                --name \\\\\\\"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\\\\\\\" \\\\\\\\\\\\n                                --query 'Parameter.Value' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION} 2>/dev/null || echo \\\\\\\"\\\\\\\"\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    if (!env.BACKUP_BUCKET) {\\\\n                        error(\\\\\\\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\\\\\\\")\\\\n                    }\\\\n                    \\\\n                    echo \\\\\\\"Backup S3 Bucket: ${env.BACKUP_BUCKET}\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Prepare Scripts') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Preparing Collection Scripts ===\\\\\\\"\\\\n                    \\\\n                    // Jenkinsリポジトリをチェックアウト\\\\n                    dir('jenkins-repo') {\\\\n                        checkout([\\\\n                            $class: 'GitSCM',\\\\n                            branches: [[name: \\\\\\\"${params.JENKINSFILE_BRANCH}\\\\\\\"]],\\\\n                            userRemoteConfigs: [[\\\\n                                url: 'https://github.com/tielec/infrastructure-as-code',\\\\n                                credentialsId: 'github-app-credentials'\\\\n                            ]]\\\\n                        ])\\\\n                    }\\\\n                    \\\\n                    // スクリプトをコピー\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\\\\n                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\\\\n                        \\\\n                        echo \\\\\\\"Script copied and made executable\\\\\\\"\\\\n                        ls -la ${SCRIPT_DIR}/\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Collect Parameters') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Collecting SSM Parameters ===\\\\\\\"\\\\n                    \\\\n                    // スクリプトの実行\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        # 環境変数を設定\\\\n                        export ENVIRONMENT=\\\\\\\"${params.ENVIRONMENT}\\\\\\\"\\\\n                        export ENV_FILTER=\\\\\\\"${env.ENV_FILTER}\\\\\\\"\\\\n                        export AWS_REGION=\\\\\\\"${AWS_REGION}\\\\\\\"\\\\n                        export BACKUP_DATE=\\\\\\\"${env.BACKUP_DATE}\\\\\\\"\\\\n                        export BACKUP_TIMESTAMP=\\\\\\\"${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                        export DATA_DIR=\\\\\\\"${DATA_DIR}\\\\\\\"\\\\n                        \\\\n                        # スクリプト実行\\\\n                        ${SCRIPT_DIR}/collect_parameters.sh\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの確認\\\\n                    if (fileExists(\\\\\\\"${DATA_DIR}/backup.json\\\\\\\")) {\\\\n                        def backupData = readJSON file: \\\\\\\"${DATA_DIR}/backup.json\\\\\\\"\\\\n                        env.PARAM_COUNT = backupData.parameter_count.toString()\\\\n                        \\\\n                        if (backupData.parameter_count == 0) {\\\\n                            echo \\\\\\\"WARNING: No parameters found for backup\\\\\\\"\\\\n                            currentBuild.result = 'UNSTABLE'\\\\n                        } else {\\\\n                            echo \\\\\\\"Backup file contains ${backupData.parameter_count} parameters\\\\\\\"\\\\n                        }\\\\n                    } else {\\\\n                        error(\\\\\\\"Backup file was not created\\\\\\\")\\\\n                    }\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Upload to S3') {\\\\n            when {\\\\n                expression { \\\\n                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\\\\n                }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Uploading Backup to S3 ===\\\\\\\"\\\\n                    \\\\n                    def backupFileName = \\\\\\\"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\\\\"\\\\n                    def s3Key = \\\\\\\"${env.BACKUP_DATE}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの名前を変更\\\\n                    sh \\\\\\\"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // S3へアップロード（暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\\\\\\\\\\n                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\\\\\\\"\\\\n                    \\\\n                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        echo '${s3Key}' | \\\\\\\\\\\\n                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // アップロード確認\\\\n                    def s3ObjectInfo = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws s3api head-object \\\\\\\\\\\\n                                --bucket ${env.BACKUP_BUCKET} \\\\\\\\\\\\n                                --key ${s3Key} \\\\\\\\\\\\n                                --query '[ContentLength, LastModified]' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION}\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    echo \\\\\\\"S3 Object Info: ${s3ObjectInfo}\\\\\\\"\\\\n                    \\\\n                    // セキュリティ上の理由によりアーティファクトとしては保存しない\\\\n                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:249:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:251:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"@Library('jenkins-shared-lib') _\\\\n\\\\n/**\\\\n * SSM Parameter Store Backup Pipeline\\\\n * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\\\\n */\\\\npipeline {\\\\n    agent {\\\\n        label 'ec2-fleet'\\\\n    }\\\\n    \\\\n    options {\\\\n        timestamps()\\\\n        timeout(time: 1, unit: 'HOURS')\\\\n        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\\\\n        disableConcurrentBuilds()\\\\n    }\\\\n    \\\\n    environment {\\\\n        // AWS設定\\\\n        AWS_REGION = 'ap-northeast-1'\\\\n        \\\\n        // タイムスタンプ\\\\n        BACKUP_DATE = sh(script: \\\\\\\"date '+%Y-%m-%d'\\\\\\\", returnStdout: true).trim()\\\\n        BACKUP_TIMESTAMP = sh(script: \\\\\\\"date '+%Y%m%d_%H%M%S'\\\\\\\", returnStdout: true).trim()\\\\n        \\\\n        // ディレクトリ構造\\\\n        WORK_DIR = \\\\\\\"${WORKSPACE}/backup-work\\\\\\\"\\\\n        DATA_DIR = \\\\\\\"${WORK_DIR}/data\\\\\\\"\\\\n        SCRIPT_DIR = \\\\\\\"${WORKSPACE}/scripts\\\\\\\"\\\\n        \\\\n        // 環境フィルタ（環境に含まれる文字列）\\\\n        ENV_FILTER = \\\\\\\"/${params.ENVIRONMENT}/\\\\\\\"\\\\n    }\\\\n    \\\\n    stages {\\\\n        stage('Initialize') {\\\\n            steps {\\\\n                script {\\\\n                    // ビルド表示名を設定\\\\n                    currentBuild.displayName = \\\\\\\"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\\\\\\\"\\\\n                    currentBuild.description = \\\\\\\"Backup at ${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    SSM Parameter Store Backup\\\\n                    =============================================\\\\n                    Environment: ${params.ENVIRONMENT}\\\\n                    Filter: Parameters containing '${env.ENV_FILTER}'\\\\n                    Dry Run: ${params.DRY_RUN}\\\\n                    Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                    Date: ${env.BACKUP_DATE}\\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // 作業ディレクトリの準備\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        rm -rf ${WORK_DIR}\\\\n                        mkdir -p ${DATA_DIR}\\\\n                        mkdir -p ${SCRIPT_DIR}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // S3バケット名の取得\\\\n                    env.BACKUP_BUCKET = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws ssm get-parameter \\\\\\\\\\\\n                                --name \\\\\\\"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\\\\\\\" \\\\\\\\\\\\n                                --query 'Parameter.Value' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION} 2>/dev/null || echo \\\\\\\"\\\\\\\"\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    if (!env.BACKUP_BUCKET) {\\\\n                        error(\\\\\\\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\\\\\\\")\\\\n                    }\\\\n                    \\\\n                    echo \\\\\\\"Backup S3 Bucket: ${env.BACKUP_BUCKET}\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Prepare Scripts') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Preparing Collection Scripts ===\\\\\\\"\\\\n                    \\\\n                    // Jenkinsリポジトリをチェックアウト\\\\n                    dir('jenkins-repo') {\\\\n                        checkout([\\\\n                            $class: 'GitSCM',\\\\n                            branches: [[name: \\\\\\\"${params.JENKINSFILE_BRANCH}\\\\\\\"]],\\\\n                            userRemoteConfigs: [[\\\\n                                url: 'https://github.com/tielec/infrastructure-as-code',\\\\n                                credentialsId: 'github-app-credentials'\\\\n                            ]]\\\\n                        ])\\\\n                    }\\\\n                    \\\\n                    // スクリプトをコピー\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\\\\n                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\\\\n                        \\\\n                        echo \\\\\\\"Script copied and made executable\\\\\\\"\\\\n                        ls -la ${SCRIPT_DIR}/\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Collect Parameters') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Collecting SSM Parameters ===\\\\\\\"\\\\n                    \\\\n                    // スクリプトの実行\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        # 環境変数を設定\\\\n                        export ENVIRONMENT=\\\\\\\"${params.ENVIRONMENT}\\\\\\\"\\\\n                        export ENV_FILTER=\\\\\\\"${env.ENV_FILTER}\\\\\\\"\\\\n                        export AWS_REGION=\\\\\\\"${AWS_REGION}\\\\\\\"\\\\n                        export BACKUP_DATE=\\\\\\\"${env.BACKUP_DATE}\\\\\\\"\\\\n                        export BACKUP_TIMESTAMP=\\\\\\\"${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                        export DATA_DIR=\\\\\\\"${DATA_DIR}\\\\\\\"\\\\n                        \\\\n                        # スクリプト実行\\\\n                        ${SCRIPT_DIR}/collect_parameters.sh\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの確認\\\\n                    if (fileExists(\\\\\\\"${DATA_DIR}/backup.json\\\\\\\")) {\\\\n                        def backupData = readJSON file: \\\\\\\"${DATA_DIR}/backup.json\\\\\\\"\\\\n                        env.PARAM_COUNT = backupData.parameter_count.toString()\\\\n                        \\\\n                        if (backupData.parameter_count == 0) {\\\\n                            echo \\\\\\\"WARNING: No parameters found for backup\\\\\\\"\\\\n                            currentBuild.result = 'UNSTABLE'\\\\n                        } else {\\\\n                            echo \\\\\\\"Backup file contains ${backupData.parameter_count} parameters\\\\\\\"\\\\n                        }\\\\n                    } else {\\\\n                        error(\\\\\\\"Backup file was not created\\\\\\\")\\\\n                    }\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Upload to S3') {\\\\n            when {\\\\n                expression { \\\\n                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\\\\n                }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Uploading Backup to S3 ===\\\\\\\"\\\\n                    \\\\n                    def backupFileName = \\\\\\\"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\\\\"\\\\n                    def s3Key = \\\\\\\"${env.BACKUP_DATE}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの名前を変更\\\\n                    sh \\\\\\\"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // S3へアップロード（暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\\\\\\\\\\n                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\\\\\\\"\\\\n                    \\\\n                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        echo '${s3Key}' | \\\\\\\\\\\\n                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // アップロード確認\\\\n                    def s3ObjectInfo = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws s3api head-object \\\\\\\\\\\\n                                --bucket ${env.BACKUP_BUCKET} \\\\\\\\\\\\n                                --key ${s3Key} \\\\\\\\\\\\n                                --query '[ContentLength, LastModified]' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION}\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    echo \\\\\\\"S3 Object Info: ${s3ObjectInfo}\\\\\\\"\\\\n                    \\\\n                    // セキュリティ上の理由によりアーティファクトとしては保存しない\\\\n                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:253:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '200,400p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Dry Run Report') {\\\\n            when {\\\\n                expression { params.DRY_RUN }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    def paramCount = env.PARAM_COUNT ?: '0'\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    DRY RUN - バックアップ実行レポート\\\\n                    =============================================\\\\n                    \\\\n                    このドライランでは実際のS3アップロードは行われませんでした。\\\\n                    \\\\n                    バックアップ対象:\\\\n                    - 環境: ${params.ENVIRONMENT}\\\\n                    - パラメータ数: ${paramCount}\\\\n                    - バックアップ日時: ${env.BACKUP_TIMESTAMP}\\\\n                    \\\\n                    実行時の動作:\\\\n                    - S3バケット: ${env.BACKUP_BUCKET}\\\\n                    - S3パス: ${env.BACKUP_DATE}/\\\\n                    - ファイル名: ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\n                    \\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // セキュリティ上の理由によりドライラン時もアーティファクトとして保存しない\\\\n                }\\\\n            }\\\\n        }\\\\n    }\\\\n    \\\\n    post {\\\\n        always {\\\\n            script {\\\\n                def paramCount = env.PARAM_COUNT ?: '0'\\\\n                \\\\n                // 実行サマリーの表示\\\\n                echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                =============================================\\\\n                SSM Parameter Store Backup Summary\\\\n                =============================================\\\\n                Build: #${env.BUILD_NUMBER}\\\\n                Status: ${currentBuild.result ?: 'SUCCESS'}\\\\n                Environment: ${params.ENVIRONMENT}\\\\n                Parameters: ${paramCount}\\\\n                Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                Dry Run: ${params.DRY_RUN}\\\\n                =============================================\\\\n                \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n            }\\\\n        }\\\\n        \\\\n        success {\\\\n            echo \\\\\\\"✅ SSMパラメータのバックアップが正常に完了しました\\\\\\\"\\\\n        }\\\\n        \\\\n        failure {\\\\n            echo \\\\\\\"❌ バックアップが失敗しました。ログを確認してください\\\\\\\"\\\\n        }\\\\n        \\\\n        unstable {\\\\n            echo \\\\\\\"⚠️ バックアップは完了しましたが、警告があります\\\\\\\"\\\\n        }\\\\n        \\\\n        cleanup {\\\\n            // 作業ディレクトリのクリーンアップ\\\\n            sh \\\\\\\"rm -rf ${WORK_DIR} ${SCRIPT_DIR} jenkins-repo || true\\\\\\\"\\\\n        }\\\\n    }\\\\n}\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:288:[DEBUG][Codex][9] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:304:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Declarative Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、各リージョンを逐次ステージ化してバックアップ処理・S3 へのアップロード・ログ集計を実施。失敗時は後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. `Regional Backup Orchestrator` ステージの Imperative ブロックがリージョンごとにサブステージを生成。各サブステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照��。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` のステージ分割とヘルパーメソッドを実装し、Declarative Linter を通す。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:308:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,160p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Declarative Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、各リージョンを逐次ステージ化してバックアップ処理・S3 へのアップロード・ログ集計を実施。失敗時は後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. `Regional Backup Orchestrator` ステージの Imperative ブロックがリージョンごとにサブステージを生成。各サブステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:316:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_9\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '90,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:348:[DEBUG][Codex][9] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Declarative Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、各リージョンを逐次ステージ化してバックアップ処理・S3 へのアップロード・ログ集計を実施。失敗時は後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. `Regional Backup Orchestrator` ステージの Imperative ブロックがリージョンごとにサブステージを生成。各サブステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` のステージ分割とヘルパーメソッドを実装し、Declarative Linter を通す。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:360:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_2\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Declarative Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、各リージョンを逐次ステージ化してバックアップ処理・S3 へのアップロード・ログ集計を実施。失敗時は後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. `Regional Backup Orchestrator` ステージの Imperative ブロックがリージョンごとにサブステージを生成。各サブステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:370:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_7\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '80,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:378:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_12\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '120,170p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:383:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_16\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '40,120p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ���応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:392:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_22\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '120,220p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` 内で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` で取得し、存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `collect_parameters.sh` 実行結果 (`results/summary.json`) から `parameterCount` を読み取り、S3 へアップロードするアーティファクトパスを返す。\\\\n  - 取得結果は `return [bucket: ..., dataDir: ..., summaryPath: ...]` のように Map で返却し、ループ内で使い回す。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `loadRegionContext(region)` を呼び出し、取得したバケット名でアップロード。DRY_RUN 時は `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: ctx.parameterCount, artifactPath: ctx.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、同梱の簡易 HTTP サーバで受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:403:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_30\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,120p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:405:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_31\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '120,220p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n   141\\\\t  1. `stage('Initialize')`\\\\n   142\\\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n   143\\\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n   144\\\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n   145\\\\t  2. `stage('Prepare Scripts')`\\\\n   146\\\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n   147\\\\t  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n   148\\\\t     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n   149\\\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n   150\\\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n   151\\\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n   152\\\\t  4. `stage('Finalize Report')`\\\\n   153\\\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n   154\\\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n   155\\\\t- **エラー制御**\\\\n   156\\\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n   157\\\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n   158\\\\t- **メトリクス／ログ**\\\\n   159\\\\t  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n   160\\\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n   161\\\\t\\\\n   162\\\\t### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n   163\\\\t- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n   164\\\\t- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n   165\\\\t- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n   166\\\\t\\\\n   167\\\\t### 7.4 `collect_parameters.sh`\\\\n   168\\\\t- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n   169\\\\t- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n   170\\\\t- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n   171\\\\t\\\\n   172\\\\t### 7.5 テスト設計詳細\\\\n   173\\\\t- **Pulumi (Jest)**  \\\\n   174\\\\t  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n   175\\\\t  - 期待事項:  \\\\n   176\\\\t    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n   177\\\\t    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n   178\\\\t    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n   179\\\\t    - `bucketMap` エクスポートが全リージョンを包含。\\\\n   180\\\\t- **Jenkins (jenkinsfile-runner)**  \\\\n   181\\\\t  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n   182\\\\t  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n   183\\\\t  - 検証点:  \\\\n   184\\\\t    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n   185\\\\t    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n   186\\\\t    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n   187\\\\t- **Manual テスト**  \\\\n   188\\\\t  - `pulumi preview` で各リージョンの差分を確認。  \\\\n   189\\\\t  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n   190\\\\t  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n   191\\\\t  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n   192\\\\t\\\\n   193\\\\t### 7.6 トレーサビリティ\\\\n   194\\\\t| 要件ID | 設計上の対応箇所 |\\\\n   195\\\\t| ------ | ---------------- |\\\\n   196\\\\t| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n   197\\\\t| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n   198\\\\t| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n   199\\\\t| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n   200\\\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n   201\\\\t\\\\n   202\\\\t### 7.7 通知計画 (FR-5)\\\\n   203\\\\t- **対象者**  \\\\n   204\\\\t  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n   205\\\\t  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n   206\\\\t- **チャネル**  \\\\n   207\\\\t  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n   208\\\\t  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n   209\\\\t- **タイミング**  \\\\n   210\\\\t  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n   211\\\\t  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n   212\\\\t  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n   213\\\\t- **責任者**  \\\\n   214\\\\t  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n   215\\\\t  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n   216\\\\t  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n   217\\\\t- **テスト/検証**  \\\\n   218\\\\t  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n   219\\\\t  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n   220\\\\t- **Runbook 更新**  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:409:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_33\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '80,140p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"    80\\\\t- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n    81\\\\t\\\\n    82\\\\t## 6. 変更・追加ファイルリスト\\\\n    83\\\\t| 区分 | ファイル/パス | 目的 |\\\\n    84\\\\t| ---- | ------------- | ---- |\\\\n    85\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n    86\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n    87\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n    88\\\\t| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n    89\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n    90\\\\t| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n    91\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n    92\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n    93\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n    94\\\\t| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n    95\\\\t| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n    96\\\\t\\\\n    97\\\\t## 7. 詳細設計\\\\n    98\\\\t\\\\n    99\\\\t### 7.1 Pulumi (IaC) 詳細\\\\n   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバイン���。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:421:[DEBUG][Codex][7] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_2\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Declarative Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、各リージョンを逐次ステージ化してバックアップ処理・S3 へのアップロード・ログ集計を実施。失敗時は後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. `Regional Backup Orchestrator` ステージの Imperative ブロックがリージョンごとにサブステージを生成。各サブステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:442:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:444:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_6\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '60,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:448:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_8\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '120,260p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:450:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_9\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '80,180p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:454:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_11\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '1,160p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"     1\\\\t# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n     2\\\\t\\\\n     3\\\\t## 1. アーキテクチャ設計\\\\n     4\\\\t\\\\n     5\\\\t### 1.1 システム全体図\\\\n     6\\\\t```mermaid\\\\n     7\\\\tflowchart TD\\\\n     8\\\\t    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n     9\\\\t        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n    10\\\\t        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n    11\\\\t        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    12\\\\t    end\\\\n    13\\\\t\\\\n    14\\\\t    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n    15\\\\t        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n    16\\\\t        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n    17\\\\t            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n    18\\\\t            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n    19\\\\t            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n    20\\\\t        end\\\\n    21\\\\t    end\\\\n    22\\\\t\\\\n    23\\\\t    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n    24\\\\t        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n    25\\\\t        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n    26\\\\t        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    27\\\\t    end\\\\n    28\\\\t\\\\n    29\\\\t    DSL -->|SCM sync| Pipeline\\\\n    30\\\\t    Pipeline -->|fetch| Script\\\\n    31\\\\t    Pipeline -->|Read config & region list| SSM\\\\n    32\\\\t    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    33\\\\t    Pipeline --> BucketB\\\\n    34\\\\t    Pipeline --> BucketC\\\\n    35\\\\t    Pulumi -->|pulumi up| Regions\\\\n    36\\\\t    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    37\\\\t    Tests --> IaC\\\\n    38\\\\t```\\\\n    39\\\\t\\\\n    40\\\\t### 1.2 コンポーネント間の関係\\\\n    41\\\\t- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n    42\\\\t- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョン���とのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n    43\\\\t- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n    44\\\\t- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n    45\\\\t\\\\n    46\\\\t### 1.3 データフロー\\\\n    47\\\\t1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n    48\\\\t2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n    49\\\\t3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n    50\\\\t4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n    51\\\\t   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n    52\\\\t   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n    53\\\\t   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n    54\\\\t5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n    55\\\\t\\\\n    56\\\\t## 2. 実装戦略: EXTEND\\\\n    57\\\\t\\\\n    58\\\\t**判断根拠**:\\\\n    59\\\\t- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n    60\\\\t- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n    61\\\\t\\\\n    62\\\\t## 3. テスト戦略: UNIT_INTEGRATION\\\\n    63\\\\t\\\\n    64\\\\t**判断根拠**:\\\\n    65\\\\t- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n    66\\\\t- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n    67\\\\t\\\\n    68\\\\t## 4. テストコード戦略: CREATE_TEST\\\\n    69\\\\t\\\\n    70\\\\t**判断根拠**:\\\\n    71\\\\t- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n    72\\\\t- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n    73\\\\t\\\\n    74\\\\t## 5. 影響範囲分析\\\\n    75\\\\t- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n    76\\\\t- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n    77\\\\t- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n    78\\\\t- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n    79\\\\t- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n    80\\\\t- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n    81\\\\t\\\\n    82\\\\t## 6. 変更・追加ファイルリスト\\\\n    83\\\\t| 区分 | ファイル/パス | 目的 |\\\\n    84\\\\t| ---- | ------------- | ---- |\\\\n    85\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n    86\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n    87\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n    88\\\\t| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n    89\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n    90\\\\t| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n    91\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n    92\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n    93\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n    94\\\\t| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n    95\\\\t| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n    96\\\\t\\\\n    97\\\\t## 7. 詳細設計\\\\n    98\\\\t\\\\n    99\\\\t### 7.1 Pulumi (IaC) 詳細\\\\n   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n   141\\\\t  1. `stage('Initialize')`\\\\n   142\\\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n   143\\\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n   144\\\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n   145\\\\t  2. `stage('Prepare Scripts')`\\\\n   146\\\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n   147\\\\t  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n   148\\\\t     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n   149\\\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n   150\\\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n   151\\\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n   152\\\\t  4. `stage('Finalize Report')`\\\\n   153\\\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n   154\\\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n   155\\\\t- **エラー制御**\\\\n   156\\\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n   157\\\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n   158\\\\t- **メトリクス／ログ**\\\\n   159\\\\t  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n   160\\\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:458:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_13\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '100,200p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n   141\\\\t  1. `stage('Initialize')`\\\\n   142\\\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n   143\\\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n   144\\\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n   145\\\\t  2. `stage('Prepare Scripts')`\\\\n   146\\\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n   147\\\\t  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n   148\\\\t     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n   149\\\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n   150\\\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n   151\\\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n   152\\\\t  4. `stage('Finalize Report')`\\\\n   153\\\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n   154\\\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n   155\\\\t- **エラー制御**\\\\n   156\\\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n   157\\\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n   158\\\\t- **メトリクス／ログ**\\\\n   159\\\\t  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n   160\\\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n   161\\\\t\\\\n   162\\\\t### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n   163\\\\t- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n   164\\\\t- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n   165\\\\t- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n   166\\\\t\\\\n   167\\\\t### 7.4 `collect_parameters.sh`\\\\n   168\\\\t- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n   169\\\\t- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n   170\\\\t- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n   171\\\\t\\\\n   172\\\\t### 7.5 テスト設計詳細\\\\n   173\\\\t- **Pulumi (Jest)**  \\\\n   174\\\\t  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n   175\\\\t  - 期待事項:  \\\\n   176\\\\t    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n   177\\\\t    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n   178\\\\t    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n   179\\\\t    - `bucketMap` エクスポートが全リージョンを包含。\\\\n   180\\\\t- **Jenkins (jenkinsfile-runner)**  \\\\n   181\\\\t  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n   182\\\\t  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n   183\\\\t  - 検証点:  \\\\n   184\\\\t    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n   185\\\\t    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n   186\\\\t    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n   187\\\\t- **Manual テスト**  \\\\n   188\\\\t  - `pulumi preview` で各リージョンの差分を確認。  \\\\n   189\\\\t  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n   190\\\\t  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n   191\\\\t  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n   192\\\\t\\\\n   193\\\\t### 7.6 トレーサビリティ\\\\n   194\\\\t| 要件ID | 設計上の対応箇所 |\\\\n   195\\\\t| ------ | ---------------- |\\\\n   196\\\\t| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n   197\\\\t| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n   198\\\\t| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n   199\\\\t| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n   200\\\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:460:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_14\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '60,120p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"    60\\\\t- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n    61\\\\t\\\\n    62\\\\t## 3. テスト戦略: UNIT_INTEGRATION\\\\n    63\\\\t\\\\n    64\\\\t**判断根拠**:\\\\n    65\\\\t- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n    66\\\\t- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n    67\\\\t\\\\n    68\\\\t## 4. テストコード戦略: CREATE_TEST\\\\n    69\\\\t\\\\n    70\\\\t**判断根拠**:\\\\n    71\\\\t- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n    72\\\\t- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n    73\\\\t\\\\n    74\\\\t## 5. 影響範囲分析\\\\n    75\\\\t- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n    76\\\\t- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n    77\\\\t- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n    78\\\\t- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n    79\\\\t- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n    80\\\\t- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n    81\\\\t\\\\n    82\\\\t## 6. 変更・追加ファイルリスト\\\\n    83\\\\t| 区分 | ファイル/パス | 目的 |\\\\n    84\\\\t| ---- | ------------- | ---- |\\\\n    85\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n    86\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n    87\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n    88\\\\t| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n    89\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n    90\\\\t| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n    91\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n    92\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n    93\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n    94\\\\t| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n    95\\\\t| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n    96\\\\t\\\\n    97\\\\t## 7. 詳細設計\\\\n    98\\\\t\\\\n    99\\\\t### 7.1 Pulumi (IaC) 詳細\\\\n   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:492:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:494:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && sed -n '1,160p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:502:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_9\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && sed -n '80,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:537:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:575:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_1\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:583:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:589:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_8\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"@Library('jenkins-shared-lib') _\\\\n\\\\n/**\\\\n * SSM Parameter Store Backup Pipeline\\\\n * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\\\\n */\\\\npipeline {\\\\n    agent {\\\\n        label 'ec2-fleet'\\\\n    }\\\\n    \\\\n    options {\\\\n        timestamps()\\\\n        timeout(time: 1, unit: 'HOURS')\\\\n        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\\\\n        disableConcurrentBuilds()\\\\n    }\\\\n    \\\\n    environment {\\\\n        // AWS設定\\\\n        AWS_REGION = 'ap-northeast-1'\\\\n        \\\\n        // タイムスタンプ\\\\n        BACKUP_DATE = sh(script: \\\\\\\"date '+%Y-%m-%d'\\\\\\\", returnStdout: true).trim()\\\\n        BACKUP_TIMESTAMP = sh(script: \\\\\\\"date '+%Y%m%d_%H%M%S'\\\\\\\", returnStdout: true).trim()\\\\n        \\\\n        // ディレクトリ構造\\\\n        WORK_DIR = \\\\\\\"${WORKSPACE}/backup-work\\\\\\\"\\\\n        DATA_DIR = \\\\\\\"${WORK_DIR}/data\\\\\\\"\\\\n        SCRIPT_DIR = \\\\\\\"${WORKSPACE}/scripts\\\\\\\"\\\\n        \\\\n        // 環境フィルタ（環境に含まれる文字列）\\\\n        ENV_FILTER = \\\\\\\"/${params.ENVIRONMENT}/\\\\\\\"\\\\n    }\\\\n    \\\\n    stages {\\\\n        stage('Initialize') {\\\\n            steps {\\\\n                script {\\\\n                    // ビルド表示名を設定\\\\n                    currentBuild.displayName = \\\\\\\"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\\\\\\\"\\\\n                    currentBuild.description = \\\\\\\"Backup at ${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    SSM Parameter Store Backup\\\\n                    =============================================\\\\n                    Environment: ${params.ENVIRONMENT}\\\\n                    Filter: Parameters containing '${env.ENV_FILTER}'\\\\n                    Dry Run: ${params.DRY_RUN}\\\\n                    Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                    Date: ${env.BACKUP_DATE}\\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // 作業ディレクトリの準備\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        rm -rf ${WORK_DIR}\\\\n                        mkdir -p ${DATA_DIR}\\\\n                        mkdir -p ${SCRIPT_DIR}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // S3バケット名の取得\\\\n                    env.BACKUP_BUCKET = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws ssm get-parameter \\\\\\\\\\\\n                                --name \\\\\\\"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\\\\\\\" \\\\\\\\\\\\n                                --query 'Parameter.Value' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION} 2>/dev/null || echo \\\\\\\"\\\\\\\"\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    if (!env.BACKUP_BUCKET) {\\\\n                        error(\\\\\\\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\\\\\\\")\\\\n                    }\\\\n                    \\\\n                    echo \\\\\\\"Backup S3 Bucket: ${env.BACKUP_BUCKET}\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Prepare Scripts') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Preparing Collection Scripts ===\\\\\\\"\\\\n                    \\\\n                    // Jenkinsリポジトリをチェックアウト\\\\n                    dir('jenkins-repo') {\\\\n                        checkout([\\\\n                            $class: 'GitSCM',\\\\n                            branches: [[name: \\\\\\\"${params.JENKINSFILE_BRANCH}\\\\\\\"]],\\\\n                            userRemoteConfigs: [[\\\\n                                url: 'https://github.com/tielec/infrastructure-as-code',\\\\n                                credentialsId: 'github-app-credentials'\\\\n                            ]]\\\\n                        ])\\\\n                    }\\\\n                    \\\\n                    // スクリプトをコピー\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\\\\n                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\\\\n                        \\\\n                        echo \\\\\\\"Script copied and made executable\\\\\\\"\\\\n                        ls -la ${SCRIPT_DIR}/\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Collect Parameters') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Collecting SSM Parameters ===\\\\\\\"\\\\n                    \\\\n                    // スクリプトの実行\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        # 環境変数を設定\\\\n                        export ENVIRONMENT=\\\\\\\"${params.ENVIRONMENT}\\\\\\\"\\\\n                        export ENV_FILTER=\\\\\\\"${env.ENV_FILTER}\\\\\\\"\\\\n                        export AWS_REGION=\\\\\\\"${AWS_REGION}\\\\\\\"\\\\n                        export BACKUP_DATE=\\\\\\\"${env.BACKUP_DATE}\\\\\\\"\\\\n                        export BACKUP_TIMESTAMP=\\\\\\\"${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                        export DATA_DIR=\\\\\\\"${DATA_DIR}\\\\\\\"\\\\n                        \\\\n                        # スクリプト実行\\\\n                        ${SCRIPT_DIR}/collect_parameters.sh\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの確認\\\\n                    if (fileExists(\\\\\\\"${DATA_DIR}/backup.json\\\\\\\")) {\\\\n                        def backupData = readJSON file: \\\\\\\"${DATA_DIR}/backup.json\\\\\\\"\\\\n                        env.PARAM_COUNT = backupData.parameter_count.toString()\\\\n                        \\\\n                        if (backupData.parameter_count == 0) {\\\\n                            echo \\\\\\\"WARNING: No parameters found for backup\\\\\\\"\\\\n                            currentBuild.result = 'UNSTABLE'\\\\n                        } else {\\\\n                            echo \\\\\\\"Backup file contains ${backupData.parameter_count} parameters\\\\\\\"\\\\n                        }\\\\n                    } else {\\\\n                        error(\\\\\\\"Backup file was not created\\\\\\\")\\\\n                    }\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Upload to S3') {\\\\n            when {\\\\n                expression { \\\\n                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\\\\n                }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Uploading Backup to S3 ===\\\\\\\"\\\\n                    \\\\n                    def backupFileName = \\\\\\\"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\\\\"\\\\n                    def s3Key = \\\\\\\"${env.BACKUP_DATE}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの名前を変更\\\\n                    sh \\\\\\\"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // S3へアップロード（暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\\\\\\\\\\n                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\\\\\\\"\\\\n                    \\\\n                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        echo '${s3Key}' | \\\\\\\\\\\\n                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // アップロード確認\\\\n                    def s3ObjectInfo = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws s3api head-object \\\\\\\\\\\\n                                --bucket ${env.BACKUP_BUCKET} \\\\\\\\\\\\n                                --key ${s3Key} \\\\\\\\\\\\n                                --query '[ContentLength, LastModified]' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION}\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    echo \\\\\\\"S3 Object Info: ${s3ObjectInfo}\\\\\\\"\\\\n                    \\\\n                    // セキュリティ上の理由によりアーティファクトとしては保存しない\\\\n                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:591:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_9\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '200,400p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Dry Run Report') {\\\\n            when {\\\\n                expression { params.DRY_RUN }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    def paramCount = env.PARAM_COUNT ?: '0'\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    DRY RUN - バックアップ実行レポート\\\\n                    =============================================\\\\n                    \\\\n                    このドライランでは実際のS3アップロードは行われませんでした。\\\\n                    \\\\n                    バックアップ対象:\\\\n                    - 環境: ${params.ENVIRONMENT}\\\\n                    - パラメータ数: ${paramCount}\\\\n                    - バックアップ日時: ${env.BACKUP_TIMESTAMP}\\\\n                    \\\\n                    実行時の動作:\\\\n                    - S3バケット: ${env.BACKUP_BUCKET}\\\\n                    - S3パス: ${env.BACKUP_DATE}/\\\\n                    - ファイル名: ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\n                    \\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // セキュリティ上の理由によりドライラン時もアーティファクトとして保存しない\\\\n                }\\\\n            }\\\\n        }\\\\n    }\\\\n    \\\\n    post {\\\\n        always {\\\\n            script {\\\\n                def paramCount = env.PARAM_COUNT ?: '0'\\\\n                \\\\n                // 実行サマリーの表示\\\\n                echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                =============================================\\\\n                SSM Parameter Store Backup Summary\\\\n                =============================================\\\\n                Build: #${env.BUILD_NUMBER}\\\\n                Status: ${currentBuild.result ?: 'SUCCESS'}\\\\n                Environment: ${params.ENVIRONMENT}\\\\n                Parameters: ${paramCount}\\\\n                Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                Dry Run: ${params.DRY_RUN}\\\\n                =============================================\\\\n                \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n            }\\\\n        }\\\\n        \\\\n        success {\\\\n            echo \\\\\\\"✅ SSMパラメータのバックアップが正常に完了しました\\\\\\\"\\\\n        }\\\\n        \\\\n        failure {\\\\n            echo \\\\\\\"❌ バックアップが失敗しました。ログを確認してください\\\\\\\"\\\\n        }\\\\n        \\\\n        unstable {\\\\n            echo \\\\\\\"⚠️ バックアップは完了しましたが、警告があります\\\\\\\"\\\\n        }\\\\n        \\\\n        cleanup {\\\\n            // 作業ディレクトリのクリーンアップ\\\\n            sh \\\\\\\"rm -rf ${WORK_DIR} ${SCRIPT_DIR} jenkins-repo || true\\\\\\\"\\\\n        }\\\\n    }\\\\n}\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:609:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_18\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '110,210p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:619:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_23\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '60,130p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:622:[CODEX EVENT] {\\\"type\\\":\\\"item.started\\\",\\\"item\\\":{\\\"id\\\":\\\"item_25\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'grep -R \\\\\\\"SSM Parameter Store Backup\\\\\\\" -n'\\\",\\\"aggregated_output\\\":\\\"\\\",\\\"status\\\":\\\"in_progress\\\"}}\\npulumi/jenkins-ssm-backup-s3/index.ts:44:        Purpose: \\\"SSM Parameter Store Backup Storage\\\",\\njenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile:4: * SSM Parameter Store Backup Pipeline\\njenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile:46:                    SSM Parameter Store Backup\\njenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile:247:                SSM Parameter Store Backup Summary\\njenkins/jobs/pipeline/_seed/job-creator/job-config.yaml:70:  # SSM Parameter Store Backup Jobs\\njenkins/jobs/pipeline/_seed/job-creator/job-config.yaml:73:    displayName: 'SSM Parameter Store Backup'\\n.ai-workflow/issue-391/03_test_scenario/review/agent_log_raw.txt:12:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/03_test_scenario/execute/agent_log.md:375:        Purpose: \\\"SSM Parameter Store Backup Storage\\\",\\n.ai-workflow/issue-391/03_test_scenario/execute/agent_log.md:589:  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/03_test_scenario/execute/agent_log_raw.txt:12:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/03_test_scenario/execute/agent_log_raw.txt:14:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && sed -n '1,160p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/03_test_scenario/execute/agent_log_raw.txt:22:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_9\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && sed -n '80,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log.md:259:  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/revise/agent_log.md:416:タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/revise/agent_log.md:606:タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/revise/agent_log.md:868:120\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/revise/agent_log.md:1024:   120\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:8:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_2\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Declarative Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、各リージョンを逐次ステージ化してバックアップ処理・S3 へのアップロード・ログ集計を実施。失敗時は後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. `Regional Backup Orchestrator` ステージの Imperative ブロックがリージョンごとにサブステージを生成。各サブステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:18:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_7\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '80,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:26:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_12\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '120,170p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:31:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_16\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '40,120p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:40:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_22\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '120,220p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` 内で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` で取得し、存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `collect_parameters.sh` 実行結果 (`results/summary.json`) から `parameterCount` を読み取り、S3 へアップロードするアーティファクトパスを返す。\\\\n  - 取得結果は `return [bucket: ..., dataDir: ..., summaryPath: ...]` のように Map で返却し、ループ内で使い回す。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `loadRegionContext(region)` を呼び出し、取得したバケット名でアップロード。DRY_RUN 時は `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: ctx.parameterCount, artifactPath: ctx.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、同梱の簡易 HTTP サーバで受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:51:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_30\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,120p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:53:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_31\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '120,220p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n   141\\\\t  1. `stage('Initialize')`\\\\n   142\\\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n   143\\\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n   144\\\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n   145\\\\t  2. `stage('Prepare Scripts')`\\\\n   146\\\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n   147\\\\t  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n   148\\\\t     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n   149\\\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n   150\\\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n   151\\\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n   152\\\\t  4. `stage('Finalize Report')`\\\\n   153\\\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n   154\\\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n   155\\\\t- **エラー制御**\\\\n   156\\\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n   157\\\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n   158\\\\t- **メトリクス／ログ**\\\\n   159\\\\t  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n   160\\\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n   161\\\\t\\\\n   162\\\\t### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n   163\\\\t- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n   164\\\\t- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n   165\\\\t- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n   166\\\\t\\\\n   167\\\\t### 7.4 `collect_parameters.sh`\\\\n   168\\\\t- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n   169\\\\t- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n   170\\\\t- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n   171\\\\t\\\\n   172\\\\t### 7.5 テスト設計詳細\\\\n   173\\\\t- **Pulumi (Jest)**  \\\\n   174\\\\t  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n   175\\\\t  - 期待事項:  \\\\n   176\\\\t    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n   177\\\\t    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n   178\\\\t    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n   179\\\\t    - `bucketMap` エクスポートが全リージョンを包含。\\\\n   180\\\\t- **Jenkins (jenkinsfile-runner)**  \\\\n   181\\\\t  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n   182\\\\t  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n   183\\\\t  - 検証点:  \\\\n   184\\\\t    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n   185\\\\t    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n   186\\\\t    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n   187\\\\t- **Manual テスト**  \\\\n   188\\\\t  - `pulumi preview` で各リージョンの差分を確認。  \\\\n   189\\\\t  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n   190\\\\t  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n   191\\\\t  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n   192\\\\t\\\\n   193\\\\t### 7.6 トレーサビリティ\\\\n   194\\\\t| 要件ID | 設計上の対応箇所 |\\\\n   195\\\\t| ------ | ---------------- |\\\\n   196\\\\t| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n   197\\\\t| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n   198\\\\t| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n   199\\\\t| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n   200\\\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n   201\\\\t\\\\n   202\\\\t### 7.7 通知計画 (FR-5)\\\\n   203\\\\t- **対象者**  \\\\n   204\\\\t  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n   205\\\\t  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n   206\\\\t- **チャネル**  \\\\n   207\\\\t  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n   208\\\\t  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n   209\\\\t- **タイミング**  \\\\n   210\\\\t  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n   211\\\\t  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n   212\\\\t  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n   213\\\\t- **責任者**  \\\\n   214\\\\t  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n   215\\\\t  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n   216\\\\t  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n   217\\\\t- **テスト/検証**  \\\\n   218\\\\t  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n   219\\\\t  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n   220\\\\t- **Runbook 更新**  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:57:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_33\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '80,140p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"    80\\\\t- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n    81\\\\t\\\\n    82\\\\t## 6. 変更・追加ファイルリスト\\\\n    83\\\\t| 区分 | ファイル/パス | 目的 |\\\\n    84\\\\t| ---- | ------------- | ---- |\\\\n    85\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n    86\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n    87\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n    88\\\\t| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n    89\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n    90\\\\t| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n    91\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n    92\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n    93\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n    94\\\\t| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n    95\\\\t| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n    96\\\\t\\\\n    97\\\\t## 7. 詳細設計\\\\n    98\\\\t\\\\n    99\\\\t### 7.1 Pulumi (IaC) 詳細\\\\n   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log.md:316:  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/review/agent_log.md:396:タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/review/agent_log.md:494:  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/review/agent_log.md:790:   120\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/review/agent_log.md:890:   120\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:14:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニ���トテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作���ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:16:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_6\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '60,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:20:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_8\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '120,260p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:22:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_9\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '80,180p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:26:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_11\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '1,160p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"     1\\\\t# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n     2\\\\t\\\\n     3\\\\t## 1. アーキテクチャ設計\\\\n     4\\\\t\\\\n     5\\\\t### 1.1 システム全体図\\\\n     6\\\\t```mermaid\\\\n     7\\\\tflowchart TD\\\\n     8\\\\t    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n     9\\\\t        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n    10\\\\t        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n    11\\\\t        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    12\\\\t    end\\\\n    13\\\\t\\\\n    14\\\\t    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n    15\\\\t        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n    16\\\\t        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n    17\\\\t            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n    18\\\\t            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n    19\\\\t            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n    20\\\\t        end\\\\n    21\\\\t    end\\\\n    22\\\\t\\\\n    23\\\\t    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n    24\\\\t        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n    25\\\\t        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n    26\\\\t        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    27\\\\t    end\\\\n    28\\\\t\\\\n    29\\\\t    DSL -->|SCM sync| Pipeline\\\\n    30\\\\t    Pipeline -->|fetch| Script\\\\n    31\\\\t    Pipeline -->|Read config & region list| SSM\\\\n    32\\\\t    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    33\\\\t    Pipeline --> BucketB\\\\n    34\\\\t    Pipeline --> BucketC\\\\n    35\\\\t    Pulumi -->|pulumi up| Regions\\\\n    36\\\\t    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    37\\\\t    Tests --> IaC\\\\n    38\\\\t```\\\\n    39\\\\t\\\\n    40\\\\t### 1.2 コンポーネント間の関係\\\\n    41\\\\t- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n    42\\\\t- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n    43\\\\t- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n    44\\\\t- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n    45\\\\t\\\\n    46\\\\t### 1.3 データフロー\\\\n    47\\\\t1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n    48\\\\t2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n    49\\\\t3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n    50\\\\t4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n    51\\\\t   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n    52\\\\t   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n    53\\\\t   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n    54\\\\t5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n    55\\\\t\\\\n    56\\\\t## 2. 実装戦略: EXTEND\\\\n    57\\\\t\\\\n    58\\\\t**判断根拠**:\\\\n    59\\\\t- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n    60\\\\t- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n    61\\\\t\\\\n    62\\\\t## 3. テスト戦略: UNIT_INTEGRATION\\\\n    63\\\\t\\\\n    64\\\\t**判断根拠**:\\\\n    65\\\\t- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n    66\\\\t- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n    67\\\\t\\\\n    68\\\\t## 4. テストコード戦略: CREATE_TEST\\\\n    69\\\\t\\\\n    70\\\\t**判断根拠**:\\\\n    71\\\\t- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n    72\\\\t- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n    73\\\\t\\\\n    74\\\\t## 5. 影響範囲分析\\\\n    75\\\\t- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n    76\\\\t- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n    77\\\\t- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n    78\\\\t- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n    79\\\\t- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n    80\\\\t- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n    81\\\\t\\\\n    82\\\\t## 6. 変更・追加ファイルリスト\\\\n    83\\\\t| 区分 | ファイル/パス | 目的 |\\\\n    84\\\\t| ---- | ------------- | ---- |\\\\n    85\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n    86\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n    87\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n    88\\\\t| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n    89\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n    90\\\\t| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n    91\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n    92\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n    93\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n    94\\\\t| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n    95\\\\t| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n    96\\\\t\\\\n    97\\\\t## 7. 詳細設計\\\\n    98\\\\t\\\\n    99\\\\t### 7.1 Pulumi (IaC) 詳細\\\\n   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n   141\\\\t  1. `stage('Initialize')`\\\\n   142\\\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n   143\\\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n   144\\\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n   145\\\\t  2. `stage('Prepare Scripts')`\\\\n   146\\\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n   147\\\\t  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n   148\\\\t     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n   149\\\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n   150\\\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n   151\\\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n   152\\\\t  4. `stage('Finalize Report')`\\\\n   153\\\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n   154\\\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n   155\\\\t- **エラー制御**\\\\n   156\\\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n   157\\\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n   158\\\\t- **メトリクス／ログ**\\\\n   159\\\\t  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n   160\\\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:30:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_13\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '100,200p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n   141\\\\t  1. `stage('Initialize')`\\\\n   142\\\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n   143\\\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n   144\\\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n   145\\\\t  2. `stage('Prepare Scripts')`\\\\n   146\\\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n   147\\\\t  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n   148\\\\t     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n   149\\\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n   150\\\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n   151\\\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n   152\\\\t  4. `stage('Finalize Report')`\\\\n   153\\\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n   154\\\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n   155\\\\t- **エラー制御**\\\\n   156\\\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n   157\\\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n   158\\\\t- **メトリクス／ログ**\\\\n   159\\\\t  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n   160\\\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n   161\\\\t\\\\n   162\\\\t### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n   163\\\\t- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n   164\\\\t- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n   165\\\\t- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n   166\\\\t\\\\n   167\\\\t### 7.4 `collect_parameters.sh`\\\\n   168\\\\t- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n   169\\\\t- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n   170\\\\t- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n   171\\\\t\\\\n   172\\\\t### 7.5 テスト設計詳細\\\\n   173\\\\t- **Pulumi (Jest)**  \\\\n   174\\\\t  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n   175\\\\t  - 期待事項:  \\\\n   176\\\\t    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n   177\\\\t    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n   178\\\\t    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n   179\\\\t    - `bucketMap` エクスポートが全リージョンを包含。\\\\n   180\\\\t- **Jenkins (jenkinsfile-runner)**  \\\\n   181\\\\t  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n   182\\\\t  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n   183\\\\t  - 検証点:  \\\\n   184\\\\t    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n   185\\\\t    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n   186\\\\t    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n   187\\\\t- **Manual テスト**  \\\\n   188\\\\t  - `pulumi preview` で各リージョンの差分を確認。  \\\\n   189\\\\t  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n   190\\\\t  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n   191\\\\t  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n   192\\\\t\\\\n   193\\\\t### 7.6 トレーサビリティ\\\\n   194\\\\t| 要件ID | 設計上の対応箇所 |\\\\n   195\\\\t| ------ | ---------------- |\\\\n   196\\\\t| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n   197\\\\t| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n   198\\\\t| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n   199\\\\t| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n   200\\\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:32:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_14\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '60,120p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"    60\\\\t- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n    61\\\\t\\\\n    62\\\\t## 3. テスト戦略: UNIT_INTEGRATION\\\\n    63\\\\t\\\\n    64\\\\t**判断根拠**:\\\\n    65\\\\t- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n    66\\\\t- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n    67\\\\t\\\\n    68\\\\t## 4. テストコード戦略: CREATE_TEST\\\\n    69\\\\t\\\\n    70\\\\t**判断根拠**:\\\\n    71\\\\t- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n    72\\\\t- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n    73\\\\t\\\\n    74\\\\t## 5. 影響範囲分析\\\\n    75\\\\t- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n    76\\\\t- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n    77\\\\t- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n    78\\\\t- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n    79\\\\t- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n    80\\\\t- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n    81\\\\t\\\\n    82\\\\t## 6. 変更・追加ファイルリスト\\\\n    83\\\\t| 区分 | ファイル/パス | 目的 |\\\\n    84\\\\t| ---- | ------------- | ---- |\\\\n    85\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n    86\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n    87\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n    88\\\\t| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n    89\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n    90\\\\t| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n    91\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n    92\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n    93\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n    94\\\\t| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n    95\\\\t| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n    96\\\\t\\\\n    97\\\\t## 7. 詳細設計\\\\n    98\\\\t\\\\n    99\\\\t### 7.1 Pulumi (IaC) 詳細\\\\n   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/execute/agent_log.md:264:        Purpose: \\\"SSM Parameter Store Backup Storage\\\",\\n.ai-workflow/issue-391/02_design/execute/agent_log.md:344: * SSM Parameter Store Backup Pipeline\\n.ai-workflow/issue-391/02_design/execute/agent_log.md:386:                    SSM Parameter Store Backup\\n.ai-workflow/issue-391/02_design/execute/agent_log.md:504:                SSM Parameter Store Backup Summary\\n.ai-workflow/issue-391/02_design/execute/agent_log_raw.txt:10:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/execute/agent_log_raw.txt:12:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"@Library('jenkins-shared-lib') _\\\\n\\\\n/**\\\\n * SSM Parameter Store Backup Pipeline\\\\n * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\\\\n */\\\\npipeline {\\\\n    agent {\\\\n        label 'ec2-fleet'\\\\n    }\\\\n    \\\\n    options {\\\\n        timestamps()\\\\n        timeout(time: 1, unit: 'HOURS')\\\\n        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\\\\n        disableConcurrentBuilds()\\\\n    }\\\\n    \\\\n    environment {\\\\n        // AWS設定\\\\n        AWS_REGION = 'ap-northeast-1'\\\\n        \\\\n        // タイムスタンプ\\\\n        BACKUP_DATE = sh(script: \\\\\\\"date '+%Y-%m-%d'\\\\\\\", returnStdout: true).trim()\\\\n        BACKUP_TIMESTAMP = sh(script: \\\\\\\"date '+%Y%m%d_%H%M%S'\\\\\\\", returnStdout: true).trim()\\\\n        \\\\n        // ディレクトリ構造\\\\n        WORK_DIR = \\\\\\\"${WORKSPACE}/backup-work\\\\\\\"\\\\n        DATA_DIR = \\\\\\\"${WORK_DIR}/data\\\\\\\"\\\\n        SCRIPT_DIR = \\\\\\\"${WORKSPACE}/scripts\\\\\\\"\\\\n        \\\\n        // 環境フィルタ（環境に含まれる文字列）\\\\n        ENV_FILTER = \\\\\\\"/${params.ENVIRONMENT}/\\\\\\\"\\\\n    }\\\\n    \\\\n    stages {\\\\n        stage('Initialize') {\\\\n            steps {\\\\n                script {\\\\n                    // ビルド表示名を設定\\\\n                    currentBuild.displayName = \\\\\\\"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\\\\\\\"\\\\n                    currentBuild.description = \\\\\\\"Backup at ${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    SSM Parameter Store Backup\\\\n                    =============================================\\\\n                    Environment: ${params.ENVIRONMENT}\\\\n                    Filter: Parameters containing '${env.ENV_FILTER}'\\\\n                    Dry Run: ${params.DRY_RUN}\\\\n                    Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                    Date: ${env.BACKUP_DATE}\\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // 作業ディレクトリの準備\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        rm -rf ${WORK_DIR}\\\\n                        mkdir -p ${DATA_DIR}\\\\n                        mkdir -p ${SCRIPT_DIR}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // S3バケット名の取得\\\\n                    env.BACKUP_BUCKET = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws ssm get-parameter \\\\\\\\\\\\n                                --name \\\\\\\"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\\\\\\\" \\\\\\\\\\\\n                                --query 'Parameter.Value' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION} 2>/dev/null || echo \\\\\\\"\\\\\\\"\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    if (!env.BACKUP_BUCKET) {\\\\n                        error(\\\\\\\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\\\\\\\")\\\\n                    }\\\\n                    \\\\n                    echo \\\\\\\"Backup S3 Bucket: ${env.BACKUP_BUCKET}\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Prepare Scripts') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Preparing Collection Scripts ===\\\\\\\"\\\\n                    \\\\n                    // Jenkinsリポジトリをチェックアウト\\\\n                    dir('jenkins-repo') {\\\\n                        checkout([\\\\n                            $class: 'GitSCM',\\\\n                            branches: [[name: \\\\\\\"${params.JENKINSFILE_BRANCH}\\\\\\\"]],\\\\n                            userRemoteConfigs: [[\\\\n                                url: 'https://github.com/tielec/infrastructure-as-code',\\\\n                                credentialsId: 'github-app-credentials'\\\\n                            ]]\\\\n                        ])\\\\n                    }\\\\n                    \\\\n                    // スクリプトをコピー\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\\\\n                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\\\\n                        \\\\n                        echo \\\\\\\"Script copied and made executable\\\\\\\"\\\\n                        ls -la ${SCRIPT_DIR}/\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Collect Parameters') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Collecting SSM Parameters ===\\\\\\\"\\\\n                    \\\\n                    // スクリプトの実行\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        # 環境変数を設定\\\\n                        export ENVIRONMENT=\\\\\\\"${params.ENVIRONMENT}\\\\\\\"\\\\n                        export ENV_FILTER=\\\\\\\"${env.ENV_FILTER}\\\\\\\"\\\\n                        export AWS_REGION=\\\\\\\"${AWS_REGION}\\\\\\\"\\\\n                        export BACKUP_DATE=\\\\\\\"${env.BACKUP_DATE}\\\\\\\"\\\\n                        export BACKUP_TIMESTAMP=\\\\\\\"${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                        export DATA_DIR=\\\\\\\"${DATA_DIR}\\\\\\\"\\\\n                        \\\\n                        # スクリプト実行\\\\n                        ${SCRIPT_DIR}/collect_parameters.sh\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの確認\\\\n                    if (fileExists(\\\\\\\"${DATA_DIR}/backup.json\\\\\\\")) {\\\\n                        def backupData = readJSON file: \\\\\\\"${DATA_DIR}/backup.json\\\\\\\"\\\\n                        env.PARAM_COUNT = backupData.parameter_count.toString()\\\\n                        \\\\n                        if (backupData.parameter_count == 0) {\\\\n                            echo \\\\\\\"WARNING: No parameters found for backup\\\\\\\"\\\\n                            currentBuild.result = 'UNSTABLE'\\\\n                        } else {\\\\n                            echo \\\\\\\"Backup file contains ${backupData.parameter_count} parameters\\\\\\\"\\\\n                        }\\\\n                    } else {\\\\n                        error(\\\\\\\"Backup file was not created\\\\\\\")\\\\n                    }\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Upload to S3') {\\\\n            when {\\\\n                expression { \\\\n                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\\\\n                }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Uploading Backup to S3 ===\\\\\\\"\\\\n                    \\\\n                    def backupFileName = \\\\\\\"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\\\\"\\\\n                    def s3Key = \\\\\\\"${env.BACKUP_DATE}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの名前を変更\\\\n                    sh \\\\\\\"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // S3へアップロード（暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\\\\\\\\\\n                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\\\\\\\"\\\\n                    \\\\n                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        echo '${s3Key}' | \\\\\\\\\\\\n                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // アップロード確認\\\\n                    def s3ObjectInfo = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws s3api head-object \\\\\\\\\\\\n                                --bucket ${env.BACKUP_BUCKET} \\\\\\\\\\\\n                                --key ${s3Key} \\\\\\\\\\\\n                                --query '[ContentLength, LastModified]' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION}\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    echo \\\\\\\"S3 Object Info: ${s3ObjectInfo}\\\\\\\"\\\\n                    \\\\n                    // セキュリティ上の理由によりアーティファクトとしては保存しない\\\\n                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/execute/agent_log_raw.txt:14:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '200,400p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Dry Run Report') {\\\\n            when {\\\\n                expression { params.DRY_RUN }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    def paramCount = env.PARAM_COUNT ?: '0'\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    DRY RUN - バックアップ実行レポート\\\\n                    =============================================\\\\n                    \\\\n                    このドライランでは実際のS3アップロードは行われませんでした。\\\\n                    \\\\n                    バックアップ対象:\\\\n                    - 環境: ${params.ENVIRONMENT}\\\\n                    - パラメータ数: ${paramCount}\\\\n                    - バックアップ日時: ${env.BACKUP_TIMESTAMP}\\\\n                    \\\\n                    実行時の動作:\\\\n                    - S3バケット: ${env.BACKUP_BUCKET}\\\\n                    - S3パス: ${env.BACKUP_DATE}/\\\\n                    - ファイル名: ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\n                    \\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // セキュリティ上の理由によりドライラン時もアーティファクトとして保存しない\\\\n                }\\\\n            }\\\\n        }\\\\n    }\\\\n    \\\\n    post {\\\\n        always {\\\\n            script {\\\\n                def paramCount = env.PARAM_COUNT ?: '0'\\\\n                \\\\n                // 実行サマリーの表示\\\\n                echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                =============================================\\\\n                SSM Parameter Store Backup Summary\\\\n                =============================================\\\\n                Build: #${env.BUILD_NUMBER}\\\\n                Status: ${currentBuild.result ?: 'SUCCESS'}\\\\n                Environment: ${params.ENVIRONMENT}\\\\n                Parameters: ${paramCount}\\\\n                Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                Dry Run: ${params.DRY_RUN}\\\\n                =============================================\\\\n                \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n            }\\\\n        }\\\\n        \\\\n        success {\\\\n            echo \\\\\\\"✅ SSMパラメータのバックアップが正常に完了しました\\\\\\\"\\\\n        }\\\\n        \\\\n        failure {\\\\n            echo \\\\\\\"❌ バックアップが失敗しました。ログを確認してください\\\\\\\"\\\\n        }\\\\n        \\\\n        unstable {\\\\n            echo \\\\\\\"⚠️ バックアップは完了しましたが、警告があります\\\\\\\"\\\\n        }\\\\n        \\\\n        cleanup {\\\\n            // 作業ディレクトリのクリーンアップ\\\\n            sh \\\\\\\"rm -rf ${WORK_DIR} ${SCRIPT_DIR} jenkins-repo || true\\\\\\\"\\\\n        }\\\\n    }\\\\n}\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/output/design.md:120:  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/00_planning/execute/agent_log.md:81:        Purpose: \\\"SSM Parameter Store Backup Storage\\\",\\n.ai-workflow/issue-391/00_planning/execute/agent_log.md:241: * SSM Parameter Store Backup Pipeline\\n.ai-workflow/issue-391/00_planning/execute/agent_log.md:283:                    SSM Parameter Store Backup\\n.ai-workflow/issue-391/00_planning/execute/agent_log.md:401:                SSM Parameter Store Backup Summary\\n.ai-workflow/issue-391/00_planning/execute/agent_log_raw.txt:6:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_1\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,160p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/00_planning/execute/agent_log_raw.txt:10:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"@Library('jenkins-shared-lib') _\\\\n\\\\n/**\\\\n * SSM Parameter Store Backup Pipeline\\\\n * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\\\\n */\\\\npipeline {\\\\n    agent {\\\\n        label 'ec2-fleet'\\\\n    }\\\\n    \\\\n    options {\\\\n        timestamps()\\\\n        timeout(time: 1, unit: 'HOURS')\\\\n        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\\\\n        disableConcurrentBuilds()\\\\n    }\\\\n    \\\\n    environment {\\\\n        // AWS設定\\\\n        AWS_REGION = 'ap-northeast-1'\\\\n        \\\\n        // タイムスタンプ\\\\n        BACKUP_DATE = sh(script: \\\\\\\"date '+%Y-%m-%d'\\\\\\\", returnStdout: true).trim()\\\\n        BACKUP_TIMESTAMP = sh(script: \\\\\\\"date '+%Y%m%d_%H%M%S'\\\\\\\", returnStdout: true).trim()\\\\n        \\\\n        // ディレクトリ構造\\\\n        WORK_DIR = \\\\\\\"${WORKSPACE}/backup-work\\\\\\\"\\\\n        DATA_DIR = \\\\\\\"${WORK_DIR}/data\\\\\\\"\\\\n        SCRIPT_DIR = \\\\\\\"${WORKSPACE}/scripts\\\\\\\"\\\\n        \\\\n        // 環境フィルタ（環境に含まれる文字列）\\\\n        ENV_FILTER = \\\\\\\"/${params.ENVIRONMENT}/\\\\\\\"\\\\n    }\\\\n    \\\\n    stages {\\\\n        stage('Initialize') {\\\\n            steps {\\\\n                script {\\\\n                    // ビルド表示名を設定\\\\n                    currentBuild.displayName = \\\\\\\"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\\\\\\\"\\\\n                    currentBuild.description = \\\\\\\"Backup at ${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    SSM Parameter Store Backup\\\\n                    =============================================\\\\n                    Environment: ${params.ENVIRONMENT}\\\\n                    Filter: Parameters containing '${env.ENV_FILTER}'\\\\n                    Dry Run: ${params.DRY_RUN}\\\\n                    Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                    Date: ${env.BACKUP_DATE}\\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // 作業ディレクトリの準備\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        rm -rf ${WORK_DIR}\\\\n                        mkdir -p ${DATA_DIR}\\\\n                        mkdir -p ${SCRIPT_DIR}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // S3バケット名の取得\\\\n                    env.BACKUP_BUCKET = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws ssm get-parameter \\\\\\\\\\\\n                                --name \\\\\\\"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\\\\\\\" \\\\\\\\\\\\n                                --query 'Parameter.Value' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION} 2>/dev/null || echo \\\\\\\"\\\\\\\"\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    if (!env.BACKUP_BUCKET) {\\\\n                        error(\\\\\\\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\\\\\\\")\\\\n                    }\\\\n                    \\\\n                    echo \\\\\\\"Backup S3 Bucket: ${env.BACKUP_BUCKET}\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Prepare Scripts') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Preparing Collection Scripts ===\\\\\\\"\\\\n                    \\\\n                    // Jenkinsリポジトリをチェックアウト\\\\n                    dir('jenkins-repo') {\\\\n                        checkout([\\\\n                            $class: 'GitSCM',\\\\n                            branches: [[name: \\\\\\\"${params.JENKINSFILE_BRANCH}\\\\\\\"]],\\\\n                            userRemoteConfigs: [[\\\\n                                url: 'https://github.com/tielec/infrastructure-as-code',\\\\n                                credentialsId: 'github-app-credentials'\\\\n                            ]]\\\\n                        ])\\\\n                    }\\\\n                    \\\\n                    // スクリプトをコピー\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\\\\n                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\\\\n                        \\\\n                        echo \\\\\\\"Script copied and made executable\\\\\\\"\\\\n                        ls -la ${SCRIPT_DIR}/\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Collect Parameters') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Collecting SSM Parameters ===\\\\\\\"\\\\n                    \\\\n                    // スクリプトの実行\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        # 環境変数を設定\\\\n                        export ENVIRONMENT=\\\\\\\"${params.ENVIRONMENT}\\\\\\\"\\\\n                        export ENV_FILTER=\\\\\\\"${env.ENV_FILTER}\\\\\\\"\\\\n                        export AWS_REGION=\\\\\\\"${AWS_REGION}\\\\\\\"\\\\n                        export BACKUP_DATE=\\\\\\\"${env.BACKUP_DATE}\\\\\\\"\\\\n                        export BACKUP_TIMESTAMP=\\\\\\\"${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                        export DATA_DIR=\\\\\\\"${DATA_DIR}\\\\\\\"\\\\n                        \\\\n                        # スクリプト実行\\\\n                        ${SCRIPT_DIR}/collect_parameters.sh\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの確認\\\\n                    if (fileExists(\\\\\\\"${DATA_DIR}/backup.json\\\\\\\")) {\\\\n                        def backupData = readJSON file: \\\\\\\"${DATA_DIR}/backup.json\\\\\\\"\\\\n                        env.PARAM_COUNT = backupData.parameter_count.toString()\\\\n                        \\\\n                        if (backupData.parameter_count == 0) {\\\\n                            echo \\\\\\\"WARNING: No parameters found for backup\\\\\\\"\\\\n                            currentBuild.result = 'UNSTABLE'\\\\n                        } else {\\\\n                            echo \\\\\\\"Backup file contains ${backupData.parameter_count} parameters\\\\\\\"\\\\n                        }\\\\n                    } else {\\\\n                        error(\\\\\\\"Backup file was not created\\\\\\\")\\\\n                    }\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Upload to S3') {\\\\n            when {\\\\n                expression { \\\\n                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\\\\n                }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Uploading Backup to S3 ===\\\\\\\"\\\\n                    \\\\n                    def backupFileName = \\\\\\\"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\\\\"\\\\n                    def s3Key = \\\\\\\"${env.BACKUP_DATE}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの名前を変更\\\\n                    sh \\\\\\\"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // S3へアップロード（暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\\\\\\\\\\n                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\\\\\\\"\\\\n                    \\\\n                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        echo '${s3Key}' | \\\\\\\\\\\\n                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // アップロード確認\\\\n                    def s3ObjectInfo = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws s3api head-object \\\\\\\\\\\\n                                --bucket ${env.BACKUP_BUCKET} \\\\\\\\\\\\n                                --key ${s3Key} \\\\\\\\\\\\n                                --query '[ContentLength, LastModified]' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION}\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    echo \\\\\\\"S3 Object Info: ${s3ObjectInfo}\\\\\\\"\\\\n                    \\\\n                    // セキュリティ上の理由によりアーティファクトとしては保存しない\\\\n                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/00_planning/execute/agent_log_raw.txt:12:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '200,400p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Dry Run Report') {\\\\n            when {\\\\n                expression { params.DRY_RUN }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    def paramCount = env.PARAM_COUNT ?: '0'\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    DRY RUN - バックアップ実行レポート\\\\n                    =============================================\\\\n                    \\\\n                    このドライランでは実際のS3アップロードは行われませんでした。\\\\n                    \\\\n                    バックアップ対象:\\\\n                    - 環境: ${params.ENVIRONMENT}\\\\n                    - パラメータ数: ${paramCount}\\\\n                    - バックアップ日時: ${env.BACKUP_TIMESTAMP}\\\\n                    \\\\n                    実行時の動作:\\\\n                    - S3バケット: ${env.BACKUP_BUCKET}\\\\n                    - S3パス: ${env.BACKUP_DATE}/\\\\n                    - ファイル名: ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\n                    \\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // セキュリティ上の理由によりドライラン時もアーティファクトとして保存しない\\\\n                }\\\\n            }\\\\n        }\\\\n    }\\\\n    \\\\n    post {\\\\n        always {\\\\n            script {\\\\n                def paramCount = env.PARAM_COUNT ?: '0'\\\\n                \\\\n                // 実行サマリーの表示\\\\n                echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                =============================================\\\\n                SSM Parameter Store Backup Summary\\\\n                =============================================\\\\n                Build: #${env.BUILD_NUMBER}\\\\n                Status: ${currentBuild.result ?: 'SUCCESS'}\\\\n                Environment: ${params.ENVIRONMENT}\\\\n                Parameters: ${paramCount}\\\\n                Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                Dry Run: ${params.DRY_RUN}\\\\n                =============================================\\\\n                \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n            }\\\\n        }\\\\n        \\\\n        success {\\\\n            echo \\\\\\\"✅ SSMパラメータのバックアップが正常に完了しました\\\\\\\"\\\\n        }\\\\n        \\\\n        failure {\\\\n            echo \\\\\\\"❌ バックアップが失敗しました。ログを確認してください\\\\\\\"\\\\n        }\\\\n        \\\\n        unstable {\\\\n            echo \\\\\\\"⚠️ バックアップは完了しましたが、警告があります\\\\\\\"\\\\n        }\\\\n        \\\\n        cleanup {\\\\n            // 作業ディレクトリのクリーンアップ\\\\n            sh \\\\\\\"rm -rf ${WORK_DIR} ${SCRIPT_DIR} jenkins-repo || true\\\\\\\"\\\\n        }\\\\n    }\\\\n}\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:696:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_66\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"nl -ba docs/runbooks/ssm-backup.md | sed -n '1,200p'\\\"\",\"aggregated_output\":\"     1\\t# SSM Parameter Store Backup Runbook\\n     2\\t\\n     3\\t## 概要\\n     4\\t- 対象ジョブ: `Admin_Jobs/admin_ssm_backup_job`\\n     5\\t- 目的: Pulumi が生成した各リージョンの S3 バケットへ、SSM Parameter Store の内容を暗号化した JSON として日次バックアップする。\\n     6\\t- リージョン構成: Pulumi Config (`pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml`) の `regions` 配列に従い動的に決定。\\n     7\\t- メタデータ保管: `/jenkins/<env>/backup/` プレフィックスの SSM パラメータ（`region-list`, `default-region`, `s3-bucket-name`, `<region>/s3-bucket-name`）。\\n     8\\t\\n     9\\t## 運用手順\\n    10\\t1. Jenkins ジョブが自動実行（毎日 JST 22:00）。開始時に `Initialize` ステージでリージョン一覧とデフォルトリージョンを SSM から取得。\\n    11\\t2. `Backup <region>` ステージがリージョンごとに逐次実行され、`collect_parameters.sh` を用いて SSM パラメータを収集。\\n    12\\t3. 取得した JSON は `s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json` にアップロードされ、`latest-<region>.txt`（デフォルトリージョンは互換用に `latest.txt` も更新）を発行。\\n    13\\t4. 実行結果は `backup-work/region_summaries.json` に出力され、アーティファクトとして保存。Slack/メール通知には同ファイルの要約を添付。\\n    14\\t\\n    15\\t## リージョン追加・削除手順\\n    16\\t1. `pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml` の `regions` 配列を更新し、`defaultRegion` と `ssmHomeRegion` を必要に応じて調整。\\n    17\\t2. Pulumi スタックディレクトリで `npm install`（依存未導入時）後、`npm run build` → `pulumi preview` を実施し差分を確認。\\n    18\\t3. 変更内容をレビュー後、`pulumi up` を本番／ステージング順に適用。\\n    19\\t4. Jenkins ジョブをドライラン（`DRY_RUN=true`）で実行し、`Backup <region>` ステージが追加リージョンを認識することを確認。\\n    20\\t5. 運用チームへ Slack `#infra-announcements` でリージョン変更点と実施日時を共有。\\n    21\\t\\n    22\\t## ロールバック手順\\n    23\\t1. Pulumi Config を直前のコミットへ戻し `pulumi up` を実行。不要になった S3 バケットと SSM パラメータが削除されることを `pulumi preview` で確認。\\n    24\\t2. Jenkins ジョブを手動実行し、`region_summaries.json` に旧構成のみが記録されることを確認。\\n    25\\t3. 影響が大きい場合は Runbook の通知テンプレートを利用し、CLI 利用者とオンコール SRE へ速やかに連絡。\\n    26\\t\\n    27\\t## 監視・通知\\n    28\\t- 成功時: Slack `#infra-backup-alerts` にリージョン別件数・処理時間を通知。メール `ops-alerts@example.com` に同内容のサマリーを送付。\\n    29\\t- 失敗時: 失敗リージョンの `message` が通知ペイロードに含まれる。30 分以内に一次報告、復旧後 1 営業日以内に事後報告を行う。\\n    30\\t- 参照ログ: Jenkins 実行ログ・`backup-work/region_summaries.json`・S3 バケットの `latest-<region>.txt`。\\n    31\\t\\n    32\\t## トラブルシューティング\\n    33\\t| 症状 | 対処 |\\n    34\\t| ---- | ---- |\\n    35\\t| `Region list parameter ... is missing` | Pulumi スタックが未適用。`pulumi config get regions` と SSM の `/backup/region-list` を確認。 |\\n    36\\t| `Bucket definition missing for region` | `/backup/<region>/s3-bucket-name` の作成漏れ。Pulumi Config のリージョン一覧と SSM を照合。 |\\n    37\\t| `Backup file was not created` | `collect_parameters.sh` の AWS 認証／フィルタ設定を確認。`DATA_DIR/<region>` に生成物があるか検証。 |\\n    38\\t| S3 アップロードに失敗 | `aws s3 cp` コマンドのエラー詳細をログで確認。IAM 権限またはリージョン設定を見直し。 |\\n    39\\t\\n    40\\t## 参考コマンド\\n    41\\t```bash\\n    42\\t# Pulumi Stack でリージョンを確認\\n    43\\tpulumi config get regions --path --stack <env>\\n    44\\t\\n    45\\t# Jenkins アーティファクトからサマリーを取得\\n    46\\taws s3 cp s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json ./\\n    47\\t```\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:706:[DEBUG][Codex][5] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_1\",\"type\":\"command_execution\",\"command\":\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\",\"aggregated_output\":\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体図\\n```mermaid\\nflowchart TD\\n    subgraph Jenkins[\\\"Jenkins (CI)\\\"]\\n        DSL[\\\"Groovy DSL\\\\nadmin_ssm_backup_job.groovy\\\"]\\n        Pipeline[\\\"Scripted Pipeline\\\\nJenkinsfile\\\"]\\n        Script[\\\"collect_parameters.sh\\\"]\\n    end\\n\\n    subgraph AWS[\\\"AWS Account\\\"]\\n        SSM[\\\"SSM Parameter Store\\\\n(env-scoped metadata)\\\"]\\n        subgraph Regions[\\\"対象リージョン (config-driven)\\\"]\\n            BucketA[\\\"S3 Backup Bucket\\\\n(ap-northeast-1)\\\"]\\n            BucketB[\\\"S3 Backup Bucket\\\\n(us-west-2)\\\"]\\n            BucketC[\\\"S3 Backup Bucket\\\\n(... more)\\\"]\\n        end\\n    end\\n\\n    subgraph Pulumi[\\\"Pulumi Stack (TypeScript)\\\"]\\n        Config[\\\"Pulumi Config\\\\n(project/env/regions)\\\"]\\n        IaC[\\\"index.ts\\\\nmulti-region resource factory\\\"]\\n        Tests[\\\"Jest-based unit tests\\\"]\\n    end\\n\\n    DSL -->|SCM sync| Pipeline\\n    Pipeline -->|fetch| Script\\n    Pipeline -->|Read config & region list| SSM\\n    Pipeline -->|Loop regions\\\\ninvoke AWS CLI| BucketA\\n    Pipeline --> BucketB\\n    Pipeline --> BucketC\\n    Pulumi -->|pulumi up| Regions\\n    Pulumi -->|write bucket metadata\\\\n& region list| SSM\\n    Tests --> IaC\\n```\\n\\n### 1.2 コンポーネント間の関係\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\n\\n### 1.3 データフロー\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\"Backup ${region}\\\")` を生成し、各ステージ内で\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\n\\n## 2. 実装戦略: EXTEND\\n\\n**判断根拠**:\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\n\\n## 3. テスト戦略: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\n\\n## 4. テストコード戦略: CREATE_TEST\\n\\n**判断根拠**:\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\n\\n## 5. 影響範囲分析\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\n\\n## 6. 変更・追加ファイルリスト\\n| 区分 | ファイル/パス | 目的 |\\n| ---- | ------------- | ---- |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\n\\n## 7. 詳細設計\\n\\n### 7.1 Pulumi (IaC) 詳細\\n- **Config インターフェース**  \\n  ```yaml\\n  # Pulumi.<stack>.yaml\\n  config:\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\n    jenkins-ssm-backup-s3:environment: dev\\n    jenkins-ssm-backup-s3:regions:\\n      - ap-northeast-1\\n      - us-west-2\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\n  ```\\n- **主要関数設計**\\n  | 関数/スコープ | 役割 |\\n  | ------------- | ---- |\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\n- **命名規則／タグ**  \\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:722:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_2\",\"type\":\"command_execution\",\"command\":\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\",\"aggregated_output\":\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体図\\n```mermaid\\nflowchart TD\\n    subgraph Jenkins[\\\"Jenkins (CI)\\\"]\\n        DSL[\\\"Groovy DSL\\\\nadmin_ssm_backup_job.groovy\\\"]\\n        Pipeline[\\\"Scripted Pipeline\\\\nJenkinsfile\\\"]\\n        Script[\\\"collect_parameters.sh\\\"]\\n    end\\n\\n    subgraph AWS[\\\"AWS Account\\\"]\\n        SSM[\\\"SSM Parameter Store\\\\n(env-scoped metadata)\\\"]\\n        subgraph Regions[\\\"対象リージョン (config-driven)\\\"]\\n            BucketA[\\\"S3 Backup Bucket\\\\n(ap-northeast-1)\\\"]\\n            BucketB[\\\"S3 Backup Bucket\\\\n(us-west-2)\\\"]\\n            BucketC[\\\"S3 Backup Bucket\\\\n(... more)\\\"]\\n        end\\n    end\\n\\n    subgraph Pulumi[\\\"Pulumi Stack (TypeScript)\\\"]\\n        Config[\\\"Pulumi Config\\\\n(project/env/regions)\\\"]\\n        IaC[\\\"index.ts\\\\nmulti-region resource factory\\\"]\\n        Tests[\\\"Jest-based unit tests\\\"]\\n    end\\n\\n    DSL -->|SCM sync| Pipeline\\n    Pipeline -->|fetch| Script\\n    Pipeline -->|Read config & region list| SSM\\n    Pipeline -->|Loop regions\\\\ninvoke AWS CLI| BucketA\\n    Pipeline --> BucketB\\n    Pipeline --> BucketC\\n    Pulumi -->|pulumi up| Regions\\n    Pulumi -->|write bucket metadata\\\\n& region list| SSM\\n    Tests --> IaC\\n```\\n\\n### 1.2 コンポーネント間の関係\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\n\\n### 1.3 データフロー\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\"Backup ${region}\\\")` を生成し、各ステージ内で\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\n\\n## 2. 実装戦略: EXTEND\\n\\n**判断根拠**:\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\n\\n## 3. テスト戦略: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\n\\n## 4. テストコード戦略: CREATE_TEST\\n\\n**判断根拠**:\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\n\\n## 5. 影響範囲分析\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\n\\n## 6. 変更・追加ファイルリスト\\n| 区分 | ファイル/パス | 目的 |\\n| ---- | ------------- | ---- |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\n\\n## 7. 詳細設計\\n\\n### 7.1 Pulumi (IaC) 詳細\\n- **Config インターフェース**  \\n  ```yaml\\n  # Pulumi.<stack>.yaml\\n  config:\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\n    jenkins-ssm-backup-s3:environment: dev\\n    jenkins-ssm-backup-s3:regions:\\n      - ap-northeast-1\\n      - us-west-2\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\n  ```\\n- **主要関数設計**\\n  | 関数/スコープ | 役割 |\\n  | ------------- | ---- |\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\n- **命名規則／タグ**  \\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:746:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_14\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '1,200p' docs/runbooks/ssm-backup.md\\\"\",\"aggregated_output\":\"# SSM Parameter Store Backup Runbook\\n\\n## 概要\\n- 対象ジョブ: `Admin_Jobs/admin_ssm_backup_job`\\n- 目的: Pulumi が生成した各リージョンの S3 バケットへ、SSM Parameter Store の内容を暗号化した JSON として日次バックアップする。\\n- リージョン構成: Pulumi Config (`pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml`) の `regions` 配列に従い動的に決定。\\n- メタデータ保管: `/jenkins/<env>/backup/` プレフィックスの SSM パラメータ（`region-list`, `default-region`, `s3-bucket-name`, `<region>/s3-bucket-name`）。\\n\\n## 運用手順\\n1. Jenkins ジョブが自動実行（毎日 JST 22:00）。開始時に `Initialize` ステージでリージョン一覧とデフォルトリージョンを SSM から取得。\\n2. `Backup <region>` ステージがリージョンごとに逐次実行され、`collect_parameters.sh` を用いて SSM パラメータを収集。\\n3. 取得した JSON は `s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json` にアップロードされ、`latest-<region>.txt`（デフォルトリージョンは互換用に `latest.txt` も更新）を発行。\\n4. 実行結果は `backup-work/region_summaries.json` に出力され、アーティファクトとして保存。Slack/メール通知には同ファイルの要約を添付。\\n\\n## リージョン追加・削除手順\\n1. `pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml` の `regions` 配列を更新し、`defaultRegion` と `ssmHomeRegion` を必要に応じて調整。\\n2. Pulumi スタックディレクトリで `npm install`（依存未導入時）後、`npm run build` → `pulumi preview` を実施し差分を確認。\\n3. 変更内容をレビュー後、`pulumi up` を本番／ステージング順に適用。\\n4. Jenkins ジョブをドライラン（`DRY_RUN=true`）で実行し、`Backup <region>` ステージが追加リージョンを認識することを確認。\\n5. 運用チームへ Slack `#infra-announcements` でリージョン変更点と実施日時を共有。\\n\\n## ロールバック手順\\n1. Pulumi Config を直前のコミットへ戻し `pulumi up` を実行。不要になった S3 バケットと SSM パラメータが削除されることを `pulumi preview` で確認。\\n2. Jenkins ジョブを手動実行し、`region_summaries.json` に旧構成のみが記録されることを確認。\\n3. 影響が大きい場合は Runbook の通知テンプレートを利用し、CLI 利用者とオンコール SRE へ速やかに連絡。\\n\\n## 監視・通知\\n- 成功時: Slack `#infra-backup-alerts` にリージョン別件数・処理時間を通知。メール `ops-alerts@example.com` に同内容のサマリーを送付。\\n- 失敗時: 失敗リージョンの `message` が通知ペイロードに含まれる。30 分以内に一次報告、復旧後 1 営業日以内に事後報告を行う。\\n- 参照ログ: Jenkins 実行ログ・`backup-work/region_summaries.json`・S3 バケットの `latest-<region>.txt`。\\n\\n## トラブルシューティング\\n| 症状 | 対処 |\\n| ---- | ---- |\\n| `Region list parameter ... is missing` | Pulumi スタックが未適用。`pulumi config get regions` と SSM の `/backup/region-list` を確認。 |\\n| `Bucket definition missing for region` | `/backup/<region>/s3-bucket-name` の作成漏れ。Pulumi Config のリージョン一覧と SSM を照合。 |\\n| `Backup file was not created` | `collect_parameters.sh` の AWS 認証／フィルタ設定を確認。`DATA_DIR/<region>` に生成物があるか検証。 |\\n| S3 アップロードに失敗 | `aws s3 cp` コマンドのエラー詳細をログで確認。IAM 権限またはリージョン設定を見直し。 |\\n\\n## 参考コマンド\\n```bash\\n# Pulumi Stack でリージョンを確認\\npulumi config get regions --path --stack <env>\\n\\n# Jenkins アーティファクトからサマリーを取得\\naws s3 cp s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json ./\\n```\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:754:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_18\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '120,220p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジ���ブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:764:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_23\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"nl -ba docs/runbooks/ssm-backup.md | sed -n '1,160p'\\\"\",\"aggregated_output\":\"     1\\t# SSM Parameter Store Backup Runbook\\n     2\\t\\n     3\\t## 概要\\n     4\\t- 対象ジョブ: `Admin_Jobs/admin_ssm_backup_job`\\n     5\\t- 目的: Pulumi が生成した各リージョンの S3 バケットへ、SSM Parameter Store の内容を暗号化した JSON として日次バックアップする。\\n     6\\t- リージョン構成: Pulumi Config (`pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml`) の `regions` 配列に従い動的に決定。\\n     7\\t- メタデータ保管: `/jenkins/<env>/backup/` プレフィックスの SSM パラメータ（`region-list`, `default-region`, `s3-bucket-name`, `<region>/s3-bucket-name`）。\\n     8\\t\\n     9\\t## 運用手順\\n    10\\t1. Jenkins ジョブが自動実行（毎日 JST 22:00）。開始時に `Initialize` ステージでリージョン一覧とデフォルトリージョンを SSM から取得。\\n    11\\t2. `Backup <region>` ステージがリージョンごとに逐次実行され、`collect_parameters.sh` を用いて SSM パラメータを収集。\\n    12\\t3. 取得した JSON は `s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json` にアップロードされ、`latest-<region>.txt`（デフォルトリージョンは互換用に `latest.txt` も更新）を発行。\\n    13\\t4. 実行結果は `backup-work/region_summaries.json` に出力され、アーティファクトとして保存。Slack/メール通知には同ファイルの要約を添付。\\n    14\\t\\n    15\\t## リージョン追加・削除手順\\n    16\\t1. `pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml` の `regions` 配列を更新し、`defaultRegion` と `ssmHomeRegion` を必要に応じて調整。\\n    17\\t2. Pulumi スタックディレクトリで `npm install`（依存未導入時）後、`npm run build` → `pulumi preview` を実施し差分を確認。\\n    18\\t3. 変更内容をレビュー後、`pulumi up` を本番／ステージング順に適用。\\n    19\\t4. Jenkins ジョブをドライラン（`DRY_RUN=true`）で実行し、`Backup <region>` ステージが追加リージョンを認識することを確認。\\n    20\\t5. 運用チームへ Slack `#infra-announcements` でリージョン変更点と実施日時を共有。\\n    21\\t\\n    22\\t## ロールバック手順\\n    23\\t1. Pulumi Config を直前のコミットへ戻し `pulumi up` を実行。不要になった S3 バケットと SSM パラメータが削除されることを `pulumi preview` で確認。\\n    24\\t2. Jenkins ジョブを手動実行し、`region_summaries.json` に旧構成のみが記録されることを確認。\\n    25\\t3. 影響が大きい場合は Runbook の通知テンプレートを利用し、CLI 利用者とオンコール SRE へ速やかに連絡。\\n    26\\t\\n    27\\t## 監視・通知\\n    28\\t- 成功時: Slack `#infra-backup-alerts` にリージョン別件数・処理時間を通知。メール `ops-alerts@example.com` に同内容のサマリーを送付。\\n    29\\t- 失敗時: 失敗リージョンの `message` が通知ペイロードに含まれる。30 分以内に一次報告、復旧後 1 営業日以内に事後報告を行う。\\n    30\\t- 参照ログ: Jenkins 実行ログ・`backup-work/region_summaries.json`・S3 バケットの `latest-<region>.txt`。\\n    31\\t\\n    32\\t## トラブルシューティング\\n    33\\t| 症状 | 対処 |\\n    34\\t| ---- | ---- |\\n    35\\t| `Region list parameter ... is missing` | Pulumi スタックが未適用。`pulumi config get regions` と SSM の `/backup/region-list` を確認。 |\\n    36\\t| `Bucket definition missing for region` | `/backup/<region>/s3-bucket-name` の作成漏れ。Pulumi Config のリージョン一覧と SSM を照合。 |\\n    37\\t| `Backup file was not created` | `collect_parameters.sh` の AWS 認証／フィルタ設定を確認。`DATA_DIR/<region>` に生成物があるか検証。 |\\n    38\\t| S3 アップロードに失敗 | `aws s3 cp` コマンドのエラー詳細をログで確認。IAM 権限またはリージョン設定を見直し。 |\\n    39\\t\\n    40\\t## 参考コマンド\\n    41\\t```bash\\n    42\\t# Pulumi Stack でリージョンを確認\\n    43\\tpulumi config get regions --path --stack <env>\\n    44\\t\\n    45\\t# Jenkins アーティファクトからサマリーを取得\\n    46\\taws s3 cp s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json ./\\n    47\\t```\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:776:[DEBUG][Codex][7] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_2\",\"type\":\"command_execution\",\"command\":\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\",\"aggregated_output\":\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体図\\n```mermaid\\nflowchart TD\\n    subgraph Jenkins[\\\"Jenkins (CI)\\\"]\\n        DSL[\\\"Groovy DSL\\\\nadmin_ssm_backup_job.groovy\\\"]\\n        Pipeline[\\\"Scripted Pipeline\\\\nJenkinsfile\\\"]\\n        Script[\\\"collect_parameters.sh\\\"]\\n    end\\n\\n    subgraph AWS[\\\"AWS Account\\\"]\\n        SSM[\\\"SSM Parameter Store\\\\n(env-scoped metadata)\\\"]\\n        subgraph Regions[\\\"対象リージョン (config-driven)\\\"]\\n            BucketA[\\\"S3 Backup Bucket\\\\n(ap-northeast-1)\\\"]\\n            BucketB[\\\"S3 Backup Bucket\\\\n(us-west-2)\\\"]\\n            BucketC[\\\"S3 Backup Bucket\\\\n(... more)\\\"]\\n        end\\n    end\\n\\n    subgraph Pulumi[\\\"Pulumi Stack (TypeScript)\\\"]\\n        Config[\\\"Pulumi Config\\\\n(project/env/regions)\\\"]\\n        IaC[\\\"index.ts\\\\nmulti-region resource factory\\\"]\\n        Tests[\\\"Jest-based unit tests\\\"]\\n    end\\n\\n    DSL -->|SCM sync| Pipeline\\n    Pipeline -->|fetch| Script\\n    Pipeline -->|Read config & region list| SSM\\n    Pipeline -->|Loop regions\\\\ninvoke AWS CLI| BucketA\\n    Pipeline --> BucketB\\n    Pipeline --> BucketC\\n    Pulumi -->|pulumi up| Regions\\n    Pulumi -->|write bucket metadata\\\\n& region list| SSM\\n    Tests --> IaC\\n```\\n\\n### 1.2 コンポーネント間の関係\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\n\\n### 1.3 データフロー\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\"Backup ${region}\\\")` を生成し、各ステージ内で\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\n\\n## 2. 実装戦略: EXTEND\\n\\n**判断根拠**:\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\n\\n## 3. テスト戦略: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\n\\n## 4. テストコード戦略: CREATE_TEST\\n\\n**判断根拠**:\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\n\\n## 5. 影響範囲分析\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\n\\n## 6. 変更・追加ファイルリスト\\n| 区分 | ファイル/パス | 目的 |\\n| ---- | ------------- | ---- |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\n\\n## 7. 詳細設計\\n\\n### 7.1 Pulumi (IaC) 詳細\\n- **Config インターフェース**  \\n  ```yaml\\n  # Pulumi.<stack>.yaml\\n  config:\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\n    jenkins-ssm-backup-s3:environment: dev\\n    jenkins-ssm-backup-s3:regions:\\n      - ap-northeast-1\\n      - us-west-2\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\n  ```\\n- **主要関数設計**\\n  | 関数/スコープ | 役割 |\\n  | ------------- | ---- |\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\n- **命名規則／タグ**  \\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:798:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_6\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '202,260p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:800:[CODEX EVENT] {\"type\":\"item.completed\",\"item\":{\"id\":\"item_7\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '1,200p' docs/runbooks/ssm-backup.md\\\"\",\"aggregated_output\":\"# SSM Parameter Store Backup Runbook\\n\\n## 概要\\n- 対象ジョブ: `Admin_Jobs/admin_ssm_backup_job`\\n- 目的: Pulumi が生成した各リージョンの S3 バケットへ、SSM Parameter Store の内容を暗号化した JSON として日次バックアップする。\\n- リージョン構成: Pulumi Config (`pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml`) の `regions` 配列に従い動的に決定。\\n- メタデータ保管: `/jenkins/<env>/backup/` プレフィックスの SSM パラメータ（`region-list`, `default-region`, `s3-bucket-name`, `<region>/s3-bucket-name`）。\\n\\n## 運用手順\\n1. Jenkins ジョブが自動実行（毎日 JST 22:00）。開始時に `Initialize` ステージでリージョン一覧とデフォルトリージョンを SSM から取得。\\n2. `Backup <region>` ステージがリージョンごとに逐次実行され、`collect_parameters.sh` を用いて SSM パラメータを収集。\\n3. 取得した JSON は `s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json` にアップロードされ、`latest-<region>.txt`（デフォルトリージョンは互換用に `latest.txt` も更新）を発行。\\n4. 実行結果は `backup-work/region_summaries.json` に出力され、アーティファクトとして保存。Slack/メール通知には同ファイルの要約を添付。\\n\\n## リージョン追加・削除手順\\n1. `pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml` の `regions` 配列を更新し、`defaultRegion` と `ssmHomeRegion` を必要に応じて調整。\\n2. Pulumi スタックディレクトリで `npm install`（依存未導入時）後、`npm run build` → `pulumi preview` を実施し差分を確認。\\n3. 変更内容をレビュー後、`pulumi up` を本番／ステージング順に適用。\\n4. Jenkins ジョブをドライラン（`DRY_RUN=true`）で実行し、`Backup <region>` ステージが追加リージョンを認識することを確認。\\n5. 運用チームへ Slack `#infra-announcements` でリージョン変更点と実施日時を共有。\\n\\n## ロールバック手順\\n1. Pulumi Config を直前のコミットへ戻し `pulumi up` を実行。不要になった S3 バケットと SSM パラメータが削除されることを `pulumi preview` で確認。\\n2. Jenkins ジョブを手動実行し、`region_summaries.json` に旧構成のみが記録されることを確認。\\n3. 影響が大きい場合は Runbook の通知テンプレートを利用し、CLI 利用者とオンコール SRE へ速やかに連絡。\\n\\n## 監視・通知\\n- 成功時: Slack `#infra-backup-alerts` にリージョン別件数・処理時間を通知。メール `ops-alerts@example.com` に同内容のサマリーを送付。\\n- 失敗時: 失敗リージョンの `message` が通知ペイロードに含まれる。30 分以内に一次報告、復旧後 1 営業日以内に事後報告を行う。\\n- 参照ログ: Jenkins 実行ログ・`backup-work/region_summaries.json`・S3 バケットの `latest-<region>.txt`。\\n\\n## トラブルシューティング\\n| 症状 | 対処 |\\n| ---- | ---- |\\n| `Region list parameter ... is missing` | Pulumi スタックが未適用。`pulumi config get regions` と SSM の `/backup/region-list` を確認。 |\\n| `Bucket definition missing for region` | `/backup/<region>/s3-bucket-name` の作成漏れ。Pulumi Config のリージョン一覧と SSM を照合。 |\\n| `Backup file was not created` | `collect_parameters.sh` の AWS 認証／フィルタ設定を確認。`DATA_DIR/<region>` に生成物があるか検証。 |\\n| S3 アップロードに失敗 | `aws s3 cp` コマンドのエラー詳細をログで確認。IAM 権限またはリージョン設定を見直し。 |\\n\\n## 参考コマンド\\n```bash\\n# Pulumi Stack でリージョンを確認\\npulumi config get regions --path --stack <env>\\n\\n# Jenkins アーティファクトからサマリーを取得\\naws s3 cp s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json ./\\n```\\n\",\"exit_code\":0,\"status\":\"completed\"}}\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:805:[CODEX EVENT] {\"type\":\"item.started\",\"item\":{\"id\":\"item_10\",\"type\":\"command_execution\",\"command\":\"bash -lc 'grep -n \\\"ops-alerts\\\" -R'\",\"aggregated_output\":\"\",\"status\":\"in_progress\"}}\n.ai-workflow/issue-391/04_implementation/review/agent_log.md:1227:- 成功時: Slack `#infra-backup-alerts` にリージョン別件数・処理時間を通知。メール `ops-alerts@example.com` に同内容のサマリーを送付。\n.ai-workflow/issue-391/04_implementation/review/agent_log.md:1505:    28\t- 成功時: Slack `#infra-backup-alerts` にリージョン別件数・処理時間を通知。メール `ops-alerts@example.com` に同内容のサマリーを送付。\n.ai-workflow/issue-391/04_implementation/review/agent_log_raw.txt:8:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_2\",\"type\":\"command_execution\",\"command\":\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\",\"aggregated_output\":\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体図\\n```mermaid\\nflowchart TD\\n    subgraph Jenkins[\\\"Jenkins (CI)\\\"]\\n        DSL[\\\"Groovy DSL\\\\nadmin_ssm_backup_job.groovy\\\"]\\n        Pipeline[\\\"Scripted Pipeline\\\\nJenkinsfile\\\"]\\n        Script[\\\"collect_parameters.sh\\\"]\\n    end\\n\\n    subgraph AWS[\\\"AWS Account\\\"]\\n        SSM[\\\"SSM Parameter Store\\\\n(env-scoped metadata)\\\"]\\n        subgraph Regions[\\\"対象リージョン (config-driven)\\\"]\\n            BucketA[\\\"S3 Backup Bucket\\\\n(ap-northeast-1)\\\"]\\n            BucketB[\\\"S3 Backup Bucket\\\\n(us-west-2)\\\"]\\n            BucketC[\\\"S3 Backup Bucket\\\\n(... more)\\\"]\\n        end\\n    end\\n\\n    subgraph Pulumi[\\\"Pulumi Stack (TypeScript)\\\"]\\n        Config[\\\"Pulumi Config\\\\n(project/env/regions)\\\"]\\n        IaC[\\\"index.ts\\\\nmulti-region resource factory\\\"]\\n        Tests[\\\"Jest-based unit tests\\\"]\\n    end\\n\\n    DSL -->|SCM sync| Pipeline\\n    Pipeline -->|fetch| Script\\n    Pipeline -->|Read config & region list| SSM\\n    Pipeline -->|Loop regions\\\\ninvoke AWS CLI| BucketA\\n    Pipeline --> BucketB\\n    Pipeline --> BucketC\\n    Pulumi -->|pulumi up| Regions\\n    Pulumi -->|write bucket metadata\\\\n& region list| SSM\\n    Tests --> IaC\\n```\\n\\n### 1.2 コンポーネント間の関係\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\n\\n### 1.3 データフロー\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\"Backup ${region}\\\")` を生成し、各ステージ内で\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\n\\n## 2. 実装戦略: EXTEND\\n\\n**判断根拠**:\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\n\\n## 3. テスト戦略: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\n\\n## 4. テストコード戦略: CREATE_TEST\\n\\n**判断根拠**:\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\n\\n## 5. 影響範囲分析\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\n\\n## 6. 変更・追加ファイルリスト\\n| 区分 | ファイル/パス | 目的 |\\n| ---- | ------------- | ---- |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\n\\n## 7. 詳細設計\\n\\n### 7.1 Pulumi (IaC) 詳細\\n- **Config インターフェース**  \\n  ```yaml\\n  # Pulumi.<stack>.yaml\\n  config:\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\n    jenkins-ssm-backup-s3:environment: dev\\n    jenkins-ssm-backup-s3:regions:\\n      - ap-northeast-1\\n      - us-west-2\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\n  ```\\n- **主要関数設計**\\n  | 関数/スコープ | 役割 |\\n  | ------------- | ---- |\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\n- **命名規則／タグ**  \\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/04_implementation/review/agent_log_raw.txt:32:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_14\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '1,200p' docs/runbooks/ssm-backup.md\\\"\",\"aggregated_output\":\"# SSM Parameter Store Backup Runbook\\n\\n## 概要\\n- 対象ジョブ: `Admin_Jobs/admin_ssm_backup_job`\\n- 目的: Pulumi が生成した各リージョンの S3 バケットへ、SSM Parameter Store の内容を暗号化した JSON として日次バックアップする。\\n- リージョン構成: Pulumi Config (`pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml`) の `regions` 配列に従い動的に決定。\\n- メタデータ保管: `/jenkins/<env>/backup/` プレフィックスの SSM パラメータ（`region-list`, `default-region`, `s3-bucket-name`, `<region>/s3-bucket-name`）。\\n\\n## 運用手順\\n1. Jenkins ジョブが自動実行（毎日 JST 22:00）。開始時に `Initialize` ステージでリージョン一覧とデフォルトリージョンを SSM から取得。\\n2. `Backup <region>` ステージがリージョンごとに逐次実行され、`collect_parameters.sh` を用いて SSM パラメータを収集。\\n3. 取得した JSON は `s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json` にアップロードされ、`latest-<region>.txt`（デフォルトリージョンは互換用に `latest.txt` も更新）を発行。\\n4. 実行結果は `backup-work/region_summaries.json` に出力され、アーティファクトとして保存。Slack/メール通知には同ファイルの要約を添付。\\n\\n## リージョン追加・削除手順\\n1. `pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml` の `regions` 配列を更新し、`defaultRegion` と `ssmHomeRegion` を必要に応じて調整。\\n2. Pulumi スタックディレクトリで `npm install`（依存未導入時）後、`npm run build` → `pulumi preview` を実施し差分を確認。\\n3. 変更内容をレビュー後、`pulumi up` を本番／ステージング順に適用。\\n4. Jenkins ジョブをドライラン（`DRY_RUN=true`）で実行し、`Backup <region>` ステージが追加リージョンを認識することを確認。\\n5. 運用チームへ Slack `#infra-announcements` でリージョン変更点と実施日時を共有。\\n\\n## ロールバック手順\\n1. Pulumi Config を直前のコミットへ戻し `pulumi up` を実行。不要になった S3 バケットと SSM パラメータが削除されることを `pulumi preview` で確認。\\n2. Jenkins ジョブを手動実行し、`region_summaries.json` に旧構成のみが記録されることを確認。\\n3. 影響が大きい場合は Runbook の通知テンプレートを利用し、CLI 利用者とオンコール SRE へ速やかに連絡。\\n\\n## 監視・通知\\n- 成功時: Slack `#infra-backup-alerts` にリージョン別件数・処理時間を通知。メール `ops-alerts@example.com` に同内容のサマリーを送付。\\n- 失敗時: 失敗リージョンの `message` が通知ペイロードに含まれる。30 分以内に一次報告、復旧後 1 営業日以内に事後報告を行う。\\n- 参照ログ: Jenkins 実行ログ・`backup-work/region_summaries.json`・S3 バケットの `latest-<region>.txt`。\\n\\n## トラブルシューティング\\n| 症状 | 対処 |\\n| ---- | ---- |\\n| `Region list parameter ... is missing` | Pulumi スタックが未適用。`pulumi config get regions` と SSM の `/backup/region-list` を確認。 |\\n| `Bucket definition missing for region` | `/backup/<region>/s3-bucket-name` の作成漏れ。Pulumi Config のリージョン一覧と SSM を照合。 |\\n| `Backup file was not created` | `collect_parameters.sh` の AWS 認証／フィルタ設定を確認。`DATA_DIR/<region>` に生成物があるか検証。 |\\n| S3 アップロードに失敗 | `aws s3 cp` コマンドのエラー詳細をログで確認。IAM 権限またはリージョン設定を見直し。 |\\n\\n## 参考コマンド\\n```bash\\n# Pulumi Stack でリージョンを確認\\npulumi config get regions --path --stack <env>\\n\\n# Jenkins アーティファクトからサマリーを取得\\naws s3 cp s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json ./\\n```\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/04_implementation/review/agent_log_raw.txt:40:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_18\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '120,220p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/04_implementation/review/agent_log_raw.txt:50:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_23\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"nl -ba docs/runbooks/ssm-backup.md | sed -n '1,160p'\\\"\",\"aggregated_output\":\"     1\\t# SSM Parameter Store Backup Runbook\\n     2\\t\\n     3\\t## 概要\\n     4\\t- 対象ジョブ: `Admin_Jobs/admin_ssm_backup_job`\\n     5\\t- 目的: Pulumi が生成した各リージョンの S3 バケットへ、SSM Parameter Store の内容を暗号化した JSON として日次バックアップする。\\n     6\\t- リージョン構成: Pulumi Config (`pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml`) の `regions` 配列に従い動的に決定。\\n     7\\t- メタデータ保管: `/jenkins/<env>/backup/` プレフィックスの SSM パラメータ（`region-list`, `default-region`, `s3-bucket-name`, `<region>/s3-bucket-name`）。\\n     8\\t\\n     9\\t## 運用手順\\n    10\\t1. Jenkins ジョブが自動実行（毎日 JST 22:00）。開始時に `Initialize` ステージでリージョン一覧とデフォルトリージョンを SSM から取得。\\n    11\\t2. `Backup <region>` ステージがリージョンごとに逐次実行され、`collect_parameters.sh` を用いて SSM パラメータを収集。\\n    12\\t3. 取得した JSON は `s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json` にアップロードされ、`latest-<region>.txt`（デフォルトリージョンは互換用に `latest.txt` も更新）を発行。\\n    13\\t4. 実行結果は `backup-work/region_summaries.json` に出力され、アーティファクトとして保存。Slack/メール通知には同ファイルの要約を添付。\\n    14\\t\\n    15\\t## リージョン追加・削除手順\\n    16\\t1. `pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml` の `regions` 配列を更新し、`defaultRegion` と `ssmHomeRegion` を必要に応じて調整。\\n    17\\t2. Pulumi スタックディレクトリで `npm install`（依存未導入時）後、`npm run build` → `pulumi preview` を実施し差分を確認。\\n    18\\t3. 変更内容をレビュー後、`pulumi up` を本番／ステージング順に適用。\\n    19\\t4. Jenkins ジョブをドライラン（`DRY_RUN=true`）で実行し、`Backup <region>` ステージが追加リージョンを認識することを確認。\\n    20\\t5. 運用チームへ Slack `#infra-announcements` でリージョン変更点と実施日時を共有。\\n    21\\t\\n    22\\t## ロールバック手順\\n    23\\t1. Pulumi Config を直前のコミットへ戻し `pulumi up` を実行。不要になった S3 バケットと SSM パラメータが削除されることを `pulumi preview` で確認。\\n    24\\t2. Jenkins ジョブを手動実行し、`region_summaries.json` に旧構成のみが記録されることを確認。\\n    25\\t3. 影響が大きい場合は Runbook の通知テンプレートを利用し、CLI 利用者とオンコール SRE へ速やかに連絡。\\n    26\\t\\n    27\\t## 監視・通知\\n    28\\t- 成功時: Slack `#infra-backup-alerts` にリージョン別件数・処理時間を通知。メール `ops-alerts@example.com` に同内容のサマリーを送付。\\n    29\\t- 失敗時: 失敗リージョンの `message` が通知ペイロードに含まれる。30 分以内に一次報告、復旧後 1 営業日以内に事後報告を行う。\\n    30\\t- 参照ログ: Jenkins 実行ログ・`backup-work/region_summaries.json`・S3 バケットの `latest-<region>.txt`。\\n    31\\t\\n    32\\t## トラブルシューティング\\n    33\\t| 症状 | 対処 |\\n    34\\t| ---- | ---- |\\n    35\\t| `Region list parameter ... is missing` | Pulumi スタックが未適用。`pulumi config get regions` と SSM の `/backup/region-list` を確認。 |\\n    36\\t| `Bucket definition missing for region` | `/backup/<region>/s3-bucket-name` の作成漏れ。Pulumi Config のリージョン一覧と SSM を照合。 |\\n    37\\t| `Backup file was not created` | `collect_parameters.sh` の AWS 認証／フィルタ設定を確認。`DATA_DIR/<region>` に生成物があるか検証。 |\\n    38\\t| S3 アップロードに失敗 | `aws s3 cp` コマンドのエラー詳細をログで確認。IAM 権限またはリージョン設定を見直し。 |\\n    39\\t\\n    40\\t## 参考コマンド\\n    41\\t```bash\\n    42\\t# Pulumi Stack でリージョンを確認\\n    43\\tpulumi config get regions --path --stack <env>\\n    44\\t\\n    45\\t# Jenkins アーティファクトからサマリーを取得\\n    46\\taws s3 cp s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json ./\\n    47\\t```\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/04_implementation/execute/agent_log.md:2880:    28\t- 成功時: Slack `#infra-backup-alerts` にリージョン別件数・処理時間を通知。メール `ops-alerts@example.com` に同内容のサマリーを送付。\n.ai-workflow/issue-391/04_implementation/execute/agent_log_raw.txt:6:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_1\",\"type\":\"command_execution\",\"command\":\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\",\"aggregated_output\":\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体図\\n```mermaid\\nflowchart TD\\n    subgraph Jenkins[\\\"Jenkins (CI)\\\"]\\n        DSL[\\\"Groovy DSL\\\\nadmin_ssm_backup_job.groovy\\\"]\\n        Pipeline[\\\"Scripted Pipeline\\\\nJenkinsfile\\\"]\\n        Script[\\\"collect_parameters.sh\\\"]\\n    end\\n\\n    subgraph AWS[\\\"AWS Account\\\"]\\n        SSM[\\\"SSM Parameter Store\\\\n(env-scoped metadata)\\\"]\\n        subgraph Regions[\\\"対象リージョン (config-driven)\\\"]\\n            BucketA[\\\"S3 Backup Bucket\\\\n(ap-northeast-1)\\\"]\\n            BucketB[\\\"S3 Backup Bucket\\\\n(us-west-2)\\\"]\\n            BucketC[\\\"S3 Backup Bucket\\\\n(... more)\\\"]\\n        end\\n    end\\n\\n    subgraph Pulumi[\\\"Pulumi Stack (TypeScript)\\\"]\\n        Config[\\\"Pulumi Config\\\\n(project/env/regions)\\\"]\\n        IaC[\\\"index.ts\\\\nmulti-region resource factory\\\"]\\n        Tests[\\\"Jest-based unit tests\\\"]\\n    end\\n\\n    DSL -->|SCM sync| Pipeline\\n    Pipeline -->|fetch| Script\\n    Pipeline -->|Read config & region list| SSM\\n    Pipeline -->|Loop regions\\\\ninvoke AWS CLI| BucketA\\n    Pipeline --> BucketB\\n    Pipeline --> BucketC\\n    Pulumi -->|pulumi up| Regions\\n    Pulumi -->|write bucket metadata\\\\n& region list| SSM\\n    Tests --> IaC\\n```\\n\\n### 1.2 コンポーネント間の関係\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\n\\n### 1.3 データフロー\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\"Backup ${region}\\\")` を生成し、各ステージ内で\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\n\\n## 2. 実装戦略: EXTEND\\n\\n**判断根拠**:\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\n\\n## 3. テスト戦略: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\n\\n## 4. テストコード戦略: CREATE_TEST\\n\\n**判断根拠**:\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\n\\n## 5. 影響範囲分析\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\n\\n## 6. 変更・追加ファイルリスト\\n| 区分 | ファイル/パス | 目的 |\\n| ---- | ------------- | ---- |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\n\\n## 7. 詳細設計\\n\\n### 7.1 Pulumi (IaC) 詳細\\n- **Config インターフェース**  \\n  ```yaml\\n  # Pulumi.<stack>.yaml\\n  config:\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\n    jenkins-ssm-backup-s3:environment: dev\\n    jenkins-ssm-backup-s3:regions:\\n      - ap-northeast-1\\n      - us-west-2\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\n  ```\\n- **主要関数設計**\\n  | 関数/スコープ | 役割 |\\n  | ------------- | ---- |\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\n- **命名規則／タグ**  \\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/04_implementation/execute/agent_log_raw.txt:40:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_18\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '110,210p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\n  ```\\n- **主要関数設計**\\n  | 関数/スコープ | 役割 |\\n  | ------------- | ---- |\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\n- **命名規則／タグ**  \\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/04_implementation/execute/agent_log_raw.txt:54:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_25\",\"type\":\"command_execution\",\"command\":\"bash -lc 'grep -R \\\"SSM Parameter Store Backup\\\" -n'\",\"aggregated_output\":\"scripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:16:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_1\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,160p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:20:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"@Library('jenkins-shared-lib') _\\\\n\\\\n/**\\\\n * SSM Parameter Store Backup Pipeline\\\\n * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\\\\n */\\\\npipeline {\\\\n    agent {\\\\n        label 'ec2-fleet'\\\\n    }\\\\n    \\\\n    options {\\\\n        timestamps()\\\\n        timeout(time: 1, unit: 'HOURS')\\\\n        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\\\\n        disableConcurrentBuilds()\\\\n    }\\\\n    \\\\n    environment {\\\\n        // AWS設定\\\\n        AWS_REGION = 'ap-northeast-1'\\\\n        \\\\n        // タイムスタンプ\\\\n        BACKUP_DATE = sh(script: \\\\\\\"date '+%Y-%m-%d'\\\\\\\", returnStdout: true).trim()\\\\n        BACKUP_TIMESTAMP = sh(script: \\\\\\\"date '+%Y%m%d_%H%M%S'\\\\\\\", returnStdout: true).trim()\\\\n        \\\\n        // ディレクトリ構造\\\\n        WORK_DIR = \\\\\\\"${WORKSPACE}/backup-work\\\\\\\"\\\\n        DATA_DIR = \\\\\\\"${WORK_DIR}/data\\\\\\\"\\\\n        SCRIPT_DIR = \\\\\\\"${WORKSPACE}/scripts\\\\\\\"\\\\n        \\\\n        // 環境フィルタ（環境に含まれる文字列）\\\\n        ENV_FILTER = \\\\\\\"/${params.ENVIRONMENT}/\\\\\\\"\\\\n    }\\\\n    \\\\n    stages {\\\\n        stage('Initialize') {\\\\n            steps {\\\\n                script {\\\\n                    // ビルド表示名を設定\\\\n                    currentBuild.displayName = \\\\\\\"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\\\\\\\"\\\\n                    currentBuild.description = \\\\\\\"Backup at ${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    SSM Parameter Store Backup\\\\n                    =============================================\\\\n                    Environment: ${params.ENVIRONMENT}\\\\n                    Filter: Parameters containing '${env.ENV_FILTER}'\\\\n                    Dry Run: ${params.DRY_RUN}\\\\n                    Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                    Date: ${env.BACKUP_DATE}\\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // 作業ディレクトリの準備\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        rm -rf ${WORK_DIR}\\\\n                        mkdir -p ${DATA_DIR}\\\\n                        mkdir -p ${SCRIPT_DIR}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // S3バケット名の取得\\\\n                    env.BACKUP_BUCKET = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws ssm get-parameter \\\\\\\\\\\\n                                --name \\\\\\\"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\\\\\\\" \\\\\\\\\\\\n                                --query 'Parameter.Value' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION} 2>/dev/null || echo \\\\\\\"\\\\\\\"\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    if (!env.BACKUP_BUCKET) {\\\\n                        error(\\\\\\\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\\\\\\\")\\\\n                    }\\\\n                    \\\\n                    echo \\\\\\\"Backup S3 Bucket: ${env.BACKUP_BUCKET}\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Prepare Scripts') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Preparing Collection Scripts ===\\\\\\\"\\\\n                    \\\\n                    // Jenkinsリポジトリをチェックアウト\\\\n                    dir('jenkins-repo') {\\\\n                        checkout([\\\\n                            $class: 'GitSCM',\\\\n                            branches: [[name: \\\\\\\"${params.JENKINSFILE_BRANCH}\\\\\\\"]],\\\\n                            userRemoteConfigs: [[\\\\n                                url: 'https://github.com/tielec/infrastructure-as-code',\\\\n                                credentialsId: 'github-app-credentials'\\\\n                            ]]\\\\n                        ])\\\\n                    }\\\\n                    \\\\n                    // スクリプトをコピー\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\\\\n                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\\\\n                        \\\\n                        echo \\\\\\\"Script copied and made executable\\\\\\\"\\\\n                        ls -la ${SCRIPT_DIR}/\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Collect Parameters') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Collecting SSM Parameters ===\\\\\\\"\\\\n                    \\\\n                    // スクリプトの実行\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        # 環境変数を設定\\\\n                        export ENVIRONMENT=\\\\\\\"${params.ENVIRONMENT}\\\\\\\"\\\\n                        export ENV_FILTER=\\\\\\\"${env.ENV_FILTER}\\\\\\\"\\\\n                        export AWS_REGION=\\\\\\\"${AWS_REGION}\\\\\\\"\\\\n                        export BACKUP_DATE=\\\\\\\"${env.BACKUP_DATE}\\\\\\\"\\\\n                        export BACKUP_TIMESTAMP=\\\\\\\"${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                        export DATA_DIR=\\\\\\\"${DATA_DIR}\\\\\\\"\\\\n                        \\\\n                        # スクリプト実行\\\\n                        ${SCRIPT_DIR}/collect_parameters.sh\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの確認\\\\n                    if (fileExists(\\\\\\\"${DATA_DIR}/backup.json\\\\\\\")) {\\\\n                        def backupData = readJSON file: \\\\\\\"${DATA_DIR}/backup.json\\\\\\\"\\\\n                        env.PARAM_COUNT = backupData.parameter_count.toString()\\\\n                        \\\\n                        if (backupData.parameter_count == 0) {\\\\n                            echo \\\\\\\"WARNING: No parameters found for backup\\\\\\\"\\\\n                            currentBuild.result = 'UNSTABLE'\\\\n                        } else {\\\\n                            echo \\\\\\\"Backup file contains ${backupData.parameter_count} parameters\\\\\\\"\\\\n                        }\\\\n                    } else {\\\\n                        error(\\\\\\\"Backup file was not created\\\\\\\")\\\\n                    }\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Upload to S3') {\\\\n            when {\\\\n                expression { \\\\n                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\\\\n                }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Uploading Backup to S3 ===\\\\\\\"\\\\n                    \\\\n                    def backupFileName = \\\\\\\"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\\\\"\\\\n                    def s3Key = \\\\\\\"${env.BACKUP_DATE}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの名前を変更\\\\n                    sh \\\\\\\"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // S3へアップロード（暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\\\\\\\\\\n                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\\\\\\\"\\\\n                    \\\\n                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        echo '${s3Key}' | \\\\\\\\\\\\n                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // アップロード確認\\\\n                    def s3ObjectInfo = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws s3api head-object \\\\\\\\\\\\n                                --bucket ${env.BACKUP_BUCKET} \\\\\\\\\\\\n                                --key ${s3Key} \\\\\\\\\\\\n                                --query '[ContentLength, LastModified]' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION}\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    echo \\\\\\\"S3 Object Info: ${s3ObjectInfo}\\\\\\\"\\\\n                    \\\\n                    // セキュリティ上の理由によりアーティファクトとしては保存しない\\\\n                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:22:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '200,400p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Dry Run Report') {\\\\n            when {\\\\n                expression { params.DRY_RUN }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    def paramCount = env.PARAM_COUNT ?: '0'\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    DRY RUN - バックアップ実行レポート\\\\n                    =============================================\\\\n                    \\\\n                    このドライランでは実際のS3アップロードは行われませんでした。\\\\n                    \\\\n                    バックアップ対象:\\\\n                    - 環境: ${params.ENVIRONMENT}\\\\n                    - パラメータ数: ${paramCount}\\\\n                    - バックアップ日時: ${env.BACKUP_TIMESTAMP}\\\\n                    \\\\n                    実行時の動作:\\\\n                    - S3バケット: ${env.BACKUP_BUCKET}\\\\n                    - S3パス: ${env.BACKUP_DATE}/\\\\n                    - ファイル名: ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\n                    \\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // セキュリティ上の理由によりドライラン時もアーティファクトとして保存しない\\\\n                }\\\\n            }\\\\n        }\\\\n    }\\\\n    \\\\n    post {\\\\n        always {\\\\n            script {\\\\n                def paramCount = env.PARAM_COUNT ?: '0'\\\\n                \\\\n                // 実行サマリーの表示\\\\n                echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                =============================================\\\\n                SSM Parameter Store Backup Summary\\\\n                =============================================\\\\n                Build: #${env.BUILD_NUMBER}\\\\n                Status: ${currentBuild.result ?: 'SUCCESS'}\\\\n                Environment: ${params.ENVIRONMENT}\\\\n                Parameters: ${paramCount}\\\\n                Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                Dry Run: ${params.DRY_RUN}\\\\n                =============================================\\\\n                \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n            }\\\\n        }\\\\n        \\\\n        success {\\\\n            echo \\\\\\\"✅ SSMパラメータのバックアップが正常に完了しました\\\\\\\"\\\\n        }\\\\n        \\\\n        failure {\\\\n            echo \\\\\\\"❌ バックアップが失敗しました。ログを確認してください\\\\\\\"\\\\n        }\\\\n        \\\\n        unstable {\\\\n            echo \\\\\\\"⚠️ バックアップは完了しましたが、警告があります\\\\\\\"\\\\n        }\\\\n        \\\\n        cleanup {\\\\n            // 作業ディレクトリのクリーンアップ\\\\n            sh \\\\\\\"rm -rf ${WORK_DIR} ${SCRIPT_DIR} jenkins-repo || true\\\\\\\"\\\\n        }\\\\n    }\\\\n}\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:41:[DEBUG][Codex][5] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_1\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,160p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:45:[DEBUG][Codex][9] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"@Library('jenkins-shared-lib') _\\\\n\\\\n/**\\\\n * SSM Parameter Store Backup Pipeline\\\\n * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\\\\n */\\\\npipeline {\\\\n    agent {\\\\n        label 'ec2-fleet'\\\\n    }\\\\n    \\\\n    options {\\\\n        timestamps()\\\\n        timeout(time: 1, unit: 'HOURS')\\\\n        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\\\\n        disableConcurrentBuilds()\\\\n    }\\\\n    \\\\n    environment {\\\\n        // AWS設定\\\\n        AWS_REGION = 'ap-northeast-1'\\\\n        \\\\n        // タイムスタンプ\\\\n        BACKUP_DATE = sh(script: \\\\\\\"date '+%Y-%m-%d'\\\\\\\", returnStdout: true).trim()\\\\n        BACKUP_TIMESTAMP = sh(script: \\\\\\\"date '+%Y%m%d_%H%M%S'\\\\\\\", returnStdout: true).trim()\\\\n        \\\\n        // ディレクトリ構造\\\\n        WORK_DIR = \\\\\\\"${WORKSPACE}/backup-work\\\\\\\"\\\\n        DATA_DIR = \\\\\\\"${WORK_DIR}/data\\\\\\\"\\\\n        SCRIPT_DIR = \\\\\\\"${WORKSPACE}/scripts\\\\\\\"\\\\n        \\\\n        // 環境フィルタ（環境に含まれる文字列）\\\\n        ENV_FILTER = \\\\\\\"/${params.ENVIRONMENT}/\\\\\\\"\\\\n    }\\\\n    \\\\n    stages {\\\\n        stage('Initialize') {\\\\n            steps {\\\\n                script {\\\\n                    // ビルド表示名を設定\\\\n                    currentBuild.displayName = \\\\\\\"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\\\\\\\"\\\\n                    currentBuild.description = \\\\\\\"Backup at ${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    SSM Parameter Store Backup\\\\n                    =============================================\\\\n                    Environment: ${params.ENVIRONMENT}\\\\n                    Filter: Parameters containing '${env.ENV_FILTER}'\\\\n                    Dry Run: ${params.DRY_RUN}\\\\n                    Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                    Date: ${env.BACKUP_DATE}\\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // 作業ディレクトリの準備\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        rm -rf ${WORK_DIR}\\\\n                        mkdir -p ${DATA_DIR}\\\\n                        mkdir -p ${SCRIPT_DIR}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // S3バケット名の取得\\\\n                    env.BACKUP_BUCKET = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws ssm get-parameter \\\\\\\\\\\\n                                --name \\\\\\\"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\\\\\\\" \\\\\\\\\\\\n                                --query 'Parameter.Value' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION} 2>/dev/null || echo \\\\\\\"\\\\\\\"\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    if (!env.BACKUP_BUCKET) {\\\\n                        error(\\\\\\\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\\\\\\\")\\\\n                    }\\\\n                    \\\\n                    echo \\\\\\\"Backup S3 Bucket: ${env.BACKUP_BUCKET}\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Prepare Scripts') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Preparing Collection Scripts ===\\\\\\\"\\\\n                    \\\\n                    // Jenkinsリポジトリをチェックアウト\\\\n                    dir('jenkins-repo') {\\\\n                        checkout([\\\\n                            $class: 'GitSCM',\\\\n                            branches: [[name: \\\\\\\"${params.JENKINSFILE_BRANCH}\\\\\\\"]],\\\\n                            userRemoteConfigs: [[\\\\n                                url: 'https://github.com/tielec/infrastructure-as-code',\\\\n                                credentialsId: 'github-app-credentials'\\\\n                            ]]\\\\n                        ])\\\\n                    }\\\\n                    \\\\n                    // スクリプトをコピー\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\\\\n                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\\\\n                        \\\\n                        echo \\\\\\\"Script copied and made executable\\\\\\\"\\\\n                        ls -la ${SCRIPT_DIR}/\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Collect Parameters') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Collecting SSM Parameters ===\\\\\\\"\\\\n                    \\\\n                    // スクリプトの実行\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        # 環境変数を設定\\\\n                        export ENVIRONMENT=\\\\\\\"${params.ENVIRONMENT}\\\\\\\"\\\\n                        export ENV_FILTER=\\\\\\\"${env.ENV_FILTER}\\\\\\\"\\\\n                        export AWS_REGION=\\\\\\\"${AWS_REGION}\\\\\\\"\\\\n                        export BACKUP_DATE=\\\\\\\"${env.BACKUP_DATE}\\\\\\\"\\\\n                        export BACKUP_TIMESTAMP=\\\\\\\"${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                        export DATA_DIR=\\\\\\\"${DATA_DIR}\\\\\\\"\\\\n                        \\\\n                        # スクリプト実行\\\\n                        ${SCRIPT_DIR}/collect_parameters.sh\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの確認\\\\n                    if (fileExists(\\\\\\\"${DATA_DIR}/backup.json\\\\\\\")) {\\\\n                        def backupData = readJSON file: \\\\\\\"${DATA_DIR}/backup.json\\\\\\\"\\\\n                        env.PARAM_COUNT = backupData.parameter_count.toString()\\\\n                        \\\\n                        if (backupData.parameter_count == 0) {\\\\n                            echo \\\\\\\"WARNING: No parameters found for backup\\\\\\\"\\\\n                            currentBuild.result = 'UNSTABLE'\\\\n                        } else {\\\\n                            echo \\\\\\\"Backup file contains ${backupData.parameter_count} parameters\\\\\\\"\\\\n                        }\\\\n                    } else {\\\\n                        error(\\\\\\\"Backup file was not created\\\\\\\")\\\\n                    }\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Upload to S3') {\\\\n            when {\\\\n                expression { \\\\n                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\\\\n                }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Uploading Backup to S3 ===\\\\\\\"\\\\n                    \\\\n                    def backupFileName = \\\\\\\"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\\\\"\\\\n                    def s3Key = \\\\\\\"${env.BACKUP_DATE}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの名前を変更\\\\n                    sh \\\\\\\"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // S3へアップロード（暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\\\\\\\\\\n                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\\\\\\\"\\\\n                    \\\\n                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        echo '${s3Key}' | \\\\\\\\\\\\n                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // アップロード確認\\\\n                    def s3ObjectInfo = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws s3api head-object \\\\\\\\\\\\n                                --bucket ${env.BACKUP_BUCKET} \\\\\\\\\\\\n                                --key ${s3Key} \\\\\\\\\\\\n                                --query '[ContentLength, LastModified]' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION}\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    echo \\\\\\\"S3 Object Info: ${s3ObjectInfo}\\\\\\\"\\\\n                    \\\\n                    // セキュリティ上の理由によりアーティファクトとしては保存しない\\\\n                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:249:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:251:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"@Library('jenkins-shared-lib') _\\\\n\\\\n/**\\\\n * SSM Parameter Store Backup Pipeline\\\\n * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\\\\n */\\\\npipeline {\\\\n    agent {\\\\n        label 'ec2-fleet'\\\\n    }\\\\n    \\\\n    options {\\\\n        timestamps()\\\\n        timeout(time: 1, unit: 'HOURS')\\\\n        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\\\\n        disableConcurrentBuilds()\\\\n    }\\\\n    \\\\n    environment {\\\\n        // AWS設定\\\\n        AWS_REGION = 'ap-northeast-1'\\\\n        \\\\n        // タイムスタンプ\\\\n        BACKUP_DATE = sh(script: \\\\\\\"date '+%Y-%m-%d'\\\\\\\", returnStdout: true).trim()\\\\n        BACKUP_TIMESTAMP = sh(script: \\\\\\\"date '+%Y%m%d_%H%M%S'\\\\\\\", returnStdout: true).trim()\\\\n        \\\\n        // ディレクトリ構造\\\\n        WORK_DIR = \\\\\\\"${WORKSPACE}/backup-work\\\\\\\"\\\\n        DATA_DIR = \\\\\\\"${WORK_DIR}/data\\\\\\\"\\\\n        SCRIPT_DIR = \\\\\\\"${WORKSPACE}/scripts\\\\\\\"\\\\n        \\\\n        // 環境フィルタ（環境に含まれる文字列）\\\\n        ENV_FILTER = \\\\\\\"/${params.ENVIRONMENT}/\\\\\\\"\\\\n    }\\\\n    \\\\n    stages {\\\\n        stage('Initialize') {\\\\n            steps {\\\\n                script {\\\\n                    // ビルド表示名を設定\\\\n                    currentBuild.displayName = \\\\\\\"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\\\\\\\"\\\\n                    currentBuild.description = \\\\\\\"Backup at ${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    SSM Parameter Store Backup\\\\n                    =============================================\\\\n                    Environment: ${params.ENVIRONMENT}\\\\n                    Filter: Parameters containing '${env.ENV_FILTER}'\\\\n                    Dry Run: ${params.DRY_RUN}\\\\n                    Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                    Date: ${env.BACKUP_DATE}\\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // 作業ディレクトリの準備\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        rm -rf ${WORK_DIR}\\\\n                        mkdir -p ${DATA_DIR}\\\\n                        mkdir -p ${SCRIPT_DIR}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // S3バケット名の取得\\\\n                    env.BACKUP_BUCKET = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws ssm get-parameter \\\\\\\\\\\\n                                --name \\\\\\\"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\\\\\\\" \\\\\\\\\\\\n                                --query 'Parameter.Value' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION} 2>/dev/null || echo \\\\\\\"\\\\\\\"\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    if (!env.BACKUP_BUCKET) {\\\\n                        error(\\\\\\\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\\\\\\\")\\\\n                    }\\\\n                    \\\\n                    echo \\\\\\\"Backup S3 Bucket: ${env.BACKUP_BUCKET}\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Prepare Scripts') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Preparing Collection Scripts ===\\\\\\\"\\\\n                    \\\\n                    // Jenkinsリポジトリをチェックアウト\\\\n                    dir('jenkins-repo') {\\\\n                        checkout([\\\\n                            $class: 'GitSCM',\\\\n                            branches: [[name: \\\\\\\"${params.JENKINSFILE_BRANCH}\\\\\\\"]],\\\\n                            userRemoteConfigs: [[\\\\n                                url: 'https://github.com/tielec/infrastructure-as-code',\\\\n                                credentialsId: 'github-app-credentials'\\\\n                            ]]\\\\n                        ])\\\\n                    }\\\\n                    \\\\n                    // スクリプトをコピー\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\\\\n                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\\\\n                        \\\\n                        echo \\\\\\\"Script copied and made executable\\\\\\\"\\\\n                        ls -la ${SCRIPT_DIR}/\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Collect Parameters') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Collecting SSM Parameters ===\\\\\\\"\\\\n                    \\\\n                    // スクリプトの実行\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        # 環境変数を設定\\\\n                        export ENVIRONMENT=\\\\\\\"${params.ENVIRONMENT}\\\\\\\"\\\\n                        export ENV_FILTER=\\\\\\\"${env.ENV_FILTER}\\\\\\\"\\\\n                        export AWS_REGION=\\\\\\\"${AWS_REGION}\\\\\\\"\\\\n                        export BACKUP_DATE=\\\\\\\"${env.BACKUP_DATE}\\\\\\\"\\\\n                        export BACKUP_TIMESTAMP=\\\\\\\"${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                        export DATA_DIR=\\\\\\\"${DATA_DIR}\\\\\\\"\\\\n                        \\\\n                        # スクリプト実行\\\\n                        ${SCRIPT_DIR}/collect_parameters.sh\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの確認\\\\n                    if (fileExists(\\\\\\\"${DATA_DIR}/backup.json\\\\\\\")) {\\\\n                        def backupData = readJSON file: \\\\\\\"${DATA_DIR}/backup.json\\\\\\\"\\\\n                        env.PARAM_COUNT = backupData.parameter_count.toString()\\\\n                        \\\\n                        if (backupData.parameter_count == 0) {\\\\n                            echo \\\\\\\"WARNING: No parameters found for backup\\\\\\\"\\\\n                            currentBuild.result = 'UNSTABLE'\\\\n                        } else {\\\\n                            echo \\\\\\\"Backup file contains ${backupData.parameter_count} parameters\\\\\\\"\\\\n                        }\\\\n                    } else {\\\\n                        error(\\\\\\\"Backup file was not created\\\\\\\")\\\\n                    }\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Upload to S3') {\\\\n            when {\\\\n                expression { \\\\n                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\\\\n                }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Uploading Backup to S3 ===\\\\\\\"\\\\n                    \\\\n                    def backupFileName = \\\\\\\"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\\\\"\\\\n                    def s3Key = \\\\\\\"${env.BACKUP_DATE}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの名前を変更\\\\n                    sh \\\\\\\"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // S3へアップロード（暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\\\\\\\\\\n                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\\\\\\\"\\\\n                    \\\\n                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        echo '${s3Key}' | \\\\\\\\\\\\n                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // アップロード確認\\\\n                    def s3ObjectInfo = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws s3api head-object \\\\\\\\\\\\n                                --bucket ${env.BACKUP_BUCKET} \\\\\\\\\\\\n                                --key ${s3Key} \\\\\\\\\\\\n                                --query '[ContentLength, LastModified]' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION}\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    echo \\\\\\\"S3 Object Info: ${s3ObjectInfo}\\\\\\\"\\\\n                    \\\\n                    // セキュリティ上の理由によりアーティファクトとしては保存しない\\\\n                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:253:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '200,400p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Dry Run Report') {\\\\n            when {\\\\n                expression { params.DRY_RUN }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    def paramCount = env.PARAM_COUNT ?: '0'\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    DRY RUN - バックアップ実行レポート\\\\n                    =============================================\\\\n                    \\\\n                    このドライランでは実際のS3アップロードは行われませんでした。\\\\n                    \\\\n                    バックアップ対象:\\\\n                    - 環境: ${params.ENVIRONMENT}\\\\n                    - パラメータ数: ${paramCount}\\\\n                    - バックアップ日時: ${env.BACKUP_TIMESTAMP}\\\\n                    \\\\n                    実行時の動作:\\\\n                    - S3バケット: ${env.BACKUP_BUCKET}\\\\n                    - S3パス: ${env.BACKUP_DATE}/\\\\n                    - ファイル名: ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\n                    \\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // セキュリティ上の理由によりドライラン時もアーティファクトとして保存しない\\\\n                }\\\\n            }\\\\n        }\\\\n    }\\\\n    \\\\n    post {\\\\n        always {\\\\n            script {\\\\n                def paramCount = env.PARAM_COUNT ?: '0'\\\\n                \\\\n                // 実行サマリーの表示\\\\n                echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                =============================================\\\\n                SSM Parameter Store Backup Summary\\\\n                =============================================\\\\n                Build: #${env.BUILD_NUMBER}\\\\n                Status: ${currentBuild.result ?: 'SUCCESS'}\\\\n                Environment: ${params.ENVIRONMENT}\\\\n                Parameters: ${paramCount}\\\\n                Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                Dry Run: ${params.DRY_RUN}\\\\n                =============================================\\\\n                \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n            }\\\\n        }\\\\n        \\\\n        success {\\\\n            echo \\\\\\\"✅ SSMパラメータのバックアップが正常に完了しました\\\\\\\"\\\\n        }\\\\n        \\\\n        failure {\\\\n            echo \\\\\\\"❌ バックアップが失敗しました。ログを確認してください\\\\\\\"\\\\n        }\\\\n        \\\\n        unstable {\\\\n            echo \\\\\\\"⚠️ バックアップは完了しましたが、警告があります\\\\\\\"\\\\n        }\\\\n        \\\\n        cleanup {\\\\n            // 作業ディレクトリのクリーンアップ\\\\n            sh \\\\\\\"rm -rf ${WORK_DIR} ${SCRIPT_DIR} jenkins-repo || true\\\\\\\"\\\\n        }\\\\n    }\\\\n}\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:288:[DEBUG][Codex][9] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:304:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Declarative Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、各リージョンを逐次ステージ化してバックアップ処理・S3 へのアップロード・ログ集計を実施。失敗時は後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. `Regional Backup Orchestrator` ステージの Imperative ブロックがリージョンごとにサブステージを生成。各サブステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照��。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` のステージ分割とヘルパーメソッドを実装し、Declarative Linter を通す。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:308:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,160p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Declarative Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、各リージョンを逐次ステージ化してバックアップ処理・S3 へのアップロード・ログ集計を実施。失敗時は後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. `Regional Backup Orchestrator` ステージの Imperative ブロックがリージョンごとにサブステージを生成。各サブステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:316:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_9\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '90,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:348:[DEBUG][Codex][9] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Declarative Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、各リージョンを逐次ステージ化してバックアップ処理・S3 へのアップロード・ログ集計を実施。失敗時は後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. `Regional Backup Orchestrator` ステージの Imperative ブロックがリージョンごとにサブステージを生成。各サブステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` のステージ分割とヘルパーメソッドを実装し、Declarative Linter を通す。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:360:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_2\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Declarative Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、各リージョンを逐次ステージ化してバックアップ処理・S3 へのアップロード・ログ集計を実施。失敗時は後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. `Regional Backup Orchestrator` ステージの Imperative ブロックがリージョンごとにサブステージを生成。各サブステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:370:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_7\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '80,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:378:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_12\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '120,170p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:383:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_16\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '40,120p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:392:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_22\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '120,220p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` 内で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` で取得し、存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `collect_parameters.sh` 実行結果 (`results/summary.json`) から `parameterCount` を読み取り、S3 へアップロードするアーティファクトパスを返す。\\\\n  - 取得結果は `return [bucket: ..., dataDir: ..., summaryPath: ...]` のように Map で返却し、ループ内で使い回す。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `loadRegionContext(region)` を呼び出し、取得したバケット名でアップロード。DRY_RUN 時は `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: ctx.parameterCount, artifactPath: ctx.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、同梱の簡易 HTTP サーバで受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:403:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_30\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,120p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:405:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_31\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '120,220p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n   141\\\\t  1. `stage('Initialize')`\\\\n   142\\\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n   143\\\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n   144\\\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n   145\\\\t  2. `stage('Prepare Scripts')`\\\\n   146\\\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n   147\\\\t  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n   148\\\\t     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n   149\\\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n   150\\\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n   151\\\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n   152\\\\t  4. `stage('Finalize Report')`\\\\n   153\\\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n   154\\\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n   155\\\\t- **エラー制御**\\\\n   156\\\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n   157\\\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n   158\\\\t- **メトリクス／ログ**\\\\n   159\\\\t  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n   160\\\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n   161\\\\t\\\\n   162\\\\t### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n   163\\\\t- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n   164\\\\t- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n   165\\\\t- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n   166\\\\t\\\\n   167\\\\t### 7.4 `collect_parameters.sh`\\\\n   168\\\\t- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n   169\\\\t- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n   170\\\\t- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n   171\\\\t\\\\n   172\\\\t### 7.5 テスト設計詳細\\\\n   173\\\\t- **Pulumi (Jest)**  \\\\n   174\\\\t  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n   175\\\\t  - 期待事項:  \\\\n   176\\\\t    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n   177\\\\t    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n   178\\\\t    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n   179\\\\t    - `bucketMap` エクスポートが全リージョンを包含。\\\\n   180\\\\t- **Jenkins (jenkinsfile-runner)**  \\\\n   181\\\\t  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n   182\\\\t  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n   183\\\\t  - 検証点:  \\\\n   184\\\\t    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n   185\\\\t    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n   186\\\\t    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n   187\\\\t- **Manual テスト**  \\\\n   188\\\\t  - `pulumi preview` で各リージョンの差分を確認。  \\\\n   189\\\\t  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n   190\\\\t  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n   191\\\\t  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n   192\\\\t\\\\n   193\\\\t### 7.6 トレーサビリティ\\\\n   194\\\\t| 要件ID | 設計上の対応箇所 |\\\\n   195\\\\t| ------ | ---------------- |\\\\n   196\\\\t| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n   197\\\\t| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n   198\\\\t| FR-3 | Jenkins Regional orchestrator ス���ージ設計（7.2） |\\\\n   199\\\\t| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n   200\\\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n   201\\\\t\\\\n   202\\\\t### 7.7 通知計画 (FR-5)\\\\n   203\\\\t- **対象者**  \\\\n   204\\\\t  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n   205\\\\t  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n   206\\\\t- **チャネル**  \\\\n   207\\\\t  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n   208\\\\t  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n   209\\\\t- **タイミング**  \\\\n   210\\\\t  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n   211\\\\t  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n   212\\\\t  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n   213\\\\t- **責任者**  \\\\n   214\\\\t  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n   215\\\\t  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n   216\\\\t  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n   217\\\\t- **テスト/検証**  \\\\n   218\\\\t  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n   219\\\\t  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n   220\\\\t- **Runbook 更新**  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:409:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_33\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '80,140p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"    80\\\\t- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n    81\\\\t\\\\n    82\\\\t## 6. 変更・追加ファイルリスト\\\\n    83\\\\t| 区分 | ファイル/パス | 目的 |\\\\n    84\\\\t| ---- | ------------- | ---- |\\\\n    85\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n    86\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n    87\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n    88\\\\t| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n    89\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n    90\\\\t| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n    91\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n    92\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n    93\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n    94\\\\t| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n    95\\\\t| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n    96\\\\t\\\\n    97\\\\t## 7. 詳細設計\\\\n    98\\\\t\\\\n    99\\\\t### 7.1 Pulumi (IaC) 詳細\\\\n   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバイン���。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:421:[DEBUG][Codex][7] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_2\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Declarative Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、各リージョンを逐次ステージ化してバックアップ処理・S3 へのアップロード・ログ集計を実施。失敗時は後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. `Regional Backup Orchestrator` ステージの Imperative ブロックがリージョンごとにサブステージを生成。各サブステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:442:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:444:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_6\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '60,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:448:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_8\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '120,260p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:450:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_9\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '80,180p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:454:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_11\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '1,160p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"     1\\\\t# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n     2\\\\t\\\\n     3\\\\t## 1. アーキテクチャ設計\\\\n     4\\\\t\\\\n     5\\\\t### 1.1 システム全体図\\\\n     6\\\\t```mermaid\\\\n     7\\\\tflowchart TD\\\\n     8\\\\t    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n     9\\\\t        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n    10\\\\t        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n    11\\\\t        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    12\\\\t    end\\\\n    13\\\\t\\\\n    14\\\\t    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n    15\\\\t        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n    16\\\\t        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n    17\\\\t            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n    18\\\\t            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n    19\\\\t            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n    20\\\\t        end\\\\n    21\\\\t    end\\\\n    22\\\\t\\\\n    23\\\\t    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n    24\\\\t        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n    25\\\\t        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n    26\\\\t        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    27\\\\t    end\\\\n    28\\\\t\\\\n    29\\\\t    DSL -->|SCM sync| Pipeline\\\\n    30\\\\t    Pipeline -->|fetch| Script\\\\n    31\\\\t    Pipeline -->|Read config & region list| SSM\\\\n    32\\\\t    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    33\\\\t    Pipeline --> BucketB\\\\n    34\\\\t    Pipeline --> BucketC\\\\n    35\\\\t    Pulumi -->|pulumi up| Regions\\\\n    36\\\\t    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    37\\\\t    Tests --> IaC\\\\n    38\\\\t```\\\\n    39\\\\t\\\\n    40\\\\t### 1.2 コンポーネント間の関係\\\\n    41\\\\t- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n    42\\\\t- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n    43\\\\t- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n    44\\\\t- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n    45\\\\t\\\\n    46\\\\t### 1.3 データフロー\\\\n    47\\\\t1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n    48\\\\t2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n    49\\\\t3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n    50\\\\t4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n    51\\\\t   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n    52\\\\t   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n    53\\\\t   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n    54\\\\t5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n    55\\\\t\\\\n    56\\\\t## 2. 実装戦略: EXTEND\\\\n    57\\\\t\\\\n    58\\\\t**判断根拠**:\\\\n    59\\\\t- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n    60\\\\t- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n    61\\\\t\\\\n    62\\\\t## 3. テスト戦略: UNIT_INTEGRATION\\\\n    63\\\\t\\\\n    64\\\\t**判断根拠**:\\\\n    65\\\\t- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n    66\\\\t- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n    67\\\\t\\\\n    68\\\\t## 4. テストコード戦略: CREATE_TEST\\\\n    69\\\\t\\\\n    70\\\\t**判断根拠**:\\\\n    71\\\\t- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n    72\\\\t- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n    73\\\\t\\\\n    74\\\\t## 5. 影響範囲分析\\\\n    75\\\\t- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n    76\\\\t- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n    77\\\\t- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n    78\\\\t- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n    79\\\\t- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n    80\\\\t- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n    81\\\\t\\\\n    82\\\\t## 6. 変更・追加ファイルリスト\\\\n    83\\\\t| 区分 | ファイル/パス | 目的 |\\\\n    84\\\\t| ---- | ------------- | ---- |\\\\n    85\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n    86\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n    87\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n    88\\\\t| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n    89\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n    90\\\\t| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n    91\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n    92\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n    93\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n    94\\\\t| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n    95\\\\t| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n    96\\\\t\\\\n    97\\\\t## 7. 詳細設計\\\\n    98\\\\t\\\\n    99\\\\t### 7.1 Pulumi (IaC) 詳細\\\\n   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n   141\\\\t  1. `stage('Initialize')`\\\\n   142\\\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n   143\\\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n   144\\\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n   145\\\\t  2. `stage('Prepare Scripts')`\\\\n   146\\\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n   147\\\\t  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n   148\\\\t     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n   149\\\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n   150\\\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n   151\\\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n   152\\\\t  4. `stage('Finalize Report')`\\\\n   153\\\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n   154\\\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n   155\\\\t- **エラー制御**\\\\n   156\\\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n   157\\\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n   158\\\\t- **メトリクス／ログ**\\\\n   159\\\\t  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n   160\\\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:458:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_13\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '100,200p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n   141\\\\t  1. `stage('Initialize')`\\\\n   142\\\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n   143\\\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n   144\\\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n   145\\\\t  2. `stage('Prepare Scripts')`\\\\n   146\\\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n   147\\\\t  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n   148\\\\t     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n   149\\\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n   150\\\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n   151\\\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n   152\\\\t  4. `stage('Finalize Report')`\\\\n   153\\\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n   154\\\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n   155\\\\t- **エラー制御**\\\\n   156\\\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n   157\\\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n   158\\\\t- **メトリクス／ログ**\\\\n   159\\\\t  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n   160\\\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n   161\\\\t\\\\n   162\\\\t### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n   163\\\\t- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n   164\\\\t- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n   165\\\\t- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n   166\\\\t\\\\n   167\\\\t### 7.4 `collect_parameters.sh`\\\\n   168\\\\t- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n   169\\\\t- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n   170\\\\t- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n   171\\\\t\\\\n   172\\\\t### 7.5 テスト設計詳細\\\\n   173\\\\t- **Pulumi (Jest)**  \\\\n   174\\\\t  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n   175\\\\t  - 期待事項:  \\\\n   176\\\\t    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n   177\\\\t    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n   178\\\\t    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n   179\\\\t    - `bucketMap` エクスポートが全リージョンを包含。\\\\n   180\\\\t- **Jenkins (jenkinsfile-runner)**  \\\\n   181\\\\t  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n   182\\\\t  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n   183\\\\t  - 検証点:  \\\\n   184\\\\t    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n   185\\\\t    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n   186\\\\t    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n   187\\\\t- **Manual テスト**  \\\\n   188\\\\t  - `pulumi preview` で各リージョンの差分を確認。  \\\\n   189\\\\t  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n   190\\\\t  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n   191\\\\t  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n   192\\\\t\\\\n   193\\\\t### 7.6 トレーサビリティ\\\\n   194\\\\t| 要件ID | 設計上の対応箇所 |\\\\n   195\\\\t| ------ | ---------------- |\\\\n   196\\\\t| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n   197\\\\t| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n   198\\\\t| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n   199\\\\t| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n   200\\\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:460:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_14\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '60,120p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"    60\\\\t- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n    61\\\\t\\\\n    62\\\\t## 3. テスト戦略: UNIT_INTEGRATION\\\\n    63\\\\t\\\\n    64\\\\t**判断根拠**:\\\\n    65\\\\t- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n    66\\\\t- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n    67\\\\t\\\\n    68\\\\t## 4. テストコード戦略: CREATE_TEST\\\\n    69\\\\t\\\\n    70\\\\t**判断根拠**:\\\\n    71\\\\t- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n    72\\\\t- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n    73\\\\t\\\\n    74\\\\t## 5. 影響範囲分析\\\\n    75\\\\t- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n    76\\\\t- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n    77\\\\t- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n    78\\\\t- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n    79\\\\t- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n    80\\\\t- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n    81\\\\t\\\\n    82\\\\t## 6. 変更・追加ファイルリスト\\\\n    83\\\\t| 区分 | ファイル/パス | 目的 |\\\\n    84\\\\t| ---- | ------------- | ---- |\\\\n    85\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n    86\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n    87\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n    88\\\\t| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n    89\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n    90\\\\t| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n    91\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n    92\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n    93\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n    94\\\\t| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n    95\\\\t| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n    96\\\\t\\\\n    97\\\\t## 7. 詳細設計\\\\n    98\\\\t\\\\n    99\\\\t### 7.1 Pulumi (IaC) 詳細\\\\n   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:492:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキ���クチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:494:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && sed -n '1,160p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:502:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_9\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && sed -n '80,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:537:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:575:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_1\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリー���ョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:583:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:589:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_8\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"@Library('jenkins-shared-lib') _\\\\n\\\\n/**\\\\n * SSM Parameter Store Backup Pipeline\\\\n * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\\\\n */\\\\npipeline {\\\\n    agent {\\\\n        label 'ec2-fleet'\\\\n    }\\\\n    \\\\n    options {\\\\n        timestamps()\\\\n        timeout(time: 1, unit: 'HOURS')\\\\n        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\\\\n        disableConcurrentBuilds()\\\\n    }\\\\n    \\\\n    environment {\\\\n        // AWS設定\\\\n        AWS_REGION = 'ap-northeast-1'\\\\n        \\\\n        // タイムスタンプ\\\\n        BACKUP_DATE = sh(script: \\\\\\\"date '+%Y-%m-%d'\\\\\\\", returnStdout: true).trim()\\\\n        BACKUP_TIMESTAMP = sh(script: \\\\\\\"date '+%Y%m%d_%H%M%S'\\\\\\\", returnStdout: true).trim()\\\\n        \\\\n        // ディレクトリ構造\\\\n        WORK_DIR = \\\\\\\"${WORKSPACE}/backup-work\\\\\\\"\\\\n        DATA_DIR = \\\\\\\"${WORK_DIR}/data\\\\\\\"\\\\n        SCRIPT_DIR = \\\\\\\"${WORKSPACE}/scripts\\\\\\\"\\\\n        \\\\n        // 環境フィルタ（環境に含まれる文字列）\\\\n        ENV_FILTER = \\\\\\\"/${params.ENVIRONMENT}/\\\\\\\"\\\\n    }\\\\n    \\\\n    stages {\\\\n        stage('Initialize') {\\\\n            steps {\\\\n                script {\\\\n                    // ビルド表示名を設定\\\\n                    currentBuild.displayName = \\\\\\\"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\\\\\\\"\\\\n                    currentBuild.description = \\\\\\\"Backup at ${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    SSM Parameter Store Backup\\\\n                    =============================================\\\\n                    Environment: ${params.ENVIRONMENT}\\\\n                    Filter: Parameters containing '${env.ENV_FILTER}'\\\\n                    Dry Run: ${params.DRY_RUN}\\\\n                    Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                    Date: ${env.BACKUP_DATE}\\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // 作業ディレクトリの準備\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        rm -rf ${WORK_DIR}\\\\n                        mkdir -p ${DATA_DIR}\\\\n                        mkdir -p ${SCRIPT_DIR}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // S3バケット名の取得\\\\n                    env.BACKUP_BUCKET = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws ssm get-parameter \\\\\\\\\\\\n                                --name \\\\\\\"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\\\\\\\" \\\\\\\\\\\\n                                --query 'Parameter.Value' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION} 2>/dev/null || echo \\\\\\\"\\\\\\\"\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    if (!env.BACKUP_BUCKET) {\\\\n                        error(\\\\\\\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\\\\\\\")\\\\n                    }\\\\n                    \\\\n                    echo \\\\\\\"Backup S3 Bucket: ${env.BACKUP_BUCKET}\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Prepare Scripts') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Preparing Collection Scripts ===\\\\\\\"\\\\n                    \\\\n                    // Jenkinsリポジトリをチェックアウト\\\\n                    dir('jenkins-repo') {\\\\n                        checkout([\\\\n                            $class: 'GitSCM',\\\\n                            branches: [[name: \\\\\\\"${params.JENKINSFILE_BRANCH}\\\\\\\"]],\\\\n                            userRemoteConfigs: [[\\\\n                                url: 'https://github.com/tielec/infrastructure-as-code',\\\\n                                credentialsId: 'github-app-credentials'\\\\n                            ]]\\\\n                        ])\\\\n                    }\\\\n                    \\\\n                    // スクリプトをコピー\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\\\\n                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\\\\n                        \\\\n                        echo \\\\\\\"Script copied and made executable\\\\\\\"\\\\n                        ls -la ${SCRIPT_DIR}/\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Collect Parameters') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Collecting SSM Parameters ===\\\\\\\"\\\\n                    \\\\n                    // スクリプトの実行\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        # 環境変数を設定\\\\n                        export ENVIRONMENT=\\\\\\\"${params.ENVIRONMENT}\\\\\\\"\\\\n                        export ENV_FILTER=\\\\\\\"${env.ENV_FILTER}\\\\\\\"\\\\n                        export AWS_REGION=\\\\\\\"${AWS_REGION}\\\\\\\"\\\\n                        export BACKUP_DATE=\\\\\\\"${env.BACKUP_DATE}\\\\\\\"\\\\n                        export BACKUP_TIMESTAMP=\\\\\\\"${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                        export DATA_DIR=\\\\\\\"${DATA_DIR}\\\\\\\"\\\\n                        \\\\n                        # スクリプト実行\\\\n                        ${SCRIPT_DIR}/collect_parameters.sh\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの確認\\\\n                    if (fileExists(\\\\\\\"${DATA_DIR}/backup.json\\\\\\\")) {\\\\n                        def backupData = readJSON file: \\\\\\\"${DATA_DIR}/backup.json\\\\\\\"\\\\n                        env.PARAM_COUNT = backupData.parameter_count.toString()\\\\n                        \\\\n                        if (backupData.parameter_count == 0) {\\\\n                            echo \\\\\\\"WARNING: No parameters found for backup\\\\\\\"\\\\n                            currentBuild.result = 'UNSTABLE'\\\\n                        } else {\\\\n                            echo \\\\\\\"Backup file contains ${backupData.parameter_count} parameters\\\\\\\"\\\\n                        }\\\\n                    } else {\\\\n                        error(\\\\\\\"Backup file was not created\\\\\\\")\\\\n                    }\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Upload to S3') {\\\\n            when {\\\\n                expression { \\\\n                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\\\\n                }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Uploading Backup to S3 ===\\\\\\\"\\\\n                    \\\\n                    def backupFileName = \\\\\\\"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\\\\"\\\\n                    def s3Key = \\\\\\\"${env.BACKUP_DATE}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの名前を変更\\\\n                    sh \\\\\\\"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // S3へアップロード（暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\\\\\\\\\\n                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\\\\\\\"\\\\n                    \\\\n                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        echo '${s3Key}' | \\\\\\\\\\\\n                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // アップロード確認\\\\n                    def s3ObjectInfo = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws s3api head-object \\\\\\\\\\\\n                                --bucket ${env.BACKUP_BUCKET} \\\\\\\\\\\\n                                --key ${s3Key} \\\\\\\\\\\\n                                --query '[ContentLength, LastModified]' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION}\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    echo \\\\\\\"S3 Object Info: ${s3ObjectInfo}\\\\\\\"\\\\n                    \\\\n                    // セキュリティ上の理由によりアーティファクトとしては保存しない\\\\n                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:591:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_9\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '200,400p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Dry Run Report') {\\\\n            when {\\\\n                expression { params.DRY_RUN }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    def paramCount = env.PARAM_COUNT ?: '0'\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    DRY RUN - バックアップ実行レポート\\\\n                    =============================================\\\\n                    \\\\n                    このドライランでは実際のS3アップロードは行われませんでした。\\\\n                    \\\\n                    バックアップ対象:\\\\n                    - 環境: ${params.ENVIRONMENT}\\\\n                    - パラメータ数: ${paramCount}\\\\n                    - バックアップ日時: ${env.BACKUP_TIMESTAMP}\\\\n                    \\\\n                    実行時の動作:\\\\n                    - S3バケット: ${env.BACKUP_BUCKET}\\\\n                    - S3パス: ${env.BACKUP_DATE}/\\\\n                    - ファイル名: ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\n                    \\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // セキュリティ上の理由によりドライラン時もアーティファクトとして保存しない\\\\n                }\\\\n            }\\\\n        }\\\\n    }\\\\n    \\\\n    post {\\\\n        always {\\\\n            script {\\\\n                def paramCount = env.PARAM_COUNT ?: '0'\\\\n                \\\\n                // 実行サマリーの表示\\\\n                echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                =============================================\\\\n                SSM Parameter Store Backup Summary\\\\n                =============================================\\\\n                Build: #${env.BUILD_NUMBER}\\\\n                Status: ${currentBuild.result ?: 'SUCCESS'}\\\\n                Environment: ${params.ENVIRONMENT}\\\\n                Parameters: ${paramCount}\\\\n                Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                Dry Run: ${params.DRY_RUN}\\\\n                =============================================\\\\n                \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n            }\\\\n        }\\\\n        \\\\n        success {\\\\n            echo \\\\\\\"✅ SSMパラメータのバックアップが正常に完了しました\\\\\\\"\\\\n        }\\\\n        \\\\n        failure {\\\\n            echo \\\\\\\"❌ バックアップが失敗しました。ログを確認してください\\\\\\\"\\\\n        }\\\\n        \\\\n        unstable {\\\\n            echo \\\\\\\"⚠️ バックアップは完了しましたが、警告があります\\\\\\\"\\\\n        }\\\\n        \\\\n        cleanup {\\\\n            // 作業ディレクトリのクリーンアップ\\\\n            sh \\\\\\\"rm -rf ${WORK_DIR} ${SCRIPT_DIR} jenkins-repo || true\\\\\\\"\\\\n        }\\\\n    }\\\\n}\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:609:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_18\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '110,210p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:619:[CODEX EVENT] {\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_23\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '60,130p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\nscripts/ai-workflow-v2@tmp/durable-bc8bbce0/jenkins-log.txt:622:[CODEX EVENT] {\\\"type\\\":\\\"item.started\\\",\\\"item\\\":{\\\"id\\\":\\\"item_25\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'grep -R \\\\\\\"SSM Parameter Store Backup\\\\\\\" -n'\\\",\\\"aggregated_output\\\":\\\"\\\",\\\"status\\\":\\\"in_progress\\\"}}\\npulumi/jenkins-ssm-backup-s3/index.ts:44:        Purpose: \\\"SSM Parameter Store Backup Storage\\\",\\njenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile:4: * SSM Parameter Store Backup Pipeline\\njenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile:46:                    SSM Parameter Store Backup\\njenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile:247:                SSM Parameter Store Backup Summary\\njenkins/jobs/pipeline/_seed/job-creator/job-config.yaml:70:  # SSM Parameter Store Backup Jobs\\njenkins/jobs/pipeline/_seed/job-creator/job-config.yaml:73:    displayName: 'SSM Parameter Store Backup'\\n.ai-workflow/issue-391/03_test_scenario/review/agent_log_raw.txt:12:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイ��ラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/03_test_scenario/execute/agent_log.md:375:        Purpose: \\\"SSM Parameter Store Backup Storage\\\",\\n.ai-workflow/issue-391/03_test_scenario/execute/agent_log.md:589:  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/03_test_scenario/execute/agent_log_raw.txt:12:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/03_test_scenario/execute/agent_log_raw.txt:14:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && sed -n '1,160p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/03_test_scenario/execute/agent_log_raw.txt:22:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_9\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && sed -n '80,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log.md:259:  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/revise/agent_log.md:416:タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/revise/agent_log.md:606:タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/revise/agent_log.md:868:120\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/revise/agent_log.md:1024:   120\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:8:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_2\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Declarative Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、各リージョンを逐次ステージ化してバックアップ処理・S3 へのアップロード・ログ集計を実施。失敗時は後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. `Regional Backup Orchestrator` ステージの Imperative ブロックがリージョンごとにサブステージを生成。各サブステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config ���加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:18:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_7\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '80,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Declarative linter 通過。  \\\\n    - 3 リージョン構成で stage 名が `${region}` になる。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に 3 番目がスキップされる挙動。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | ドキュメント/Runbook 更新と post 通知フロー（5, 9, 10 節） |\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計をパイプライン `options { timeout(...) }` に反映。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:26:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_12\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '120,170p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **環境変数整理**\\\\n  - `SSM_HOME_REGION`（Pulumi config で指定）を pipeline `environment` に設定し、リージョン一覧読み出しに利用。\\\\n  - グローバル `DATA_DIR` / `WORK_DIR` は維持しつつ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${DATA_DIR}/${region}\\\\\\\"` を生成。\\\\n- **ステージ構成**\\\\n  1. `Initialize`  \\\\n     - displayName/description にリージョン数と defaultRegion を表示。  \\\\n     - `/jenkins/${env}/backup/region-list` を取得して JSON parse。空の場合は失敗。  \\\\n     - `/jenkins/${env}/backup/default-region` で後方互換を確認し、旧 SSM キーと照合。\\\\n  2. `Prepare Scripts`  \\\\n     - 既存 Git checkout を維持。将来テスト用 Branch override も継続。\\\\n  3. `Regional Backup Orchestrator` (新ステージ)  \\\\n     - `script { regionList.each { region -> stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } } }` 形式で動的サブステージを生成。  \\\\n     - サブステージ内処理:\\\\n       - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"BACKUP_REGION_BUCKET=${bucket}\\\\\\\"]) { ... }`\\\\n       - SSM から `/jenkins/${env}/backup/${region}/s3-bucket-name` を取得。取得失敗で `error`。\\\\n       - `Collect Parameters` ロジックを関数化（Groovy method `collectParameters(String region)`）し再利用。\\\\n       - `Upload to S3` 処理も関数化し、DRY_RUN 時はスキップしつつログを region 付きで出力。\\\\n       - ステージ終了時に `env.PARAM_COUNTS[region]`（JSON 文字列）を更新し、post セクションで集計出力。\\\\n  4. `Dry Run Report` は region ごとのログを参照できるようリファクタ。DRY_RUN 時はリスト化された結果を出力。\\\\n- **エラー制御**  \\\\n  `try/catch` ではなく Jenkins declarative の `error()` を利用。1 リージョンでも失敗すれば後続の `stage(\\\\\\\"Backup ${next}\\\\\\\")` は実行されない。\\\\n- **メトリクス収集**  \\\\n  `currentBuild.description` に `Regions=[ap-northeast-1, us-west-2], Default=ap-northeast-1` を記録。Slack 通知拡張が必要な場合は post セクションで `regionSummary` を出力。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:31:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_16\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '40,120p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. ステージが失敗した場合は `error()` で停止し、post セクションで Slack/ログ通知が行われる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` をステージ再編（Initialize → Config load、Regional loop 化）し、失敗制御とログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:40:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_22\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '120,220p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` 内で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` で取得し、存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `collect_parameters.sh` 実行結果 (`results/summary.json`) から `parameterCount` を読み取り、S3 へアップロードするアーティファクトパスを返す。\\\\n  - 取得結果は `return [bucket: ..., dataDir: ..., summaryPath: ...]` のように Map で返却し、ループ内で使い回す。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `loadRegionContext(region)` を呼び出し、取得したバケット名でアップロード。DRY_RUN 時は `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: ctx.parameterCount, artifactPath: ctx.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、同梱の簡易 HTTP サーバで受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:51:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_30\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,120p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:53:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_31\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '120,220p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n   141\\\\t  1. `stage('Initialize')`\\\\n   142\\\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n   143\\\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n   144\\\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n   145\\\\t  2. `stage('Prepare Scripts')`\\\\n   146\\\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n   147\\\\t  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n   148\\\\t     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n   149\\\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n   150\\\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n   151\\\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n   152\\\\t  4. `stage('Finalize Report')`\\\\n   153\\\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n   154\\\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n   155\\\\t- **エラー制御**\\\\n   156\\\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n   157\\\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n   158\\\\t- **メトリクス／ログ**\\\\n   159\\\\t  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n   160\\\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n   161\\\\t\\\\n   162\\\\t### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n   163\\\\t- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n   164\\\\t- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n   165\\\\t- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n   166\\\\t\\\\n   167\\\\t### 7.4 `collect_parameters.sh`\\\\n   168\\\\t- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n   169\\\\t- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n   170\\\\t- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n   171\\\\t\\\\n   172\\\\t### 7.5 テスト設計詳細\\\\n   173\\\\t- **Pulumi (Jest)**  \\\\n   174\\\\t  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n   175\\\\t  - 期待事項:  \\\\n   176\\\\t    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n   177\\\\t    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n   178\\\\t    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n   179\\\\t    - `bucketMap` エクスポートが全リージョンを包含。\\\\n   180\\\\t- **Jenkins (jenkinsfile-runner)**  \\\\n   181\\\\t  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n   182\\\\t  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n   183\\\\t  - 検証点:  \\\\n   184\\\\t    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n   185\\\\t    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n   186\\\\t    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n   187\\\\t- **Manual テスト**  \\\\n   188\\\\t  - `pulumi preview` で各リージョンの差分を確認。  \\\\n   189\\\\t  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n   190\\\\t  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n   191\\\\t  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n   192\\\\t\\\\n   193\\\\t### 7.6 トレーサビリティ\\\\n   194\\\\t| 要件ID | 設計上の対応箇所 |\\\\n   195\\\\t| ------ | ---------------- |\\\\n   196\\\\t| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n   197\\\\t| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n   198\\\\t| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n   199\\\\t| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n   200\\\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n   201\\\\t\\\\n   202\\\\t### 7.7 通知計画 (FR-5)\\\\n   203\\\\t- **対象者**  \\\\n   204\\\\t  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n   205\\\\t  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n   206\\\\t- **チャネル**  \\\\n   207\\\\t  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n   208\\\\t  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n   209\\\\t- **タイミング**  \\\\n   210\\\\t  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n   211\\\\t  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n   212\\\\t  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n   213\\\\t- **責任者**  \\\\n   214\\\\t  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n   215\\\\t  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n   216\\\\t  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n   217\\\\t- **テスト/検証**  \\\\n   218\\\\t  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n   219\\\\t  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n   220\\\\t- **Runbook 更新**  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:57:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_33\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '80,140p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"    80\\\\t- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n    81\\\\t\\\\n    82\\\\t## 6. 変更・追加ファイルリスト\\\\n    83\\\\t| 区分 | ファイル/パス | 目的 |\\\\n    84\\\\t| ---- | ------------- | ---- |\\\\n    85\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n    86\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n    87\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n    88\\\\t| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n    89\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n    90\\\\t| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n    91\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n    92\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n    93\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n    94\\\\t| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n    95\\\\t| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n    96\\\\t\\\\n    97\\\\t## 7. 詳細設計\\\\n    98\\\\t\\\\n    99\\\\t### 7.1 Pulumi (IaC) 詳細\\\\n   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log.md:316:  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/review/agent_log.md:396:タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/review/agent_log.md:494:  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/review/agent_log.md:790:   120\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/02_design/review/agent_log.md:890:   120\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:14:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\\\",\\\"aggregated_output\\\":\\\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n\\\\n## 1. アーキテクチャ設計\\\\n\\\\n### 1.1 システム全体図\\\\n```mermaid\\\\nflowchart TD\\\\n    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    end\\\\n\\\\n    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n        end\\\\n    end\\\\n\\\\n    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    end\\\\n\\\\n    DSL -->|SCM sync| Pipeline\\\\n    Pipeline -->|fetch| Script\\\\n    Pipeline -->|Read config & region list| SSM\\\\n    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    Pipeline --> BucketB\\\\n    Pipeline --> BucketC\\\\n    Pulumi -->|pulumi up| Regions\\\\n    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    Tests --> IaC\\\\n```\\\\n\\\\n### 1.2 コンポーネント間の関係\\\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n\\\\n### 1.3 データフロー\\\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n\\\\n## 2. 実装戦略: EXTEND\\\\n\\\\n**判断根拠**:\\\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニ���トテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:16:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_6\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '60,200p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n\\\\n## 3. テスト戦略: UNIT_INTEGRATION\\\\n\\\\n**判断根拠**:\\\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n\\\\n## 4. テストコード戦略: CREATE_TEST\\\\n\\\\n**判断根拠**:\\\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n\\\\n## 5. 影響範囲分析\\\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:20:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_8\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '120,260p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受���取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n  - 検証点:  \\\\n    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n- **Manual テスト**  \\\\n  - `pulumi preview` で各リージョンの差分を確認。  \\\\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n\\\\n### 7.6 トレーサビリティ\\\\n| 要件ID | 設計上の対応箇所 |\\\\n| ------ | ---------------- |\\\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\\n### 7.7 通知計画 (FR-5)\\\\n- **対象者**  \\\\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\\\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\\\n- **チャネル**  \\\\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\\\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\\\n- **タイミング**  \\\\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\\\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\\\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\\\n- **責任者**  \\\\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\\\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\\\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\\\n- **テスト/検証**  \\\\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\\\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\\\n- **Runbook 更新**  \\\\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\\\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\\\n\\\\n## 8. セキュリティ考慮事項\\\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\\\n\\\\n## 9. 非機能要件への対応\\\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\\\n\\\\n## 10. 実装の順序\\\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\\\n\\\\n---\\\\n\\\\n### 品質ゲート確認\\\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\\\n- ✅ 既存コードへの影響範囲を分析\\\\n- ✅ 必要な変更ファイルをリストアップ\\\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:22:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_9\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '80,180p' .ai-workflow/issue-391/02_design/output/design.md\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n\\\\n## 6. 変更・追加ファイルリスト\\\\n| 区分 | ファイル/パス | 目的 |\\\\n| ---- | ------------- | ---- |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n\\\\n## 7. 詳細設計\\\\n\\\\n### 7.1 Pulumi (IaC) 詳細\\\\n- **Config インターフェース**  \\\\n  ```yaml\\\\n  # Pulumi.<stack>.yaml\\\\n  config:\\\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n    jenkins-ssm-backup-s3:environment: dev\\\\n    jenkins-ssm-backup-s3:regions:\\\\n      - ap-northeast-1\\\\n      - us-west-2\\\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n  ```\\\\n- **主要関数設計**\\\\n  | 関数/スコープ | 役割 |\\\\n  | ------------- | ---- |\\\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n- **命名規則／タグ**  \\\\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n- **プロバイダー管理**  \\\\n  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n- **非同期処理**  \\\\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n- **エクスポート**  \\\\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n\\\\n### 7.2 Jenkins Pipeline 詳細\\\\n- **パイプライン方式**\\\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n- **グローバル変数**\\\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n- **リージョンコンテキスト取得**\\\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n- **ステージ構成**\\\\n  1. `stage('Initialize')`\\\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n  2. `stage('Prepare Scripts')`\\\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n  4. `stage('Finalize Report')`\\\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n- **エラー制御**\\\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n- **メトリクス／ログ**\\\\n  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n\\\\n### 7.4 `collect_parameters.sh`\\\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n\\\\n### 7.5 テスト設計詳細\\\\n- **Pulumi (Jest)**  \\\\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n  - 期待事項:  \\\\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n    - `bucketMap` エクスポートが全リージョンを包含。\\\\n- **Jenkins (jenkinsfile-runner)**  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:26:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_11\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '1,160p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"     1\\\\t# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\\\n     2\\\\t\\\\n     3\\\\t## 1. アーキテクチャ設計\\\\n     4\\\\t\\\\n     5\\\\t### 1.1 システム全体図\\\\n     6\\\\t```mermaid\\\\n     7\\\\tflowchart TD\\\\n     8\\\\t    subgraph Jenkins[\\\\\\\"Jenkins (CI)\\\\\\\"]\\\\n     9\\\\t        DSL[\\\\\\\"Groovy DSL\\\\\\\\nadmin_ssm_backup_job.groovy\\\\\\\"]\\\\n    10\\\\t        Pipeline[\\\\\\\"Scripted Pipeline\\\\\\\\nJenkinsfile\\\\\\\"]\\\\n    11\\\\t        Script[\\\\\\\"collect_parameters.sh\\\\\\\"]\\\\n    12\\\\t    end\\\\n    13\\\\t\\\\n    14\\\\t    subgraph AWS[\\\\\\\"AWS Account\\\\\\\"]\\\\n    15\\\\t        SSM[\\\\\\\"SSM Parameter Store\\\\\\\\n(env-scoped metadata)\\\\\\\"]\\\\n    16\\\\t        subgraph Regions[\\\\\\\"対象リージョン (config-driven)\\\\\\\"]\\\\n    17\\\\t            BucketA[\\\\\\\"S3 Backup Bucket\\\\\\\\n(ap-northeast-1)\\\\\\\"]\\\\n    18\\\\t            BucketB[\\\\\\\"S3 Backup Bucket\\\\\\\\n(us-west-2)\\\\\\\"]\\\\n    19\\\\t            BucketC[\\\\\\\"S3 Backup Bucket\\\\\\\\n(... more)\\\\\\\"]\\\\n    20\\\\t        end\\\\n    21\\\\t    end\\\\n    22\\\\t\\\\n    23\\\\t    subgraph Pulumi[\\\\\\\"Pulumi Stack (TypeScript)\\\\\\\"]\\\\n    24\\\\t        Config[\\\\\\\"Pulumi Config\\\\\\\\n(project/env/regions)\\\\\\\"]\\\\n    25\\\\t        IaC[\\\\\\\"index.ts\\\\\\\\nmulti-region resource factory\\\\\\\"]\\\\n    26\\\\t        Tests[\\\\\\\"Jest-based unit tests\\\\\\\"]\\\\n    27\\\\t    end\\\\n    28\\\\t\\\\n    29\\\\t    DSL -->|SCM sync| Pipeline\\\\n    30\\\\t    Pipeline -->|fetch| Script\\\\n    31\\\\t    Pipeline -->|Read config & region list| SSM\\\\n    32\\\\t    Pipeline -->|Loop regions\\\\\\\\ninvoke AWS CLI| BucketA\\\\n    33\\\\t    Pipeline --> BucketB\\\\n    34\\\\t    Pipeline --> BucketC\\\\n    35\\\\t    Pulumi -->|pulumi up| Regions\\\\n    36\\\\t    Pulumi -->|write bucket metadata\\\\\\\\n& region list| SSM\\\\n    37\\\\t    Tests --> IaC\\\\n    38\\\\t```\\\\n    39\\\\t\\\\n    40\\\\t### 1.2 コンポーネント間の関係\\\\n    41\\\\t- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\\\n    42\\\\t- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\\\n    43\\\\t- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\\\n    44\\\\t- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\\\n    45\\\\t\\\\n    46\\\\t### 1.3 データフロー\\\\n    47\\\\t1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\\\n    48\\\\t2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\\\n    49\\\\t3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\\\n    50\\\\t4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\\\\\"Backup ${region}\\\\\\\")` を生成し、各ステージ内で\\\\n    51\\\\t   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\\\n    52\\\\t   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\\\n    53\\\\t   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\\\n    54\\\\t5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\\\n    55\\\\t\\\\n    56\\\\t## 2. 実装戦略: EXTEND\\\\n    57\\\\t\\\\n    58\\\\t**判断根拠**:\\\\n    59\\\\t- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\\\n    60\\\\t- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n    61\\\\t\\\\n    62\\\\t## 3. テスト戦略: UNIT_INTEGRATION\\\\n    63\\\\t\\\\n    64\\\\t**判断根拠**:\\\\n    65\\\\t- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n    66\\\\t- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n    67\\\\t\\\\n    68\\\\t## 4. テストコード戦略: CREATE_TEST\\\\n    69\\\\t\\\\n    70\\\\t**判断根拠**:\\\\n    71\\\\t- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n    72\\\\t- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n    73\\\\t\\\\n    74\\\\t## 5. 影響範囲分析\\\\n    75\\\\t- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n    76\\\\t- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n    77\\\\t- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n    78\\\\t- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n    79\\\\t- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n    80\\\\t- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n    81\\\\t\\\\n    82\\\\t## 6. 変更・追加ファイルリスト\\\\n    83\\\\t| 区分 | ファイル/パス | 目的 |\\\\n    84\\\\t| ---- | ------------- | ---- |\\\\n    85\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n    86\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n    87\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n    88\\\\t| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n    89\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n    90\\\\t| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n    91\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n    92\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n    93\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n    94\\\\t| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n    95\\\\t| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n    96\\\\t\\\\n    97\\\\t## 7. 詳細設計\\\\n    98\\\\t\\\\n    99\\\\t### 7.1 Pulumi (IaC) 詳細\\\\n   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n   141\\\\t  1. `stage('Initialize')`\\\\n   142\\\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n   143\\\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n   144\\\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n   145\\\\t  2. `stage('Prepare Scripts')`\\\\n   146\\\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n   147\\\\t  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n   148\\\\t     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n   149\\\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n   150\\\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n   151\\\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n   152\\\\t  4. `stage('Finalize Report')`\\\\n   153\\\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n   154\\\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n   155\\\\t- **エラー制御**\\\\n   156\\\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n   157\\\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n   158\\\\t- **メトリクス／ログ**\\\\n   159\\\\t  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n   160\\\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:30:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_13\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '100,200p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n   121\\\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\\\n   122\\\\t- **プロバイダー管理**  \\\\n   123\\\\t  `const provider = new aws.Provider(\\\\\\\\`region-${region}\\\\\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\\\n   124\\\\t- **非同期処理**  \\\\n   125\\\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\\\n   126\\\\t- **エクスポート**  \\\\n   127\\\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\\\n   128\\\\t\\\\n   129\\\\t### 7.2 Jenkins Pipeline 詳細\\\\n   130\\\\t- **パイプライン方式**\\\\n   131\\\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\\\\\"Backup ${region}\\\\\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\\\n   132\\\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\\\n   133\\\\t- **グローバル変数**\\\\n   134\\\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\\\n   135\\\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\\\\\"${env.DATA_DIR}/${region}\\\\\\\"` を付与。\\\\n   136\\\\t- **リージョンコンテキスト取得**\\\\n   137\\\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\\\\\"Bucket definition missing for ${region}\\\\\\\")`。\\\\n   138\\\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\\\n   139\\\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\\\n   140\\\\t- **ステージ構成**\\\\n   141\\\\t  1. `stage('Initialize')`\\\\n   142\\\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\\\n   143\\\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\\\n   144\\\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\\\n   145\\\\t  2. `stage('Prepare Scripts')`\\\\n   146\\\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\\\n   147\\\\t  3. `for (region in regionList) { stage(\\\\\\\"Backup ${region}\\\\\\\") { ... } }`\\\\n   148\\\\t     - `withEnv([\\\\\\\"TARGET_REGION=${region}\\\\\\\", \\\\\\\"AWS_REGION=${region}\\\\\\\", \\\\\\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\\\\\"])` で環境を切り替え。\\\\n   149\\\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\\\\\"[DRY RUN] Skipped upload for ${region}\\\\\\\"` のみ出力。\\\\n   150\\\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\\\n   151\\\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\\\n   152\\\\t  4. `stage('Finalize Report')`\\\\n   153\\\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\\\n   154\\\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\\\n   155\\\\t- **エラー制御**\\\\n   156\\\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\\\n   157\\\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\\\n   158\\\\t- **メトリクス／ログ**\\\\n   159\\\\t  - `collect_parameters.sh` は `summary.json` に `{\\\\\\\"parameterCount\\\\\\\": 123, \\\\\\\"executionTimeSec\\\\\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\\\n   160\\\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\\\n   161\\\\t\\\\n   162\\\\t### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\\\n   163\\\\t- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\\\n   164\\\\t- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\\\n   165\\\\t- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\\\n   166\\\\t\\\\n   167\\\\t### 7.4 `collect_parameters.sh`\\\\n   168\\\\t- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\\\n   169\\\\t- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\\\n   170\\\\t- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\\\n   171\\\\t\\\\n   172\\\\t### 7.5 テスト設計詳細\\\\n   173\\\\t- **Pulumi (Jest)**  \\\\n   174\\\\t  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\\\\\"ap-northeast-1\\\\\\\", \\\\\\\"us-west-2\\\\\\\"]` を与えて `require(\\\\\\\"../index\\\\\\\")`。  \\\\n   175\\\\t  - 期待事項:  \\\\n   176\\\\t    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\\\n   177\\\\t    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\\\n   178\\\\t    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\\\n   179\\\\t    - `bucketMap` エクスポートが全リージョンを包含。\\\\n   180\\\\t- **Jenkins (jenkinsfile-runner)**  \\\\n   181\\\\t  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\\\n   182\\\\t  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\\\n   183\\\\t  - 検証点:  \\\\n   184\\\\t    - Scripted Pipeline がリージョン配列から `stage(\\\\\\\"Backup ${region}\\\\\\\")` を順次生成する。  \\\\n   185\\\\t    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\\\n   186\\\\t    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\\\n   187\\\\t- **Manual テスト**  \\\\n   188\\\\t  - `pulumi preview` で各リージョンの差分を確認。  \\\\n   189\\\\t  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\\\n   190\\\\t  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\\\n   191\\\\t  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\\\n   192\\\\t\\\\n   193\\\\t### 7.6 トレーサビリティ\\\\n   194\\\\t| 要件ID | 設計上の対応箇所 |\\\\n   195\\\\t| ------ | ---------------- |\\\\n   196\\\\t| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\\\n   197\\\\t| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\\\n   198\\\\t| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\\\n   199\\\\t| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\\\n   200\\\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:32:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_14\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '60,120p'\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"    60\\\\t- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\\\n    61\\\\t\\\\n    62\\\\t## 3. テスト戦略: UNIT_INTEGRATION\\\\n    63\\\\t\\\\n    64\\\\t**判断根拠**:\\\\n    65\\\\t- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\\\n    66\\\\t- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\\\n    67\\\\t\\\\n    68\\\\t## 4. テストコード戦略: CREATE_TEST\\\\n    69\\\\t\\\\n    70\\\\t**判断根拠**:\\\\n    71\\\\t- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\\\n    72\\\\t- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\\\n    73\\\\t\\\\n    74\\\\t## 5. 影響範囲分析\\\\n    75\\\\t- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\\\n    76\\\\t- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\\\n    77\\\\t- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\\\n    78\\\\t- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\\\n    79\\\\t- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\\\n    80\\\\t- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\\\n    81\\\\t\\\\n    82\\\\t## 6. 変更・追加ファイルリスト\\\\n    83\\\\t| 区分 | ファイル/パス | 目的 |\\\\n    84\\\\t| ---- | ------------- | ---- |\\\\n    85\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\\\n    86\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\\\n    87\\\\t| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\\\n    88\\\\t| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\\\n    89\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\\\n    90\\\\t| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\\\n    91\\\\t| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\\\n    92\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\\\n    93\\\\t| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\\\n    94\\\\t| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\\\n    95\\\\t| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\\\n    96\\\\t\\\\n    97\\\\t## 7. 詳細設計\\\\n    98\\\\t\\\\n    99\\\\t### 7.1 Pulumi (IaC) 詳細\\\\n   100\\\\t- **Config インターフェース**  \\\\n   101\\\\t  ```yaml\\\\n   102\\\\t  # Pulumi.<stack>.yaml\\\\n   103\\\\t  config:\\\\n   104\\\\t    jenkins-ssm-backup-s3:projectName: jenkins-infra\\\\n   105\\\\t    jenkins-ssm-backup-s3:environment: dev\\\\n   106\\\\t    jenkins-ssm-backup-s3:regions:\\\\n   107\\\\t      - ap-northeast-1\\\\n   108\\\\t      - us-west-2\\\\n   109\\\\t    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\\\n   110\\\\t    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\\\n   111\\\\t  ```\\\\n   112\\\\t- **主要関数設計**\\\\n   113\\\\t  | 関数/スコープ | 役割 |\\\\n   114\\\\t  | ------------- | ---- |\\\\n   115\\\\t  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\\\n   116\\\\t  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\\\n   117\\\\t  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\\\n   118\\\\t- **命名規則／タグ**  \\\\n   119\\\\t  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\\\n   120\\\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/execute/agent_log.md:264:        Purpose: \\\"SSM Parameter Store Backup Storage\\\",\\n.ai-workflow/issue-391/02_design/execute/agent_log.md:344: * SSM Parameter Store Backup Pipeline\\n.ai-workflow/issue-391/02_design/execute/agent_log.md:386:                    SSM Parameter Store Backup\\n.ai-workflow/issue-391/02_design/execute/agent_log.md:504:                SSM Parameter Store Backup Summary\\n.ai-workflow/issue-391/02_design/execute/agent_log_raw.txt:10:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/execute/agent_log_raw.txt:12:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"@Library('jenkins-shared-lib') _\\\\n\\\\n/**\\\\n * SSM Parameter Store Backup Pipeline\\\\n * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\\\\n */\\\\npipeline {\\\\n    agent {\\\\n        label 'ec2-fleet'\\\\n    }\\\\n    \\\\n    options {\\\\n        timestamps()\\\\n        timeout(time: 1, unit: 'HOURS')\\\\n        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\\\\n        disableConcurrentBuilds()\\\\n    }\\\\n    \\\\n    environment {\\\\n        // AWS設定\\\\n        AWS_REGION = 'ap-northeast-1'\\\\n        \\\\n        // タイムスタンプ\\\\n        BACKUP_DATE = sh(script: \\\\\\\"date '+%Y-%m-%d'\\\\\\\", returnStdout: true).trim()\\\\n        BACKUP_TIMESTAMP = sh(script: \\\\\\\"date '+%Y%m%d_%H%M%S'\\\\\\\", returnStdout: true).trim()\\\\n        \\\\n        // ディレクトリ構造\\\\n        WORK_DIR = \\\\\\\"${WORKSPACE}/backup-work\\\\\\\"\\\\n        DATA_DIR = \\\\\\\"${WORK_DIR}/data\\\\\\\"\\\\n        SCRIPT_DIR = \\\\\\\"${WORKSPACE}/scripts\\\\\\\"\\\\n        \\\\n        // 環境フィルタ（環境に含まれる文字列）\\\\n        ENV_FILTER = \\\\\\\"/${params.ENVIRONMENT}/\\\\\\\"\\\\n    }\\\\n    \\\\n    stages {\\\\n        stage('Initialize') {\\\\n            steps {\\\\n                script {\\\\n                    // ビルド表示名を設定\\\\n                    currentBuild.displayName = \\\\\\\"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\\\\\\\"\\\\n                    currentBuild.description = \\\\\\\"Backup at ${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    SSM Parameter Store Backup\\\\n                    =============================================\\\\n                    Environment: ${params.ENVIRONMENT}\\\\n                    Filter: Parameters containing '${env.ENV_FILTER}'\\\\n                    Dry Run: ${params.DRY_RUN}\\\\n                    Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                    Date: ${env.BACKUP_DATE}\\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // 作業ディレクトリの準備\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        rm -rf ${WORK_DIR}\\\\n                        mkdir -p ${DATA_DIR}\\\\n                        mkdir -p ${SCRIPT_DIR}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // S3バケット名の取得\\\\n                    env.BACKUP_BUCKET = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws ssm get-parameter \\\\\\\\\\\\n                                --name \\\\\\\"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\\\\\\\" \\\\\\\\\\\\n                                --query 'Parameter.Value' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION} 2>/dev/null || echo \\\\\\\"\\\\\\\"\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    if (!env.BACKUP_BUCKET) {\\\\n                        error(\\\\\\\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\\\\\\\")\\\\n                    }\\\\n                    \\\\n                    echo \\\\\\\"Backup S3 Bucket: ${env.BACKUP_BUCKET}\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Prepare Scripts') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Preparing Collection Scripts ===\\\\\\\"\\\\n                    \\\\n                    // Jenkinsリポジトリをチェックアウト\\\\n                    dir('jenkins-repo') {\\\\n                        checkout([\\\\n                            $class: 'GitSCM',\\\\n                            branches: [[name: \\\\\\\"${params.JENKINSFILE_BRANCH}\\\\\\\"]],\\\\n                            userRemoteConfigs: [[\\\\n                                url: 'https://github.com/tielec/infrastructure-as-code',\\\\n                                credentialsId: 'github-app-credentials'\\\\n                            ]]\\\\n                        ])\\\\n                    }\\\\n                    \\\\n                    // スクリプトをコピー\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\\\\n                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\\\\n                        \\\\n                        echo \\\\\\\"Script copied and made executable\\\\\\\"\\\\n                        ls -la ${SCRIPT_DIR}/\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Collect Parameters') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Collecting SSM Parameters ===\\\\\\\"\\\\n                    \\\\n                    // スクリプトの実行\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        # 環境変数を設定\\\\n                        export ENVIRONMENT=\\\\\\\"${params.ENVIRONMENT}\\\\\\\"\\\\n                        export ENV_FILTER=\\\\\\\"${env.ENV_FILTER}\\\\\\\"\\\\n                        export AWS_REGION=\\\\\\\"${AWS_REGION}\\\\\\\"\\\\n                        export BACKUP_DATE=\\\\\\\"${env.BACKUP_DATE}\\\\\\\"\\\\n                        export BACKUP_TIMESTAMP=\\\\\\\"${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                        export DATA_DIR=\\\\\\\"${DATA_DIR}\\\\\\\"\\\\n                        \\\\n                        # スクリプト実行\\\\n                        ${SCRIPT_DIR}/collect_parameters.sh\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの確認\\\\n                    if (fileExists(\\\\\\\"${DATA_DIR}/backup.json\\\\\\\")) {\\\\n                        def backupData = readJSON file: \\\\\\\"${DATA_DIR}/backup.json\\\\\\\"\\\\n                        env.PARAM_COUNT = backupData.parameter_count.toString()\\\\n                        \\\\n                        if (backupData.parameter_count == 0) {\\\\n                            echo \\\\\\\"WARNING: No parameters found for backup\\\\\\\"\\\\n                            currentBuild.result = 'UNSTABLE'\\\\n                        } else {\\\\n                            echo \\\\\\\"Backup file contains ${backupData.parameter_count} parameters\\\\\\\"\\\\n                        }\\\\n                    } else {\\\\n                        error(\\\\\\\"Backup file was not created\\\\\\\")\\\\n                    }\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Upload to S3') {\\\\n            when {\\\\n                expression { \\\\n                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\\\\n                }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Uploading Backup to S3 ===\\\\\\\"\\\\n                    \\\\n                    def backupFileName = \\\\\\\"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\\\\"\\\\n                    def s3Key = \\\\\\\"${env.BACKUP_DATE}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの名前を変更\\\\n                    sh \\\\\\\"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // S3へアップロード（暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\\\\\\\\\\n                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\\\\\\\"\\\\n                    \\\\n                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        echo '${s3Key}' | \\\\\\\\\\\\n                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // アップロード確認\\\\n                    def s3ObjectInfo = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws s3api head-object \\\\\\\\\\\\n                                --bucket ${env.BACKUP_BUCKET} \\\\\\\\\\\\n                                --key ${s3Key} \\\\\\\\\\\\n                                --query '[ContentLength, LastModified]' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION}\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    echo \\\\\\\"S3 Object Info: ${s3ObjectInfo}\\\\\\\"\\\\n                    \\\\n                    // セキュリティ上の理由によりアーティファクトとしては保存しない\\\\n                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/execute/agent_log_raw.txt:14:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_5\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '200,400p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Dry Run Report') {\\\\n            when {\\\\n                expression { params.DRY_RUN }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    def paramCount = env.PARAM_COUNT ?: '0'\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    DRY RUN - バックアップ実行レポート\\\\n                    =============================================\\\\n                    \\\\n                    このドライランでは実際のS3アップロードは行われませんでした。\\\\n                    \\\\n                    バックアップ対象:\\\\n                    - 環境: ${params.ENVIRONMENT}\\\\n                    - パラメータ数: ${paramCount}\\\\n                    - バックアップ日時: ${env.BACKUP_TIMESTAMP}\\\\n                    \\\\n                    実行時の動作:\\\\n                    - S3バケット: ${env.BACKUP_BUCKET}\\\\n                    - S3パス: ${env.BACKUP_DATE}/\\\\n                    - ファイル名: ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\n                    \\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // セキュリティ上の理由によりドライラン時もアーティファクトとして保存しない\\\\n                }\\\\n            }\\\\n        }\\\\n    }\\\\n    \\\\n    post {\\\\n        always {\\\\n            script {\\\\n                def paramCount = env.PARAM_COUNT ?: '0'\\\\n                \\\\n                // 実行サマリーの表示\\\\n                echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                =============================================\\\\n                SSM Parameter Store Backup Summary\\\\n                =============================================\\\\n                Build: #${env.BUILD_NUMBER}\\\\n                Status: ${currentBuild.result ?: 'SUCCESS'}\\\\n                Environment: ${params.ENVIRONMENT}\\\\n                Parameters: ${paramCount}\\\\n                Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                Dry Run: ${params.DRY_RUN}\\\\n                =============================================\\\\n                \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n            }\\\\n        }\\\\n        \\\\n        success {\\\\n            echo \\\\\\\"✅ SSMパラメータのバックアップが正常に完了しました\\\\\\\"\\\\n        }\\\\n        \\\\n        failure {\\\\n            echo \\\\\\\"❌ バックアップが失敗しました。ログを確認してください\\\\\\\"\\\\n        }\\\\n        \\\\n        unstable {\\\\n            echo \\\\\\\"⚠️ バックアップは完了しましたが、警告があります\\\\\\\"\\\\n        }\\\\n        \\\\n        cleanup {\\\\n            // 作業ディレクトリのクリーンアップ\\\\n            sh \\\\\\\"rm -rf ${WORK_DIR} ${SCRIPT_DIR} jenkins-repo || true\\\\\\\"\\\\n        }\\\\n    }\\\\n}\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/02_design/output/design.md:120:  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n.ai-workflow/issue-391/00_planning/execute/agent_log.md:81:        Purpose: \\\"SSM Parameter Store Backup Storage\\\",\\n.ai-workflow/issue-391/00_planning/execute/agent_log.md:241: * SSM Parameter Store Backup Pipeline\\n.ai-workflow/issue-391/00_planning/execute/agent_log.md:283:                    SSM Parameter Store Backup\\n.ai-workflow/issue-391/00_planning/execute/agent_log.md:401:                SSM Parameter Store Backup Summary\\n.ai-workflow/issue-391/00_planning/execute/agent_log_raw.txt:6:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_1\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,160p' pulumi/jenkins-ssm-backup-s3/index.ts\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"import * as pulumi from \\\\\\\"@pulumi/pulumi\\\\\\\";\\\\nimport * as aws from \\\\\\\"@pulumi/aws\\\\\\\";\\\\n\\\\n// 設定値の取得\\\\nconst config = new pulumi.Config();\\\\nconst projectName = config.require(\\\\\\\"projectName\\\\\\\");\\\\nconst environment = config.require(\\\\\\\"environment\\\\\\\");\\\\n\\\\n// AWSアカウント情報とリージョンを取得\\\\nconst accountId = aws.getCallerIdentity().then(identity => identity.accountId);\\\\nconst region = aws.config.region || \\\\\\\"ap-northeast-1\\\\\\\";\\\\n\\\\n// S3バケット名の生成（アカウント番号とリージョンを含めて一意性を確保）\\\\nconst bucketName = pulumi.interpolate`${projectName}-ssm-backup-${environment}-${accountId}-${region}`;\\\\n\\\\n// SSMパラメータバックアップ用S3バケット\\\\nconst backupBucket = new aws.s3.Bucket(\\\\\\\"ssm-backup-bucket\\\\\\\", {\\\\n    bucket: bucketName,\\\\n    versioning: {\\\\n        enabled: true,\\\\n    },\\\\n    serverSideEncryptionConfiguration: {\\\\n        rule: {\\\\n            applyServerSideEncryptionByDefault: {\\\\n                sseAlgorithm: \\\\\\\"AES256\\\\\\\",\\\\n            },\\\\n            bucketKeyEnabled: true,  // S3 Bucket Keysを有効化（暗号化コストを削減）\\\\n        },\\\\n    },\\\\n    lifecycleRules: [{\\\\n        id: \\\\\\\"delete-old-backups\\\\\\\",\\\\n        enabled: true,\\\\n        expiration: {\\\\n            days: 30,  // 30日間保持\\\\n        },\\\\n        noncurrentVersionExpiration: {\\\\n            days: 7,  // 非現行バージョンは7日間保持\\\\n        },\\\\n    }],\\\\n    objectLockEnabled: false,  // 必要に応じてObject Lockを有効化可能\\\\n    tags: {\\\\n        Name: bucketName,\\\\n        Environment: environment,\\\\n        Purpose: \\\\\\\"SSM Parameter Store Backup Storage\\\\\\\",\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n        DataClassification: \\\\\\\"Confidential\\\\\\\",  // データ分類を明示\\\\n    },\\\\n});\\\\n\\\\n// バケットのパブリックアクセスブロック設定\\\\nconst bucketPublicAccessBlock = new aws.s3.BucketPublicAccessBlock(\\\\\\\"ssm-backup-bucket-pab\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    blockPublicAcls: true,\\\\n    blockPublicPolicy: true,\\\\n    ignorePublicAcls: true,\\\\n    restrictPublicBuckets: true,\\\\n});\\\\n\\\\n// バケットポリシー：HTTPS通信の強制とIP制限（オプション）\\\\nconst bucketPolicy = new aws.s3.BucketPolicy(\\\\\\\"ssm-backup-bucket-policy\\\\\\\", {\\\\n    bucket: backupBucket.id,\\\\n    policy: pulumi.all([backupBucket.arn]).apply(([bucketArn]) => JSON.stringify({\\\\n        Version: \\\\\\\"2012-10-17\\\\\\\",\\\\n        Statement: [\\\\n            {\\\\n                Sid: \\\\\\\"DenyInsecureConnections\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:*\\\\\\\",\\\\n                Resource: [\\\\n                    bucketArn,\\\\n                    `${bucketArn}/*`,\\\\n                ],\\\\n                Condition: {\\\\n                    Bool: {\\\\n                        \\\\\\\"aws:SecureTransport\\\\\\\": \\\\\\\"false\\\\\\\"\\\\n                    }\\\\n                }\\\\n            },\\\\n            {\\\\n                Sid: \\\\\\\"DenyUnencryptedObjectUploads\\\\\\\",\\\\n                Effect: \\\\\\\"Deny\\\\\\\",\\\\n                Principal: \\\\\\\"*\\\\\\\",\\\\n                Action: \\\\\\\"s3:PutObject\\\\\\\",\\\\n                Resource: `${bucketArn}/*`,\\\\n                Condition: {\\\\n                    StringNotEquals: {\\\\n                        \\\\\\\"s3:x-amz-server-side-encryption\\\\\\\": \\\\\\\"AES256\\\\\\\"\\\\n                    }\\\\n                }\\\\n            }\\\\n        ]\\\\n    })),\\\\n});\\\\n\\\\n// SSMパラメータストアにバケット名を保存\\\\nconst ssmBackupBucketName = new aws.ssm.Parameter(\\\\\\\"ssm-backup-bucket-name\\\\\\\", {\\\\n    name: `/jenkins/${environment}/backup/s3-bucket-name`,\\\\n    type: \\\\\\\"String\\\\\\\",\\\\n    value: backupBucket.bucket,\\\\n    description: \\\\\\\"SSM Parameter Store backup S3 bucket name\\\\\\\",\\\\n    tags: {\\\\n        Environment: environment,\\\\n        ManagedBy: \\\\\\\"Pulumi\\\\\\\",\\\\n    },\\\\n});\\\\n\\\\n// エクスポート\\\\nexport const bucketNameOutput = backupBucket.bucket;\\\\nexport const bucketArn = backupBucket.arn;\\\\nexport const ssmBackupBucketParameter = ssmBackupBucketName.name;\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/00_planning/execute/agent_log_raw.txt:10:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_3\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '1,200p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"@Library('jenkins-shared-lib') _\\\\n\\\\n/**\\\\n * SSM Parameter Store Backup Pipeline\\\\n * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\\\\n */\\\\npipeline {\\\\n    agent {\\\\n        label 'ec2-fleet'\\\\n    }\\\\n    \\\\n    options {\\\\n        timestamps()\\\\n        timeout(time: 1, unit: 'HOURS')\\\\n        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\\\\n        disableConcurrentBuilds()\\\\n    }\\\\n    \\\\n    environment {\\\\n        // AWS設定\\\\n        AWS_REGION = 'ap-northeast-1'\\\\n        \\\\n        // タイムスタンプ\\\\n        BACKUP_DATE = sh(script: \\\\\\\"date '+%Y-%m-%d'\\\\\\\", returnStdout: true).trim()\\\\n        BACKUP_TIMESTAMP = sh(script: \\\\\\\"date '+%Y%m%d_%H%M%S'\\\\\\\", returnStdout: true).trim()\\\\n        \\\\n        // ディレクトリ構造\\\\n        WORK_DIR = \\\\\\\"${WORKSPACE}/backup-work\\\\\\\"\\\\n        DATA_DIR = \\\\\\\"${WORK_DIR}/data\\\\\\\"\\\\n        SCRIPT_DIR = \\\\\\\"${WORKSPACE}/scripts\\\\\\\"\\\\n        \\\\n        // 環境フィルタ（環境に含まれる文字列）\\\\n        ENV_FILTER = \\\\\\\"/${params.ENVIRONMENT}/\\\\\\\"\\\\n    }\\\\n    \\\\n    stages {\\\\n        stage('Initialize') {\\\\n            steps {\\\\n                script {\\\\n                    // ビルド表示名を設定\\\\n                    currentBuild.displayName = \\\\\\\"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\\\\\\\"\\\\n                    currentBuild.description = \\\\\\\"Backup at ${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    SSM Parameter Store Backup\\\\n                    =============================================\\\\n                    Environment: ${params.ENVIRONMENT}\\\\n                    Filter: Parameters containing '${env.ENV_FILTER}'\\\\n                    Dry Run: ${params.DRY_RUN}\\\\n                    Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                    Date: ${env.BACKUP_DATE}\\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // 作業ディレクトリの準備\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        rm -rf ${WORK_DIR}\\\\n                        mkdir -p ${DATA_DIR}\\\\n                        mkdir -p ${SCRIPT_DIR}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // S3バケット名の取得\\\\n                    env.BACKUP_BUCKET = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws ssm get-parameter \\\\\\\\\\\\n                                --name \\\\\\\"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\\\\\\\" \\\\\\\\\\\\n                                --query 'Parameter.Value' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION} 2>/dev/null || echo \\\\\\\"\\\\\\\"\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    if (!env.BACKUP_BUCKET) {\\\\n                        error(\\\\\\\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\\\\\\\")\\\\n                    }\\\\n                    \\\\n                    echo \\\\\\\"Backup S3 Bucket: ${env.BACKUP_BUCKET}\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Prepare Scripts') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Preparing Collection Scripts ===\\\\\\\"\\\\n                    \\\\n                    // Jenkinsリポジトリをチェックアウト\\\\n                    dir('jenkins-repo') {\\\\n                        checkout([\\\\n                            $class: 'GitSCM',\\\\n                            branches: [[name: \\\\\\\"${params.JENKINSFILE_BRANCH}\\\\\\\"]],\\\\n                            userRemoteConfigs: [[\\\\n                                url: 'https://github.com/tielec/infrastructure-as-code',\\\\n                                credentialsId: 'github-app-credentials'\\\\n                            ]]\\\\n                        ])\\\\n                    }\\\\n                    \\\\n                    // スクリプトをコピー\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\\\\n                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\\\\n                        \\\\n                        echo \\\\\\\"Script copied and made executable\\\\\\\"\\\\n                        ls -la ${SCRIPT_DIR}/\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Collect Parameters') {\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Collecting SSM Parameters ===\\\\\\\"\\\\n                    \\\\n                    // スクリプトの実行\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        # 環境変数を設定\\\\n                        export ENVIRONMENT=\\\\\\\"${params.ENVIRONMENT}\\\\\\\"\\\\n                        export ENV_FILTER=\\\\\\\"${env.ENV_FILTER}\\\\\\\"\\\\n                        export AWS_REGION=\\\\\\\"${AWS_REGION}\\\\\\\"\\\\n                        export BACKUP_DATE=\\\\\\\"${env.BACKUP_DATE}\\\\\\\"\\\\n                        export BACKUP_TIMESTAMP=\\\\\\\"${env.BACKUP_TIMESTAMP}\\\\\\\"\\\\n                        export DATA_DIR=\\\\\\\"${DATA_DIR}\\\\\\\"\\\\n                        \\\\n                        # スクリプト実行\\\\n                        ${SCRIPT_DIR}/collect_parameters.sh\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの確認\\\\n                    if (fileExists(\\\\\\\"${DATA_DIR}/backup.json\\\\\\\")) {\\\\n                        def backupData = readJSON file: \\\\\\\"${DATA_DIR}/backup.json\\\\\\\"\\\\n                        env.PARAM_COUNT = backupData.parameter_count.toString()\\\\n                        \\\\n                        if (backupData.parameter_count == 0) {\\\\n                            echo \\\\\\\"WARNING: No parameters found for backup\\\\\\\"\\\\n                            currentBuild.result = 'UNSTABLE'\\\\n                        } else {\\\\n                            echo \\\\\\\"Backup file contains ${backupData.parameter_count} parameters\\\\\\\"\\\\n                        }\\\\n                    } else {\\\\n                        error(\\\\\\\"Backup file was not created\\\\\\\")\\\\n                    }\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Upload to S3') {\\\\n            when {\\\\n                expression { \\\\n                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\\\\n                }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    echo \\\\\\\"=== Uploading Backup to S3 ===\\\\\\\"\\\\n                    \\\\n                    def backupFileName = \\\\\\\"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\\\\"\\\\n                    def s3Key = \\\\\\\"${env.BACKUP_DATE}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // バックアップファイルの名前を変更\\\\n                    sh \\\\\\\"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\\\\\\\"\\\\n                    \\\\n                    // S3へアップロード（暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\\\\\\\\\\n                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    echo \\\\\\\"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\\\\\\\"\\\\n                    \\\\n                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\\\\n                    sh \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        echo '${s3Key}' | \\\\\\\\\\\\n                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\\\\\\\\\\n                            --sse AES256 \\\\\\\\\\\\n                            --region ${AWS_REGION}\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    \\\\n                    // アップロード確認\\\\n                    def s3ObjectInfo = sh(\\\\n                        script: \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            aws s3api head-object \\\\\\\\\\\\n                                --bucket ${env.BACKUP_BUCKET} \\\\\\\\\\\\n                                --key ${s3Key} \\\\\\\\\\\\n                                --query '[ContentLength, LastModified]' \\\\\\\\\\\\n                                --output text \\\\\\\\\\\\n                                --region ${AWS_REGION}\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                        returnStdout: true\\\\n                    ).trim()\\\\n                    \\\\n                    echo \\\\\\\"S3 Object Info: ${s3ObjectInfo}\\\\\\\"\\\\n                    \\\\n                    // セキュリティ上の理由によりアーティファクトとしては保存しない\\\\n                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n.ai-workflow/issue-391/00_planning/execute/agent_log_raw.txt:12:{\\\"type\\\":\\\"item.completed\\\",\\\"item\\\":{\\\"id\\\":\\\"item_4\\\",\\\"type\\\":\\\"command_execution\\\",\\\"command\\\":\\\"bash -lc \\\\\\\"sed -n '200,400p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\\\\\\\"\\\",\\\"aggregated_output\\\":\\\"                    // バックアップファイルは暗号化されたS3バケットでのみ管理\\\\n                }\\\\n            }\\\\n        }\\\\n        \\\\n        stage('Dry Run Report') {\\\\n            when {\\\\n                expression { params.DRY_RUN }\\\\n            }\\\\n            steps {\\\\n                script {\\\\n                    def paramCount = env.PARAM_COUNT ?: '0'\\\\n                    \\\\n                    echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    =============================================\\\\n                    DRY RUN - バックアップ実行レポート\\\\n                    =============================================\\\\n                    \\\\n                    このドライランでは実際のS3アップロードは行われませんでした。\\\\n                    \\\\n                    バックアップ対象:\\\\n                    - 環境: ${params.ENVIRONMENT}\\\\n                    - パラメータ数: ${paramCount}\\\\n                    - バックアップ日時: ${env.BACKUP_TIMESTAMP}\\\\n                    \\\\n                    実行時の動作:\\\\n                    - S3バケット: ${env.BACKUP_BUCKET}\\\\n                    - S3パス: ${env.BACKUP_DATE}/\\\\n                    - ファイル名: ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\\\\n                    \\\\n                    =============================================\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n                    \\\\n                    // セキュリティ上の理由によりドライラン時もアーティファクトとして保存しない\\\\n                }\\\\n            }\\\\n        }\\\\n    }\\\\n    \\\\n    post {\\\\n        always {\\\\n            script {\\\\n                def paramCount = env.PARAM_COUNT ?: '0'\\\\n                \\\\n                // 実行サマリーの表示\\\\n                echo \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                =============================================\\\\n                SSM Parameter Store Backup Summary\\\\n                =============================================\\\\n                Build: #${env.BUILD_NUMBER}\\\\n                Status: ${currentBuild.result ?: 'SUCCESS'}\\\\n                Environment: ${params.ENVIRONMENT}\\\\n                Parameters: ${paramCount}\\\\n                Timestamp: ${env.BACKUP_TIMESTAMP}\\\\n                Dry Run: ${params.DRY_RUN}\\\\n                =============================================\\\\n                \\\\\\\"\\\\\\\"\\\\\\\".stripIndent()\\\\n            }\\\\n        }\\\\n        \\\\n        success {\\\\n            echo \\\\\\\"✅ SSMパラメータのバックアップが正常に完了しました\\\\\\\"\\\\n        }\\\\n        \\\\n        failure {\\\\n            echo \\\\\\\"❌ バックアップが失敗しました。ログを確認してください\\\\\\\"\\\\n        }\\\\n        \\\\n        unstable {\\\\n            echo \\\\\\\"⚠️ バックアップは完了しましたが、警告があります\\\\\\\"\\\\n        }\\\\n        \\\\n        cleanup {\\\\n            // 作業ディレクトリのクリーンアップ\\\\n            sh \\\\\\\"rm -rf ${WORK_DIR} ${SCRIPT_DIR} jenkins-repo || true\\\\\\\"\\\\n        }\\\\n    }\\\\n}\\\",\\\"exit_code\\\":0,\\\"status\\\":\\\"completed\\\"}}\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/04_implementation/execute/agent_log_raw.txt:127:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_66\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"nl -ba docs/runbooks/ssm-backup.md | sed -n '1,200p'\\\"\",\"aggregated_output\":\"     1\\t# SSM Parameter Store Backup Runbook\\n     2\\t\\n     3\\t## 概要\\n     4\\t- 対象ジョブ: `Admin_Jobs/admin_ssm_backup_job`\\n     5\\t- 目的: Pulumi が生成した各リージョンの S3 バケットへ、SSM Parameter Store の内容を暗号化した JSON として日次バックアップする。\\n     6\\t- リージョン構成: Pulumi Config (`pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml`) の `regions` 配列に従い動的に決定。\\n     7\\t- メタデータ保管: `/jenkins/<env>/backup/` プレフィックスの SSM パラメータ（`region-list`, `default-region`, `s3-bucket-name`, `<region>/s3-bucket-name`）。\\n     8\\t\\n     9\\t## 運用手順\\n    10\\t1. Jenkins ジョブが自動実行（毎日 JST 22:00）。開始時に `Initialize` ステージでリージョン一覧とデフォルトリージョンを SSM から取得。\\n    11\\t2. `Backup <region>` ステージがリージョンごとに逐次実行され、`collect_parameters.sh` を用いて SSM パラメータを収集。\\n    12\\t3. 取得した JSON は `s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json` にアップロードされ、`latest-<region>.txt`（デフォルトリージョンは互換用に `latest.txt` も更新）を発行。\\n    13\\t4. 実行結果は `backup-work/region_summaries.json` に出力され、アーティファクトとして保存。Slack/メール通知には同ファイルの要約を添付。\\n    14\\t\\n    15\\t## リージョン追加・削除手順\\n    16\\t1. `pulumi/jenkins-ssm-backup-s3/Pulumi.<env>.yaml` の `regions` 配列を更新し、`defaultRegion` と `ssmHomeRegion` を必要に応じて調整。\\n    17\\t2. Pulumi スタックディレクトリで `npm install`（依存未導入時）後、`npm run build` → `pulumi preview` を実施し差分を確認。\\n    18\\t3. 変更内容をレビュー後、`pulumi up` を本番／ステージング順に適用。\\n    19\\t4. Jenkins ジョブをドライラン（`DRY_RUN=true`）で実行し、`Backup <region>` ステージが追加リージョンを認識することを確認。\\n    20\\t5. 運用チームへ Slack `#infra-announcements` でリージョン変更点と実施日時を共有。\\n    21\\t\\n    22\\t## ロールバック手順\\n    23\\t1. Pulumi Config を直前のコミットへ戻し `pulumi up` を実行。不要になった S3 バケットと SSM パラメータが削除されることを `pulumi preview` で確認。\\n    24\\t2. Jenkins ジョブを手動実行し、`region_summaries.json` に旧構成のみが記録されることを確認。\\n    25\\t3. 影響が大きい場合は Runbook の通知テンプレートを利用し、CLI 利用者とオンコール SRE へ速やかに連絡。\\n    26\\t\\n    27\\t## 監視・通知\\n    28\\t- 成功時: Slack `#infra-backup-alerts` にリージョン別件数・処理時間を通知。メール `ops-alerts@example.com` に同内容のサマリーを送付。\\n    29\\t- 失敗時: 失敗リージョンの `message` が通知ペイロードに含まれる。30 分以内に一次報告、復旧後 1 営業日以内に事後報告を行う。\\n    30\\t- 参照ログ: Jenkins 実行ログ・`backup-work/region_summaries.json`・S3 バケットの `latest-<region>.txt`。\\n    31\\t\\n    32\\t## トラブルシューティング\\n    33\\t| 症状 | 対処 |\\n    34\\t| ---- | ---- |\\n    35\\t| `Region list parameter ... is missing` | Pulumi スタックが未適用。`pulumi config get regions` と SSM の `/backup/region-list` を確認。 |\\n    36\\t| `Bucket definition missing for region` | `/backup/<region>/s3-bucket-name` の作成漏れ。Pulumi Config のリージョン一覧と SSM を照合。 |\\n    37\\t| `Backup file was not created` | `collect_parameters.sh` の AWS 認証／フィルタ設定を確認。`DATA_DIR/<region>` に生成物があるか検証。 |\\n    38\\t| S3 アップロードに失敗 | `aws s3 cp` コマンドのエラー詳細をログで確認。IAM 権限またはリージョン設定を見直し。 |\\n    39\\t\\n    40\\t## 参考コマンド\\n    41\\t```bash\\n    42\\t# Pulumi Stack でリージョンを確認\\n    43\\tpulumi config get regions --path --stack <env>\\n    44\\t\\n    45\\t# Jenkins アーティファクトからサマリーを取得\\n    46\\taws s3 cp s3://<bucket>/<YYYY-MM-DD>/<region>/ssm-backup-<env>-<region>-<timestamp>.json ./\\n    47\\t```\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/03_test_scenario/execute/agent_log.md:516:  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \n.ai-workflow/issue-391/03_test_scenario/execute/agent_log_raw.txt:12:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_4\",\"type\":\"command_execution\",\"command\":\"bash -lc 'cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && cat .ai-workflow/issue-391/02_design/output/design.md'\",\"aggregated_output\":\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体図\\n```mermaid\\nflowchart TD\\n    subgraph Jenkins[\\\"Jenkins (CI)\\\"]\\n        DSL[\\\"Groovy DSL\\\\nadmin_ssm_backup_job.groovy\\\"]\\n        Pipeline[\\\"Scripted Pipeline\\\\nJenkinsfile\\\"]\\n        Script[\\\"collect_parameters.sh\\\"]\\n    end\\n\\n    subgraph AWS[\\\"AWS Account\\\"]\\n        SSM[\\\"SSM Parameter Store\\\\n(env-scoped metadata)\\\"]\\n        subgraph Regions[\\\"対象リージョン (config-driven)\\\"]\\n            BucketA[\\\"S3 Backup Bucket\\\\n(ap-northeast-1)\\\"]\\n            BucketB[\\\"S3 Backup Bucket\\\\n(us-west-2)\\\"]\\n            BucketC[\\\"S3 Backup Bucket\\\\n(... more)\\\"]\\n        end\\n    end\\n\\n    subgraph Pulumi[\\\"Pulumi Stack (TypeScript)\\\"]\\n        Config[\\\"Pulumi Config\\\\n(project/env/regions)\\\"]\\n        IaC[\\\"index.ts\\\\nmulti-region resource factory\\\"]\\n        Tests[\\\"Jest-based unit tests\\\"]\\n    end\\n\\n    DSL -->|SCM sync| Pipeline\\n    Pipeline -->|fetch| Script\\n    Pipeline -->|Read config & region list| SSM\\n    Pipeline -->|Loop regions\\\\ninvoke AWS CLI| BucketA\\n    Pipeline --> BucketB\\n    Pipeline --> BucketC\\n    Pulumi -->|pulumi up| Regions\\n    Pulumi -->|write bucket metadata\\\\n& region list| SSM\\n    Tests --> IaC\\n```\\n\\n### 1.2 コンポーネント間の関係\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\n\\n### 1.3 データフロー\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\"Backup ${region}\\\")` を生成し、各ステージ内で\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\n\\n## 2. 実装戦略: EXTEND\\n\\n**判断根拠**:\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\n\\n## 3. テスト戦略: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\n\\n## 4. テストコード戦略: CREATE_TEST\\n\\n**判断根拠**:\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\n\\n## 5. 影響範囲分析\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\n\\n## 6. 変更・追加ファイルリスト\\n| 区分 | ファイル/パス | 目的 |\\n| ---- | ------------- | ---- |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\n\\n## 7. 詳細設計\\n\\n### 7.1 Pulumi (IaC) 詳細\\n- **Config インターフェース**  \\n  ```yaml\\n  # Pulumi.<stack>.yaml\\n  config:\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\n    jenkins-ssm-backup-s3:environment: dev\\n    jenkins-ssm-backup-s3:regions:\\n      - ap-northeast-1\\n      - us-west-2\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\n  ```\\n- **主要関数設計**\\n  | 関数/スコープ | 役割 |\\n  | ------------- | ---- |\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\n- **命名規則／タグ**  \\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/03_test_scenario/execute/agent_log_raw.txt:20:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_8\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"cd /tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator && sed -n '160,320p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/02_design/revise/agent_log.md:930:   208\t  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:40:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_22\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '120,220p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` 内で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` で取得し、存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `collect_parameters.sh` 実行結果 (`results/summary.json`) から `parameterCount` を読み取り、S3 へアップロードするアーティファクトパスを返す。\\n  - 取得結果は `return [bucket: ..., dataDir: ..., summaryPath: ...]` のように Map で返却し、ループ内で使い回す。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `loadRegionContext(region)` を呼び出し、取得したバケット名でアップロード。DRY_RUN 時は `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: ctx.parameterCount, artifactPath: ctx.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、同梱の簡易 HTTP サーバで受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:53:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_31\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '120,220p'\\\"\",\"aggregated_output\":\"   120\\t  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n   121\\t  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n   122\\t- **プロバイダー管理**  \\n   123\\t  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n   124\\t- **非同期処理**  \\n   125\\t  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n   126\\t- **エクスポート**  \\n   127\\t  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n   128\\t\\n   129\\t### 7.2 Jenkins Pipeline 詳細\\n   130\\t- **パイプライン方式**\\n   131\\t  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n   132\\t  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n   133\\t- **グローバル変数**\\n   134\\t  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n   135\\t  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n   136\\t- **リージョンコンテキスト取得**\\n   137\\t  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n   138\\t  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n   139\\t  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n   140\\t- **ステージ構成**\\n   141\\t  1. `stage('Initialize')`\\n   142\\t     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n   143\\t     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n   144\\t     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n   145\\t  2. `stage('Prepare Scripts')`\\n   146\\t     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n   147\\t  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n   148\\t     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n   149\\t     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n   150\\t     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n   151\\t     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n   152\\t  4. `stage('Finalize Report')`\\n   153\\t     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n   154\\t     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n   155\\t- **エラー制御**\\n   156\\t  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n   157\\t  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n   158\\t- **メトリクス／ログ**\\n   159\\t  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n   160\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n   161\\t\\n   162\\t### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n   163\\t- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n   164\\t- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n   165\\t- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n   166\\t\\n   167\\t### 7.4 `collect_parameters.sh`\\n   168\\t- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n   169\\t- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n   170\\t- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n   171\\t\\n   172\\t### 7.5 テスト設計詳細\\n   173\\t- **Pulumi (Jest)**  \\n   174\\t  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n   175\\t  - 期待事項:  \\n   176\\t    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n   177\\t    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n   178\\t    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n   179\\t    - `bucketMap` エクスポートが全リージョンを包含。\\n   180\\t- **Jenkins (jenkinsfile-runner)**  \\n   181\\t  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n   182\\t  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n   183\\t  - 検証点:  \\n   184\\t    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n   185\\t    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n   186\\t    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n   187\\t- **Manual テスト**  \\n   188\\t  - `pulumi preview` で各リージョンの差分を確認。  \\n   189\\t  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n   190\\t  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n   191\\t  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n   192\\t\\n   193\\t### 7.6 トレーサビリティ\\n   194\\t| 要件ID | 設計上の対応箇所 |\\n   195\\t| ------ | ---------------- |\\n   196\\t| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n   197\\t| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n   198\\t| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n   199\\t| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n   200\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n   201\\t\\n   202\\t### 7.7 通知計画 (FR-5)\\n   203\\t- **対象者**  \\n   204\\t  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n   205\\t  - CLI 経由でバックアップ結果を参照する開発チーム  \\n   206\\t- **チャネル**  \\n   207\\t  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n   208\\t  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n   209\\t- **タイミング**  \\n   210\\t  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n   211\\t  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n   212\\t  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n   213\\t- **責任者**  \\n   214\\t  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n   215\\t  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n   216\\t  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n   217\\t- **テスト/検証**  \\n   218\\t  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n   219\\t  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n   220\\t- **Runbook 更新**  \\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/02_design/revise/agent_log_raw.txt:55:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_32\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '200,320p'\\\"\",\"aggregated_output\":\"   200\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n   201\\t\\n   202\\t### 7.7 通知計画 (FR-5)\\n   203\\t- **対象者**  \\n   204\\t  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n   205\\t  - CLI 経由でバックアップ結果を参照する開発チーム  \\n   206\\t- **チャネル**  \\n   207\\t  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n   208\\t  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n   209\\t- **タイミング**  \\n   210\\t  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n   211\\t  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n   212\\t  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n   213\\t- **責任者**  \\n   214\\t  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n   215\\t  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n   216\\t  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n   217\\t- **テスト/検証**  \\n   218\\t  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n   219\\t  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n   220\\t- **Runbook 更新**  \\n   221\\t  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n   222\\t  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n   223\\t\\n   224\\t## 8. セキュリティ考慮事項\\n   225\\t- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n   226\\t- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n   227\\t- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n   228\\t\\n   229\\t## 9. 非機能要件への対応\\n   230\\t- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n   231\\t- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n   232\\t- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n   233\\t- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n   234\\t\\n   235\\t## 10. 実装の順序\\n   236\\t1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n   237\\t2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n   238\\t3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n   239\\t4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n   240\\t5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n   241\\t6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n   242\\t7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n   243\\t8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n   244\\t\\n   245\\t---\\n   246\\t\\n   247\\t### 品質ゲート確認\\n   248\\t- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n   249\\t- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n   250\\t- ✅ 既存コードへの影響範囲を分析\\n   251\\t- ✅ 必要な変更ファイルをリストアップ\\n   252\\t- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/02_design/review/agent_log.md:342:  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \n.ai-workflow/issue-391/02_design/review/agent_log.md:551:  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \n.ai-workflow/issue-391/02_design/review/agent_log.md:741:   208\t  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:14:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_5\",\"type\":\"command_execution\",\"command\":\"bash -lc 'cat .ai-workflow/issue-391/02_design/output/design.md'\",\"aggregated_output\":\"# Issue #391 詳細設計書: SSMバックアップのマルチリージョン対応\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体図\\n```mermaid\\nflowchart TD\\n    subgraph Jenkins[\\\"Jenkins (CI)\\\"]\\n        DSL[\\\"Groovy DSL\\\\nadmin_ssm_backup_job.groovy\\\"]\\n        Pipeline[\\\"Scripted Pipeline\\\\nJenkinsfile\\\"]\\n        Script[\\\"collect_parameters.sh\\\"]\\n    end\\n\\n    subgraph AWS[\\\"AWS Account\\\"]\\n        SSM[\\\"SSM Parameter Store\\\\n(env-scoped metadata)\\\"]\\n        subgraph Regions[\\\"対象リージョン (config-driven)\\\"]\\n            BucketA[\\\"S3 Backup Bucket\\\\n(ap-northeast-1)\\\"]\\n            BucketB[\\\"S3 Backup Bucket\\\\n(us-west-2)\\\"]\\n            BucketC[\\\"S3 Backup Bucket\\\\n(... more)\\\"]\\n        end\\n    end\\n\\n    subgraph Pulumi[\\\"Pulumi Stack (TypeScript)\\\"]\\n        Config[\\\"Pulumi Config\\\\n(project/env/regions)\\\"]\\n        IaC[\\\"index.ts\\\\nmulti-region resource factory\\\"]\\n        Tests[\\\"Jest-based unit tests\\\"]\\n    end\\n\\n    DSL -->|SCM sync| Pipeline\\n    Pipeline -->|fetch| Script\\n    Pipeline -->|Read config & region list| SSM\\n    Pipeline -->|Loop regions\\\\ninvoke AWS CLI| BucketA\\n    Pipeline --> BucketB\\n    Pipeline --> BucketC\\n    Pulumi -->|pulumi up| Regions\\n    Pulumi -->|write bucket metadata\\\\n& region list| SSM\\n    Tests --> IaC\\n```\\n\\n### 1.2 コンポーネント間の関係\\n- **Pulumi**: リージョン配列に基づき AWS Provider を切り替え、S3 バケット＋SSM パラメータをリージョンごとに生成。メタデータ（リージョン一覧、デフォルトリージョン、レガシー互換キー）を SSM に書き込む。\\n- **Jenkins Pipeline**: SSM からリージョン一覧を読み取り、Scripted Pipeline でリージョンごとのステージを動的生成しつつ逐次バックアップ処理・S3 アップロード・ログ集計を実施。失敗時は即座に後続リージョンをスキップ。\\n- **collect_parameters.sh**: Jenkins 各ステージからリージョン別に呼び出される共通スクリプト。AWS_REGION 等の環境変数を受け取り、該当リージョンの SSM からパラメータを収集して JSON 化。\\n- **Groovy DSL**: UI パラメータを変更せず、説明文・スケジューリング・タイムアウトなどのメタ情報だけを調整。\\n\\n### 1.3 データフロー\\n1. 運用チームが Pulumi config (`regions`, `defaultRegion`) を更新し、`pulumi up` 実行でターゲットリージョン毎の S3 バケットと `/jenkins/{env}/backup/{region}/s3-bucket-name` パラメータを作成。\\n2. Pulumi は同時に `/jenkins/{env}/backup/region-list`（JSON 配列）と `/jenkins/{env}/backup/s3-bucket-name`（互換用デフォルトバケット）も更新。\\n3. Jenkins DSL がスケジュールジョブを定義し、パイプライン起動時に `Initialize` ステージでリージョン一覧を SSM から取得し JSON→List へ変換。\\n4. Scripted Pipeline のメインループがリージョンごとに `stage(\\\"Backup ${region}\\\")` を生成し、各ステージ内で\\n   - 対象リージョンに切り替えた AWS CLI で SSM を参照しバケット名を取得\\n   - `collect_parameters.sh` を対象リージョン向けディレクトリで実行\\n   - DRY_RUN フラグに応じたアップロード（AES256）と最新ポインタ更新を実行し、結果をステージローカルのマップへ格納\\n5. 全リージョンの結果は `regionSummaries` に蓄積され、`Finalize Report` ステージで `region_summaries.json` として出力した後、post セクションで Slack／メール通知（7.7節）を送信する。失敗時は `error()` で即停止し、失敗リージョンと原因が通知に含まれる。\\n\\n## 2. 実装戦略: EXTEND\\n\\n**判断根拠**:\\n- 既存の Pulumi スタックと Jenkins パイプラインを土台に、多リージョン化のための設定値・ループ処理を追加する拡張作業が主体（FR-1, FR-3）。\\n- 既存 SSM キーを互換維持しながらリージョン別キーを増やす方針で、新規システムを構築するのではなく現状の IaC/CI を拡張する形となる（FR-2, FR-4）。\\n\\n## 3. テスト戦略: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- Pulumi 側はリージョン配列→リソース生成ロジックの分岐が増えるため、mocks を用いたユニットテストでリソース数・命名規則・タグを検証する必要がある（FR-1, NFR-保守性）。\\n- Jenkins パイプラインは多ステージ逐次実行とエラー制御を含むため、jenkinsfile-runner を使った dry-run 統合テストでリージョン別ステージ生成・失敗時の停止挙動を検証する（FR-3, NFR-可用性）。\\n\\n## 4. テストコード戦略: CREATE_TEST\\n\\n**判断根拠**:\\n- `pulumi/jenkins-ssm-backup-s3` には自動テストが存在しないため、Jest ベースの新規テストスイートを作成する必要がある。\\n- Jenkins パイプラインにも既存テストがないため、jenkinsfile-runner を呼び出す新規スクリプト＋サンプル設定を追加して自動検証を実現する。\\n\\n## 5. 影響範囲分析\\n- **Pulumi IaC**: `index.ts` のロジック刷新、Pulumi config ファイル（dev/prod）へのリージョン配列・デフォルトリージョン設定追加、`package.json` のテスト依存追加。\\n- **Jenkins Pipeline**: `Jenkinsfile` を Declarative から Scripted へ移行し、ステージ再編（Initialize → Config load、Regional loop 化）と失敗制御・ログ整備を追加。\\n- **Jenkins DSL**: UI パラメータ不変のまま説明文・タイムアウト・ビルド制御パラメータを見直し多リージョン実行時間を許容。\\n- **スクリプト**: `collect_parameters.sh` でリージョン名をログ出力し、複数回実行時のディレクトリ競合を防ぐ。\\n- **ドキュメント**: Runbook/README にリージョン追加/削除手順・ロールバック方針および Pulumi config 更新手順を追記。\\n- **その他**: Jenkins dry-run 用コンテナ利用方法を開発者ガイドに追記（テスト戦略反映）。\\n\\n## 6. 変更・追加ファイルリスト\\n| 区分 | ファイル/パス | 目的 |\\n| ---- | ------------- | ---- |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/index.ts` | 多リージョン対応ロジック、SSM メタデータ生成、命名規則の抽象化 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`<br>`pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml` | `regions`, `defaultRegion` 等の config 追加 |\\n| 既存修正 | `pulumi/jenkins-ssm-backup-s3/package.json` | テスト実行 (`jest`, `ts-jest`, `@types/jest`) スクリプトの追加 |\\n| 新規追加 | `pulumi/jenkins-ssm-backup-s3/__tests__/index.test.ts` | Pulumi mocks を用いた多リージョン生成ロジックのユニットテスト |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile` | リージョン逐次ステージ化、SSM リージョン一覧の読み込み、エラー停止 |\\n| 既存修正 | `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy` | ジョブ説明、タイムアウト、通知周りの調整 |\\n| 既存修正 | `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh` | リージョン別ディレクトリ対応、ログ明確化 |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/jenkinsfile_runner.sh` | jenkinsfile-runner を使った dry-run テストスクリプト |\\n| 新規追加 | `jenkins/jobs/pipeline/admin/ssm-backup/tests/config/regions_sample.json` | テスト用の SSM 疑似レスポンス/入力データ |\\n| 新規追加 | `scripts/aws_mock.sh` | Jenkins テストで AWS CLI をモックし、リージョン別レスポンスを返すヘルパー |\\n| 既存修正 | `docs/runbooks/ssm-backup.md` (存在する場合) / `README.md` | リージョン増減・Pulumi config 手順・ロールバック方法の追記 |\\n\\n## 7. 詳細設計\\n\\n### 7.1 Pulumi (IaC) 詳細\\n- **Config インターフェース**  \\n  ```yaml\\n  # Pulumi.<stack>.yaml\\n  config:\\n    jenkins-ssm-backup-s3:projectName: jenkins-infra\\n    jenkins-ssm-backup-s3:environment: dev\\n    jenkins-ssm-backup-s3:regions:\\n      - ap-northeast-1\\n      - us-west-2\\n    jenkins-ssm-backup-s3:defaultRegion: ap-northeast-1\\n    jenkins-ssm-backup-s3:ssmHomeRegion: ap-northeast-1  # SSM メタデータを書き込む基準リージョン\\n  ```\\n- **主要関数設計**\\n  | 関数/スコープ | 役割 |\\n  | ------------- | ---- |\\n  | `createRegionalResources(region: string, provider: aws.Provider, accountId: pulumi.Output<string>)` | バケット・パブリックアクセスブロック・バケットポリシー・リージョン別 SSM パラメータを生成し、`pulumi.Resource` を返す。 |\\n  | `emitLegacyParameter(defaultRegionBucketName: pulumi.Output<string>)` | 既存キー `/jenkins/{env}/backup/s3-bucket-name` を更新して後方互換を確保。 |\\n  | `emitRegionMetadata(regions: string[], defaultRegion: string)` | `/jenkins/{env}/backup/region-list`（JSON 文字列）と `/jenkins/{env}/backup/default-region` を `ssmHomeRegion` で生成。 |\\n- **命名規則／タグ**  \\n  `bucketName = ${projectName}-ssm-backup-${environment}-${accountId}-${region}`  \\n  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:18:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_7\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '200,360p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:20:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_8\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '120,260p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"  タグ: `Environment`, `ManagedBy=Pulumi`, `Region`, `Purpose=SSM Parameter Store Backup`, `DataClassification=Confidential`.  \\n  バケットリソース名: `ssm-backup-bucket-${region}`（Pulumi logical nameにリージョンを含め Terraform 差分衝突を防止）。\\n- **プロバイダー管理**  \\n  `const provider = new aws.Provider(\\\\`region-${region}\\\\`, { region });` を生成し、各リージョンの S3 リソースは該当プロバイダーにバインド。SSM パラメータは `provider: defaultProvider` または `ssmHomeRegion`.\\n- **非同期処理**  \\n  `aws.getCallerIdentity()` の `Output` を `pulumi.all` で束ね、リージョンループ内で `apply` を用いて命名文字列を構築。\\n- **エクスポート**  \\n  `export const bucketMap = pulumi.output(regions.reduce(...))` で `{ region: bucketName }` マップを出力し、CI/Runbook から参照可能にする。\\n\\n### 7.2 Jenkins Pipeline 詳細\\n- **パイプライン方式**\\n  - Jenkinsfile を Scripted Pipeline へ切り替え、`node('ssm-backup') { ... }` ブロックでステージを定義する。これによりリージョン配列に基づき `stage(\\\"Backup ${region}\\\")` を Groovy ループで逐次生成でき、Declarative のステージネスト制約を回避。\\n  - Jenkinsfile 内に共通関数（例: `loadRegionContext(region)`、`runBackupForRegion(ctx)`）を定義し、AWS CLI 呼び出しやエラーハンドリングを集約する。\\n- **グローバル変数**\\n  - `def regionList = []` と `def regionSummaries = [:]` を `node` ブロック直下で初期化し、リージョン一覧とリージョン別結果を管理。`regionSummaries` には `{status, parameterCount, artifactPath, failureMessage}` を格納。\\n  - 既存の `env.SSM_HOME_REGION`, `env.WORK_DIR`, `env.DATA_DIR`, `env.DRY_RUN` は `withEnv` で引き継ぎ、リージョン処理時に `REGION_DATA_DIR = \\\"${env.DATA_DIR}/${region}\\\"` を付与。\\n- **リージョンコンテキスト取得**\\n  - `loadRegionContext(region)` で `/jenkins/${env}/backup/${region}/s3-bucket-name` を `aws ssm get-parameter` から取得し、リージョン固有の作業ディレクトリ (`${env.DATA_DIR}/${region}`) を初期化。存在しない場合は `error(\\\"Bucket definition missing for ${region}\\\")`。\\n  - `runBackupForRegion(ctx)` が `collect_parameters.sh` を実行し、`results/summary.json` から `parameterCount` を読み取って S3 へアップロードする `.tar.gz` や `latest.txt` のパスを返す。\\n  - ループ内で `ctx`（リージョン情報）と `result`（実行結果）をマージし、通知／成果物化に必要なキーを整備する。\\n- **ステージ構成**\\n  1. `stage('Initialize')`\\n     - `/jenkins/${env}/backup/region-list` を取得し `readJSON` で配列化。空配列なら `error('No regions configured')` で早期終了。\\n     - `/jenkins/${env}/backup/default-region` と `/jenkins/${env}/backup/s3-bucket-name` を照合し後方互換を確認。\\n     - `currentBuild.description` に `Regions=[...], Default=...` を記録し、post 通知向けに `env.REGION_LIST = regionList.join(',')` を設定。\\n  2. `stage('Prepare Scripts')`\\n     - リポジトリ checkout、`collect_parameters.sh` の実行権限付与、jenkinsfile-runner テスト資材の配置確認を実施。\\n  3. `for (region in regionList) { stage(\\\"Backup ${region}\\\") { ... } }`\\n     - `withEnv([\\\"TARGET_REGION=${region}\\\", \\\"AWS_REGION=${region}\\\", \\\"REGION_DATA_DIR=${env.DATA_DIR}/${region}\\\"])` で環境を切り替え。\\n     - `def ctx = loadRegionContext(region)` で対象情報を取得し、`def result = runBackupForRegion(ctx)` を実行。DRY_RUN 時は `result.archivePath` を生成せず `echo \\\"[DRY RUN] Skipped upload for ${region}\\\"` のみ出力。\\n     - 正常終了時は `regionSummaries[region] = [status: 'SUCCESS', parameterCount: result.parameterCount, artifactPath: result.archivePath]` をセット。\\n     - 例外発生時は `regionSummaries[region] = [status: 'FAILED', failureMessage: err.getMessage()]` とし、`error(err.message)` でパイプラインを停止。\\n  4. `stage('Finalize Report')`\\n     - `writeJSON file: 'region_summaries.json', json: regionSummaries` と `archiveArtifacts artifacts: 'region_summaries.json'` を実施。\\n     - Runbook で参照するための最新成果物パスを `env.REGION_SUMMARY_PATH` に設定。\\n- **エラー制御**\\n  - Scripted Pipeline の `try/catch` でリージョン単位の例外を補足し、`regionSummaries` に失敗理由を残したうえで `error()` を再送する。\\n  - 逐次ループのため、失敗リージョン以降のステージは生成されない。リトライ時には Jenkins の `Replay` 機能でリージョン増減を確認可能。\\n- **メトリクス／ログ**\\n  - `collect_parameters.sh` は `summary.json` に `{\\\"parameterCount\\\": 123, \\\"executionTimeSec\\\": 45}` を出力し、パイプラインが `readJSON` で読み込む。\\n  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n\\n### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n\\n### 7.4 `collect_parameters.sh`\\n- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n\\n### 7.5 テスト設計詳細\\n- **Pulumi (Jest)**  \\n  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n  - 期待事項:  \\n    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n    - `bucketMap` エクスポートが全リージョンを包含。\\n- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:24:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_10\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '180,280p' .ai-workflow/issue-391/02_design/output/design.md\\\"\",\"aggregated_output\":\"- **Jenkins (jenkinsfile-runner)**  \\n  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n  - 検証点:  \\n    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n- **Manual テスト**  \\n  - `pulumi preview` で各リージョンの差分を確認。  \\n  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n\\n### 7.6 トレーサビリティ\\n| 要件ID | 設計上の対応箇所 |\\n| ------ | ---------------- |\\n| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n\\n### 7.7 通知計画 (FR-5)\\n- **対象者**  \\n  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n  - CLI 経由でバックアップ結果を参照する開発チーム  \\n- **チャネル**  \\n  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n- **タイミング**  \\n  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n- **責任者**  \\n  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n- **テスト/検証**  \\n  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n- **Runbook 更新**  \\n  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n\\n## 8. セキュリティ考慮事項\\n- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n\\n## 9. 非機能要件への対応\\n- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n\\n## 10. 実装の順序\\n1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n\\n---\\n\\n### 品質ゲート確認\\n- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n- ✅ 既存コードへの影響範囲を分析\\n- ✅ 必要な変更ファイルをリストアップ\\n- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/02_design/review/agent_log_raw.txt:28:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_12\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"nl -ba .ai-workflow/issue-391/02_design/output/design.md | sed -n '160,320p'\\\"\",\"aggregated_output\":\"   160\\t  - `currentBuild.description` と `region_summaries.json` を post セクションの Slack/Mail 通知テンプレートに渡し、リージョン別結果を通知。\\n   161\\t\\n   162\\t### 7.3 Jenkins DSL (`admin_ssm_backup_job.groovy`)\\n   163\\t- 説明文を「複数リージョンへ順次バックアップ」に更新し、期待実行時間やロールバック手順の参照先 (Runbook) を記載。\\n   164\\t- `throttleConcurrentBuilds { maxTotal(1) }` は維持しつつ、`pipelineTriggers` タイムゾーンコメントを多リージョン対応に合わせて更新。\\n   165\\t- `timeout`/`options` は Pipeline 内で 1 時間→リージョン数×10分 + α を許容できるよう `options { timeout(time: 90, unit: 'MINUTES') }` へ延長。DSL 側の説明にも反映。\\n   166\\t\\n   167\\t### 7.4 `collect_parameters.sh`\\n   168\\t- `DATA_DIR` を事前クリアする処理をオプション化し、リージョンごとにサブディレクトリを受け取って上書きを防止。Pipeline 側で `DATA_DIR=${WORK_DIR}/data/${TARGET_REGION}` を渡す。\\n   169\\t- ログに `Target Region` を追加しジョブログ上でリージョンを識別可能にする。\\n   170\\t- 連続実行時に `parameter_names.txt` 等がリージョンごとに保存されるため、`rm -f ${DATA_DIR}/*` を追加。\\n   171\\t\\n   172\\t### 7.5 テスト設計詳細\\n   173\\t- **Pulumi (Jest)**  \\n   174\\t  - `beforeAll` で `pulumi.runtime.setMocks` を設定し、`regions = [\\\"ap-northeast-1\\\", \\\"us-west-2\\\"]` を与えて `require(\\\"../index\\\")`。  \\n   175\\t  - 期待事項:  \\n   176\\t    - バケットがリージョン数分作成され Logical name/タグが正しい。  \\n   177\\t    - `/backup/{region}/s3-bucket-name` SSM が各リージョンに存在。  \\n   178\\t    - レガシーキー `/backup/s3-bucket-name` が defaultRegion のバケット名と一致。  \\n   179\\t    - `bucketMap` エクスポートが全リージョンを包含。\\n   180\\t- **Jenkins (jenkinsfile-runner)**  \\n   181\\t  - `tests/jenkinsfile_runner.sh` で Docker イメージ `ghcr.io/jenkinsci/jenkinsfile-runner:latest` を起動。  \\n   182\\t  - 事前に `AWS_REGION_LIST_JSON` などの env をモックし、`aws` CLI 呼び出しを `scripts/aws_mock.sh`（必要に応じ新規追加）で代替。  \\n   183\\t  - 検証点:  \\n   184\\t    - Scripted Pipeline がリージョン配列から `stage(\\\"Backup ${region}\\\")` を順次生成する。  \\n   185\\t    - `region_summaries.json` にリージョン別 `status` と `parameterCount` が記録される。  \\n   186\\t    - 2 番目のリージョンで `error` を発生させた際に処理が停止し、`regionSummaries` に失敗理由が入る。\\n   187\\t- **Manual テスト**  \\n   188\\t  - `pulumi preview` で各リージョンの差分を確認。  \\n   189\\t  - Jenkins 実行ログで `Backup us-west-2` ステージが 10 分以内に完了することを確認。  \\n   190\\t  - us-west-2 の S3 に `latest.txt` が更新されているか spot-check。  \\n   191\\t  - Slack 通知およびメール配信でリージョン別結果が配信されることを運用チャンネルで確認。\\n   192\\t\\n   193\\t### 7.6 トレーサビリティ\\n   194\\t| 要件ID | 設計上の対応箇所 |\\n   195\\t| ------ | ---------------- |\\n   196\\t| FR-1 | Pulumi 多リージョンリソース生成（7.1） |\\n   197\\t| FR-2 | レガシー SSM キー維持と defaultRegion メタデータ（7.1, Jenkins Initialize） |\\n   198\\t| FR-3 | Jenkins Regional orchestrator ステージ設計（7.2） |\\n   199\\t| FR-4 | DSL UI パラメータ不変・説明更新（7.3） |\\n   200\\t| FR-5 | 通知計画と運用責務整理（7.7, 9, 10 節） |\\n   201\\t\\n   202\\t### 7.7 通知計画 (FR-5)\\n   203\\t- **対象者**  \\n   204\\t  - Jenkins ジョブ実行者（運用チーム当番・オンコール SRE）  \\n   205\\t  - CLI 経由でバックアップ結果を参照する開発チーム  \\n   206\\t- **チャネル**  \\n   207\\t  - Slack `#infra-backup-alerts`: Jenkins post セクションから `slackSend` で成功/失敗を通知。本文には `region_summaries.json` の要約（成功・失敗リージョン、件数、duration）と Runbook リンクを含める。  \\n   208\\t  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \\n   209\\t- **タイミング**  \\n   210\\t  - パイプライン `post { success { ... } failure { ... } aborted { ... } }` で即時通知。  \\n   211\\t  - Pulumi config でリージョンを増減した際は同日の業務時間内に Slack `#infra-announcements` へ計画通知（運用担当が手動で投稿）。  \\n   212\\t  - 障害発生時は Runbook に従い 30 分以内に状況報告、復旧後 1 営業日以内に事後報告。  \\n   213\\t- **責任者**  \\n   214\\t  - ジョブオーナー: インフラチームリード（Jenkins folder owner）  \\n   215\\t  - オンコール SRE: 通知を受領し Runbook 手順でリカバリーを実施。  \\n   216\\t  - Pulumi オペレーター: config 変更時の事前通知・ロールバック判断を担当。  \\n   217\\t- **テスト/検証**  \\n   218\\t  - jenkinsfile-runner dry-run 時に Slack Webhook 先をダミー URL (`http://localhost:18080/slack`) に切り替え、`tests/jenkinsfile_runner.sh` で起動する簡易 HTTP サーバ（`python -m http.server 18080`）で受信したペイロードを `tests/output/slack_payload.json` に保存しリージョン要約が含まれることを確認。  \\n   219\\t  - 本番導入前にステージングジョブで成功/失敗ケースを実行し、Slack/メール双方で想定文面を確認する。  \\n   220\\t- **Runbook 更新**  \\n   221\\t  - 通知チャネルと責任者、ロールバック時の連絡テンプレートを `docs/runbooks/ssm-backup.md` に追記。  \\n   222\\t  - CLI 利用者向け FAQ に「どのタイミングで通知が届くか」「障害報告をどこで確認するか」を追加。\\n   223\\t\\n   224\\t## 8. セキュリティ考慮事項\\n   225\\t- **認証・認可**: Pulumi/Jenkins は既存 IAM ロールを継続利用。リージョン追加時に該当リージョンへの S3/SSM 権限があることを事前検証。jenkinsfile-runner テストでは資格情報をモックし、実際の AWS 認証情報を使用しない。\\n   226\\t- **データ保護**: すべての S3 バケットに SSE-S3 (`AES256`) を強制し、バケットポリシーで未暗号化アップロードを拒否。Public Access Block を全リージョンで有効化。SSM パラメータは `SecureString` を維持（bucket 名は `String` で問題ないが、将来的に暗号化情報を扱う場合のテンプレートを整備）。\\n   227\\t- **監査ログ**: Region ごとのバックアップ成功/失敗を Jenkins ログに記録し、後日 CloudTrail/S3 Access Log と突合できるようログフォーマットを標準化。Runbook にアラート発報手順を追記。\\n   228\\t\\n   229\\t## 9. 非機能要件への対応\\n   230\\t- **パフォーマンス**: ステージ毎のタイムアウトを 10 分に設定し、リージョン数に応じた合計を Scripted Pipeline のトップレベル `timeout(time: regionList.size()*10 + 30, unit: 'MINUTES')` でガード。AWS CLI のリトライは現行スクリプトの指数バックオフを再利用。\\n   231\\t- **スケーラビリティ**: Pulumi config のリージョン配列を変更するだけで対応リージョンを増減可能。Jenkins は動的ステージ生成によりコード変更なくリスト変化に追随。\\n   232\\t- **保守性**: Pulumi テストと Jenkins dry-run を CI へ組み込み、リージョン追加の回帰を早期検知。`bucketMap` エクスポートにより運用チームが CLI で状況確認しやすくする。\\n   233\\t- **可用性**: 失敗時に早期停止し、post セクションで失敗リージョンを明示。Runbook にはロールバック手順と再実行ガイドを追記。\\n   234\\t\\n   235\\t## 10. 実装の順序\\n   236\\t1. **Pulumi Config/コード修正**: `index.ts` を多リージョン化し、config ファイルとテスト依存を更新。\\n   237\\t2. **Pulumi ユニットテスト作成**: Jest セットアップと mocks を実装し、`npm test` で緑に。\\n   238\\t3. **Jenkins Pipeline リファクタ**: `Jenkinsfile` を Scripted Pipeline へ移行し、ヘルパーメソッド／リージョンループを実装して jenkinsfile-runner dry-run で検証。\\n   239\\t4. **collect_parameters.sh 調整**: リージョン別ディレクトリ／ログの拡充を反映。\\n   240\\t5. **Jenkins DSL 更新**: 説明・タイムアウト・ドキュメントリンクの修正。\\n   241\\t6. **jenkinsfile-runner テスト追加**: テストスクリプト整備とドキュメント化。\\n   242\\t7. **Runbook/README 更新**: リージョン増減・Pulumi config 変更手順、ロールバック手順を明文化。\\n   243\\t8. **統合テスト**: Pulumi preview、jenkinsfile-runner dry-run、本番想定リージョンのスポットテスト。\\n   244\\t\\n   245\\t---\\n   246\\t\\n   247\\t### 品質ゲート確認\\n   248\\t- ✅ 実装戦略 (EXTEND) と判断根拠を明記\\n   249\\t- ✅ テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記\\n   250\\t- ✅ 既存コードへの影響範囲を分析\\n   251\\t- ✅ 必要な変更ファイルをリストアップ\\n   252\\t- ✅ 実装手順と詳細設計で実現可能性を担保\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-391/02_design/output/design.md:208:  - メール `ops-alerts@example.com`: `emailext` で日次ジョブ成功時にリージョン別サマリを送付。失敗時は件名に `[FAIL]` を付与し、オンコール SRE を CC。  \n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_11","type":"command_execution","command":"bash -lc \"sed -n '1,200p' .ai-workflow/issue-391/04_implementation/output/implementation.md\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_11","type":"command_execution","command":"bash -lc \"sed -n '1,200p' .ai-workflow/issue-391/04_implementation/output/implementation.md\"","aggregated_output":"# 実装ログ\n\n## 実装サマリー\n- 実装戦略: EXTEND\n- 変更ファイル数: 9個\n- 新規作成ファイル数: 2個\n\n## 変更ファイル一覧\n\n### 新規作成\n- `docs/runbooks/ssm-backup.md`: マルチリージョン運用手順・ロールバック・通知フローを整理したRunbook\n- `.ai-workflow/issue-391/04_implementation/output/implementation.md`: 本フェーズの実装内容を記録\n\n### 修正\n- `pulumi/jenkins-ssm-backup-s3/index.ts`: 多リージョンS3/SSMリソース生成と地域メタデータ出力に対応\n- `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`: リージョン配列・デフォルトリージョン・SSMホームリージョンを追加\n- `pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml`: 本番スタック用に同上設定を追加\n- `pulumi/jenkins-ssm-backup-s3/package.json`: Jest系依存と`jest --passWithNoTests`スクリプトを定義\n- `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile`: Scripted Pipeline化とリージョン逐次ステージ/サマリ生成を実装\n- `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh`: リージョンログ/ディレクトリ初期化/summary出力を追加\n- `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy`: 説明文・実行時間注記をマルチリージョン対応へ更新\n- `.ai-workflow/issue-391/metadata.json`: ワークフロー管理情報がimplementationフェーズに遷移\n\n## 実装詳細\n\n### ファイル1: pulumi/jenkins-ssm-backup-s3/index.ts\n- **変更内容**: リージョン配列を検証し、リージョンごとにProviderを切り替えてS3バケット/パブリックアクセスブロック/ポリシー/SSMパラメータを生成。既存互換キーとリージョンリスト/デフォルトリージョンのメタデータを出力し、`bucketMap` をエクスポート。\n- **理由**: PulumiスタックでFR-1/FR-2のマルチリージョン要件を満たし、Jenkins側がリージョン一覧とバケット名を参照できるようにするため。\n- **注意点**: `regions` と `defaultRegion` のPulumi Config設定が必須。`ssmHomeRegion` を変更する場合はJenkinsパイプラインの環境変数とも整合させる。\n\n### ファイル2: pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml\n- **変更内容**: `regions`, `defaultRegion`, `ssmHomeRegion` を追加し、Dev環境の多リージョン構成を定義。\n- **理由**: Pulumiコードの新しい入力インターフェースに合わせるため。\n- **注意点**: 本番と異なるリージョン構成にする場合は`defaultRegion`を必ず配列内に含める。\n\n### ファイル3: pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml\n- **変更内容**: Prod環境用にDevと同様のマルチリージョン設定フィールドを追加。\n- **理由**: Pulumiスタックを本番でも同じインターフェースで動かすため。\n- **注意点**: 本番のリージョン変更時はRunbookに従い事前告知と`pulumi preview`を実行する。\n\n### ファイル4: pulumi/jenkins-ssm-backup-s3/package.json\n- **変更内容**: Jest/ts-jest/@types/jestをdevDependenciesに追加し、`npm test`でエラーとならないよう`jest --passWithNoTests`を設定。\n- **理由**: Phase 5で追加予定のユニットテスト基盤を事前に整え、今フェーズでもTypeScriptビルド確認が可能な状態にするため。\n- **注意点**: `npm install`実行後は`node_modules`をコミットしないよう注意。\n\n### ファイル5: jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\n- **変更内容**: DeclarativeからScripted Pipelineへ移行し、SSMから取得したリージョン配列で逐次ステージを生成。リージョンごとのバックアップ実行、S3アップロード（地域別`latest-<region>.txt`とデフォルト用`latest.txt`）、`region_summaries.json`の生成、ポストサマリー出力を実装。\n- **理由**: FR-3の逐次処理/失敗制御要件に対応しつつ、リージョン数に応じた動的ステージ生成とメタ情報出力を実現するため。\n- **注意点**: SSMホームリージョンを変える場合は Jenkins ノードに `SSM_HOME_REGION` 環境変数を設定する。S3アップロードはパラメータ数0の場合にスキップする仕様。\n\n### ファイル6: jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\n- **変更内容**: 実行前に出力ディレクトリを初期化し、ターゲットリージョンをログに出力。バックアップ処理後にリージョン別サマリーJSONを生成。\n- **理由**: 多リージョン実行時にファイル衝突を避け、パイプラインで参照できる統一フォーマットのサマリーを提供するため。\n- **注意点**: jq/AWS CLI依存は従来通り。DRY_RUN時はパイプライン側で制御する。\n\n### ファイル7: jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy\n- **変更内容**: ジョブ説明とcronコメントをマルチリージョン運用向けに更新し、Runbook参照先を明示。\n- **理由**: FR-4の「UIパラメータ変更なしで多リージョン対応」の方針を維持しつつ利用者への注意点を明文化するため。\n- **注意点**: 説明文内のRunbookパス変更時は併せて更新する。\n\n### ファイル8: docs/runbooks/ssm-backup.md\n- **変更内容**: バックアップジョブの概要、リージョン追加/削除手順、ロールバック、通知、トラブルシューティングを整理。\n- **理由**: 運用チームが多リージョン化後の手順と連絡フローを即座に参照できるようにするため。\n- **注意点**: Pulumi Configや通知チャネルを更新したら本Runbookも同期する。\n\n### ファイル9: .ai-workflow/issue-391/metadata.json\n- **変更内容**: ワークフロー状態が implementation フェーズ開始を示すよう自動更新。\n- **理由**: AIワークフローの進行管理に伴うメタ情報更新。\n- **注意点**: システム更新のため手動で編集しない。\n\n## 次のステップ\n- Phase 5（test_implementation）でPulumi/Jenkinsの自動テストコードを追加し`npm test`/jenkinsfile-runner検証を実装\n- Phase 6（testing）で`pulumi preview`とjenkinsfile-runner dry-runを実施し、マルチリージョン挙動を確認\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_12","type":"command_execution","command":"bash -lc \"sed -n '60,140p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_12","type":"command_execution","command":"bash -lc \"sed -n '60,140p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"                        aws ssm get-parameter \\\\\n                            --name \"${pipelineContext.metadataBasePath}/default-region\" \\\\\n                            --query 'Parameter.Value' \\\\\n                            --output text \\\\\n                            --region ${ssmHomeRegion} 2>/dev/null || echo \"\"\n                    \"\"\",\n                    returnStdout: true\n                ).trim()\n\n                if (!defaultRegionValue) {\n                    error(\"Default region parameter '${pipelineContext.metadataBasePath}/default-region' is missing.\")\n                }\n\n                if (!regionList.contains(defaultRegionValue)) {\n                    error(\"Default region '${defaultRegionValue}' is not part of configured region list ${regionList}.\")\n                }\n\n                env.DEFAULT_REGION = defaultRegionValue\n\n                def legacyBucket = sh(\n                    script: \"\"\"\n                        aws ssm get-parameter \\\\\n                            --name \"${pipelineContext.metadataBasePath}/s3-bucket-name\" \\\\\n                            --query 'Parameter.Value' \\\\\n                            --output text \\\\\n                            --region ${ssmHomeRegion} 2>/dev/null || echo \"\"\n                    \"\"\",\n                    returnStdout: true\n                ).trim()\n\n                if (legacyBucket) {\n                    env.BACKUP_BUCKET = legacyBucket\n                }\n\n                currentBuild.displayName = \"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\"\n                currentBuild.description = \"Regions=${regionList.join(',')} | Default=${defaultRegionValue}\"\n\n                echo \"\"\"\n                =============================================\n                SSM Parameter Store Backup (Multi-Region)\n                =============================================\n                Environment      : ${params.ENVIRONMENT}\n                Regions          : ${regionList.join(', ')}\n                Default Region   : ${defaultRegionValue}\n                Dry Run          : ${params.DRY_RUN}\n                Backup Date      : ${env.BACKUP_DATE}\n                Timestamp        : ${env.BACKUP_TIMESTAMP}\n                SSM Home Region  : ${ssmHomeRegion}\n                Work Directory   : ${workDir}\n                =============================================\n                \"\"\".stripIndent()\n\n                env.REGION_LIST = regionList.join(',')\n                pipelineContext.timeoutMinutes = Math.max(regionList.size() * 10 + 30, 30)\n            }\n\n            timeout(time: pipelineContext.timeoutMinutes as int, unit: 'MINUTES') {\n                stage('Prepare Scripts') {\n                    sh \"rm -rf jenkins-repo\"\n                    dir('jenkins-repo') {\n                        checkout([\n                            $class: 'GitSCM',\n                            branches: [[name: \"${params.JENKINSFILE_BRANCH}\"]],\n                            userRemoteConfigs: [[\n                                url: 'https://github.com/tielec/infrastructure-as-code',\n                                credentialsId: 'github-app-credentials'\n                            ]]\n                        ])\n                    }\n\n                    sh \"\"\"\n                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${scriptDir}/\n                        chmod +x ${scriptDir}/collect_parameters.sh\n                        ls -la ${scriptDir}/\n                    \"\"\"\n                }\n\n                boolean dryRun = params.DRY_RUN as boolean\n\n                regionList.each { region ->\n                    stage(\"Backup ${region}\") {\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_13","type":"command_execution","command":"bash -lc \"sed -n '140,260p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_13","type":"command_execution","command":"bash -lc \"sed -n '140,260p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"                    stage(\"Backup ${region}\") {\n                        def ctx = loadRegionContext(\n                            params.ENVIRONMENT,\n                            region,\n                            pipelineContext.metadataBasePath,\n                            ssmHomeRegion,\n                            dataDir\n                        )\n\n                        def stageStart = System.currentTimeMillis()\n\n                        try {\n                            def result = runBackupForRegion(\n                                ctx + [\n                                    defaultRegion: env.DEFAULT_REGION,\n                                    scriptDir: scriptDir,\n                                    envFilter: env.ENV_FILTER,\n                                    backupDate: env.BACKUP_DATE,\n                                    backupTimestamp: env.BACKUP_TIMESTAMP,\n                                ],\n                                dryRun\n                            )\n\n                            def durationSeconds = ((System.currentTimeMillis() - stageStart) / 1000) as long\n\n                            regionSummaries[region] = [\n                                status          : 'SUCCESS',\n                                parameterCount  : result.parameterCount,\n                                bucket          : ctx.bucketName,\n                                s3Key           : result.s3Key,\n                                dryRun          : dryRun,\n                                durationSeconds : durationSeconds,\n                            ]\n\n                            echo \"Backup for ${region} completed (parameters=${result.parameterCount}, dryRun=${dryRun})\"\n                        } catch (Throwable t) {\n                            def durationSeconds = ((System.currentTimeMillis() - stageStart) / 1000) as long\n                            regionSummaries[region] = [\n                                status          : 'FAILED',\n                                message         : t.getMessage(),\n                                durationSeconds : durationSeconds,\n                            ]\n                            throw t\n                        }\n                    }\n                }\n\n                stage('Finalize Report') {\n                    def summaryFile = \"${workDirRelative}/region_summaries.json\"\n                    writeJSON file: summaryFile, json: regionSummaries, pretty: 4\n                    archiveArtifacts artifacts: summaryFile, fingerprint: true\n                    env.REGION_SUMMARY_PATH = \"${workDir}/${summaryFile.split('/', 2).last()}\"\n                    echo \"Region summary stored at ${summaryFile}\"\n                }\n            }\n\n            currentBuild.result = currentBuild.result ?: 'SUCCESS'\n        } catch (Throwable err) {\n            currentBuild.result = currentBuild.result ?: 'FAILURE'\n            throw err\n        } finally {\n            stage('Post Actions') {\n                emitRunSummary(regionSummaries, params.ENVIRONMENT, params.DRY_RUN as boolean)\n                if (currentBuild.result == 'SUCCESS') {\n                    echo \"✅ SSMパラメータのバックアップが正常に完了しました\"\n                } else if (currentBuild.result == 'UNSTABLE') {\n                    echo \"⚠️ バックアップは完了しましたが、警告があります\"\n                } else {\n                    echo \"❌ バックアップが失敗しました。ログを確認してください\"\n                }\n\n                sh \"rm -rf ${workDir} jenkins-repo || true\"\n            }\n        }\n    }\n}\n\ndef loadRegionContext(String environment, String region, String metadataBasePath, String ssmHomeRegion, String dataDirRoot) {\n    def parameterName = \"${metadataBasePath}/${region}/s3-bucket-name\"\n    def bucketName = sh(\n        script: \"\"\"\n            aws ssm get-parameter \\\\\n                --name \"${parameterName}\" \\\\\n                --query 'Parameter.Value' \\\\\n                --output text \\\\\n                --region ${ssmHomeRegion} 2>/dev/null || echo \"\"\n        \"\"\",\n        returnStdout: true\n    ).trim()\n\n    if (!bucketName) {\n        error(\"Bucket definition missing for region ${region}. Expected SSM parameter ${parameterName}.\")\n    }\n\n    def regionDataDir = \"${dataDirRoot}/${region}\"\n    sh \"\"\"\n        rm -rf ${regionDataDir}\n        mkdir -p ${regionDataDir}\n    \"\"\"\n\n    return [\n        environment   : environment,\n        region        : region,\n        bucketName    : bucketName,\n        regionDataDir : regionDataDir,\n    ]\n}\n\ndef runBackupForRegion(Map ctx, boolean dryRun) {\n    def envFilter = ctx.envFilter\n    def scriptDir = ctx.scriptDir\n    def backupDate = ctx.backupDate\n    def backupTimestamp = ctx.backupTimestamp\n    def environment = ctx.environment\n    def region = ctx.region\n    def regionDataDir = ctx.regionDataDir\n    def bucketName = ctx.bucketName\n    def defaultRegion = ctx.defaultRegion\n\n    def backupJsonPath = \"${regionDataDir}/backup.json\"\n    def backupFileName = \"ssm-backup-${environment}-${region}-${backupTimestamp}.json\"\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_14","type":"file_change","changes":[{"path":"/tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator/jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_15","type":"file_change","changes":[{"path":"/tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator/jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_16","type":"file_change","changes":[{"path":"/tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator/jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile","kind":"update"}],"status":"completed"}}
{"type":"item.started","item":{"id":"item_17","type":"command_execution","command":"bash -lc \"grep -n \\\"return \\\\[\\\" -n jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_17","type":"command_execution","command":"bash -lc \"grep -n \\\"return \\\\[\\\" -n jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"247:    return [\n352:    return [\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_18","type":"command_execution","command":"bash -lc \"sed -n '320,360p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_18","type":"command_execution","command":"bash -lc \"sed -n '320,360p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"            echo '${s3Key}' | aws s3 cp - s3://${bucketName}/latest-${region}.txt \\\n                --sse AES256 \\\n                --region ${region}\n        \"\"\"\n\n        if (region == defaultRegion) {\n            sh \"\"\"\n                echo '${s3Key}' | aws s3 cp - s3://${bucketName}/latest.txt \\\n                    --sse AES256 \\\n                    --region ${region}\n            \"\"\"\n        }\n\n        def objectInfo = sh(\n            script: \"\"\"\n                aws s3api head-object \\\\\n                    --bucket ${bucketName} \\\\\n                    --key ${s3Key} \\\\\n                    --query '[ContentLength, LastModified]' \\\\\n                    --output text \\\\\n                    --region ${region}\n            \"\"\",\n            returnStdout: true\n        ).trim()\n\n        echo \"S3 Object Info [${region}]: ${objectInfo}\"\n    } else if (dryRun) {\n        echo \"[DRY RUN] Skipped S3 upload for ${region}. Planned key: ${s3Key}\"\n    } else {\n        echo \"No parameters to upload for ${region}. Skipping S3 upload.\"\n    }\n\n    return [\n        parameterCount : parameterCount,\n        s3Key          : s3Key,\n        backupFilePath : backupFilePath,\n        summaryPath    : summaryPath,\n    ]\n}\n\ndef emitRunSummary(Map regionSummaries, String environment, boolean dryRun) {\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_19","type":"file_change","changes":[{"path":"/tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator/jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile","kind":"update"}],"status":"completed"}}
{"type":"item.started","item":{"id":"item_20","type":"command_execution","command":"bash -lc \"sed -n '360,440p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_20","type":"command_execution","command":"bash -lc \"sed -n '360,440p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"        executionTimeSec: executionTimeSec,\n        failedCount     : failedCount,\n    ]\n}\n\ndef emitRunSummary(Map regionSummaries, String environment, boolean dryRun) {\n    echo \"\"\"\n    =============================================\n    SSM Parameter Store Backup Summary\n    =============================================\n    Build       : #${env.BUILD_NUMBER}\n    Status      : ${currentBuild.result ?: 'UNKNOWN'}\n    Environment : ${environment}\n    Dry Run     : ${dryRun}\n    Regions     : ${env.REGION_LIST ?: 'N/A'}\n    Summary File: ${env.REGION_SUMMARY_PATH ?: 'N/A'}\n    =============================================\n    \"\"\".stripIndent()\n\n    regionSummaries.each { region, summary ->\n        echo \"Region: ${region} => ${summary}\"\n    }\n}\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_21","type":"file_change","changes":[{"path":"/tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator/jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_22","type":"file_change","changes":[{"path":"/tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh","kind":"update"}],"status":"completed"}}
{"type":"item.started","item":{"id":"item_23","type":"command_execution","command":"bash -lc \"sed -n '220,360p' jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_23","type":"command_execution","command":"bash -lc \"sed -n '220,360p' jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\"","aggregated_output":"            BATCH_RESULT=$(aws ssm get-parameters \\\n                --names \"${batch_params[@]}\" \\\n                --with-decryption \\\n                --output json \\\n                --region ${AWS_REGION} 2>/dev/null || echo '{\"Parameters\": [], \"InvalidParameters\": []}')\n\n            VALID_PARAMS=$(echo \"$BATCH_RESULT\" | jq '.Parameters // []')\n            if [ \"$VALID_PARAMS\" != \"[]\" ] && [ \"$VALID_PARAMS\" != \"null\" ]; then\n                BACKUP_DATA=$(echo \"$BACKUP_DATA\" | jq --argjson new_params \"$VALID_PARAMS\" '. + $new_params')\n            fi\n\n            INVALID_PARAMS=$(echo \"$BATCH_RESULT\" | jq -r '.InvalidParameters[]?' 2>/dev/null)\n            if [ -n \"$INVALID_PARAMS\" ]; then\n                while IFS= read -r invalid_param; do\n                    echo \"Warning: Failed to get parameter: $invalid_param\"\n                    FAILED_PARAMS+=(\"$invalid_param\")\n                    FAILED_COUNT=$((FAILED_COUNT + 1))\n                done <<< \"$INVALID_PARAMS\"\n            fi\n        fi\n\n        if [ $end -lt $TOTAL_PARAMS ]; then\n            sleep 2\n        fi\n    done\nelse\n    echo \"WARNING: No parameters found matching filter '${ENV_FILTER}'\"\nfi\n\nCOUNTER=$TOTAL_PARAMS\n\necho \"Successfully fetched $((COUNTER - FAILED_COUNT)) parameters\"\nif [ \"$FAILED_COUNT\" -gt 0 ]; then\n    echo \"Failed to fetch ${FAILED_COUNT} parameters\"\nfi\n\n# バックアップファイルの作成\necho \"Creating backup file...\"\nBACKUP_JSON=$(jq -n \\\n    --arg date \"${BACKUP_DATE}\" \\\n    --arg timestamp \"${BACKUP_TIMESTAMP}\" \\\n    --arg environment \"${ENVIRONMENT}\" \\\n    --arg count \"$((COUNTER - FAILED_COUNT))\" \\\n    --argjson parameters \"$BACKUP_DATA\" \\\n    '{\n        backup_date: $date,\n        backup_timestamp: $timestamp,\n        environment: $environment,\n        parameter_count: $count | tonumber,\n        parameters: $parameters\n    }')\n\necho \"$BACKUP_JSON\" | jq '.' > ${DATA_DIR}/backup.json\n\necho \"======================================\"\necho \"Backup Summary\"\necho \"======================================\"\necho \"Backup file created: ${DATA_DIR}/backup.json\"\necho \"Total parameters backed up: $(echo \"$BACKUP_JSON\" | jq '.parameter_count')\"\necho \"Failed parameters: ${FAILED_COUNT}\"\necho \"======================================\"\n\n# サマリーファイルを生成して上位パイプラインで参照できるようにする\necho \"Creating summary file...\"\njq -n \\\n    --arg environment \"${ENVIRONMENT}\" \\\n    --arg region \"${AWS_REGION}\" \\\n    --arg backup_date \"${BACKUP_DATE}\" \\\n    --arg backup_timestamp \"${BACKUP_TIMESTAMP}\" \\\n    --argjson parameter_count \"$(echo \"$BACKUP_JSON\" | jq '.parameter_count')\" \\\n    --argjson failed_count $FAILED_COUNT \\\n    '{\n        environment: $environment,\n        region: $region,\n        backup_date: $backup_date,\n        backup_timestamp: $backup_timestamp,\n        parameter_count: $parameter_count,\n        failed_count: $failed_count\n    }' > \"${DATA_DIR}/summary.json\"\n\necho \"Summary file created: ${DATA_DIR}/summary.json\"\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_24","type":"file_change","changes":[{"path":"/tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh","kind":"update"}],"status":"completed"}}
{"type":"item.started","item":{"id":"item_25","type":"command_execution","command":"bash -lc 'git status -sb'","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_25","type":"command_execution","command":"bash -lc 'git status -sb'","aggregated_output":"## ai-workflow/issue-391...origin/ai-workflow/issue-391\n M .ai-workflow/issue-391/metadata.json\n M jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy\n M jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\n M jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\n M pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml\n M pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml\n M pulumi/jenkins-ssm-backup-s3/index.ts\n M pulumi/jenkins-ssm-backup-s3/package.json\n?? .ai-workflow/issue-391/04_implementation/\n?? docs/\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_26","type":"command_execution","command":"bash -lc 'git diff jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile'","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_26","type":"command_execution","command":"bash -lc 'git diff jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile'","aggregated_output":"diff --git a/jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile b/jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\nindex 2fef425..03b9bdc 100644\n--- a/jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\n+++ b/jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\n@@ -1,92 +1,121 @@\n @Library('jenkins-shared-lib') _\n \n-/**\n- * SSM Parameter Store Backup Pipeline\n- * AWS Systems Manager Parameter Storeのパラメータを定期的にバックアップ\n- */\n-pipeline {\n-    agent {\n-        label 'ec2-fleet'\n-    }\n-    \n-    options {\n-        timestamps()\n-        timeout(time: 1, unit: 'HOURS')\n-        buildDiscarder(logRotator(daysToKeepStr: '30', numToKeepStr: '100'))\n-        disableConcurrentBuilds()\n-    }\n-    \n-    environment {\n-        // AWS設定\n-        AWS_REGION = 'ap-northeast-1'\n-        \n-        // タイムスタンプ\n-        BACKUP_DATE = sh(script: \"date '+%Y-%m-%d'\", returnStdout: true).trim()\n-        BACKUP_TIMESTAMP = sh(script: \"date '+%Y%m%d_%H%M%S'\", returnStdout: true).trim()\n-        \n-        // ディレクトリ構造\n-        WORK_DIR = \"${WORKSPACE}/backup-work\"\n-        DATA_DIR = \"${WORK_DIR}/data\"\n-        SCRIPT_DIR = \"${WORKSPACE}/scripts\"\n-        \n-        // 環境フィルタ（環境に含まれる文字列）\n-        ENV_FILTER = \"/${params.ENVIRONMENT}/\"\n-    }\n-    \n-    stages {\n-        stage('Initialize') {\n-            steps {\n-                script {\n-                    // ビルド表示名を設定\n-                    currentBuild.displayName = \"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\"\n-                    currentBuild.description = \"Backup at ${env.BACKUP_TIMESTAMP}\"\n-                    \n-                    echo \"\"\"\n-                    =============================================\n-                    SSM Parameter Store Backup\n-                    =============================================\n-                    Environment: ${params.ENVIRONMENT}\n-                    Filter: Parameters containing '${env.ENV_FILTER}'\n-                    Dry Run: ${params.DRY_RUN}\n-                    Timestamp: ${env.BACKUP_TIMESTAMP}\n-                    Date: ${env.BACKUP_DATE}\n-                    =============================================\n-                    \"\"\".stripIndent()\n-                    \n-                    // 作業ディレクトリの準備\n-                    sh \"\"\"\n-                        rm -rf ${WORK_DIR}\n-                        mkdir -p ${DATA_DIR}\n-                        mkdir -p ${SCRIPT_DIR}\n-                    \"\"\"\n-                    \n-                    // S3バケット名の取得\n-                    env.BACKUP_BUCKET = sh(\n-                        script: \"\"\"\n-                            aws ssm get-parameter \\\n-                                --name \"/jenkins/${params.ENVIRONMENT}/backup/s3-bucket-name\" \\\n-                                --query 'Parameter.Value' \\\n-                                --output text \\\n-                                --region ${AWS_REGION} 2>/dev/null || echo \"\"\n-                        \"\"\",\n-                        returnStdout: true\n-                    ).trim()\n-                    \n-                    if (!env.BACKUP_BUCKET) {\n-                        error(\"バックアップ用S3バケットが見つかりません。Pulumiスタックがデプロイされていることを確認してください。\")\n-                    }\n-                    \n-                    echo \"Backup S3 Bucket: ${env.BACKUP_BUCKET}\"\n+def regionList = []\n+def regionSummaries = [:]\n+def pipelineContext = [\n+    metadataBasePath: \"/jenkins/${params.ENVIRONMENT}/backup\",\n+]\n+\n+node('ec2-fleet') {\n+    timestamps {\n+        def ssmHomeRegion = env.SSM_HOME_REGION ?: 'ap-northeast-1'\n+        def workDirRelative = \"backup-work\"\n+        def dataDirRelative = \"${workDirRelative}/data\"\n+        def scriptDirRelative = \"${workDirRelative}/scripts\"\n+        def workDir = \"${env.WORKSPACE}/${workDirRelative}\"\n+        def dataDir = \"${env.WORKSPACE}/${dataDirRelative}\"\n+        def scriptDir = \"${env.WORKSPACE}/${scriptDirRelative}\"\n+        def envFilter = \"/${params.ENVIRONMENT}/\"\n+        env.SSM_HOME_REGION = ssmHomeRegion\n+        env.WORK_DIR = workDir\n+        env.DATA_DIR = dataDir\n+        env.SCRIPT_DIR = scriptDir\n+        env.ENV_FILTER = envFilter\n+\n+        try {\n+            stage('Initialize') {\n+                env.BACKUP_DATE = sh(script: \"date '+%Y-%m-%d'\", returnStdout: true).trim()\n+                env.BACKUP_TIMESTAMP = sh(script: \"date '+%Y%m%d_%H%M%S'\", returnStdout: true).trim()\n+\n+                sh \"\"\"\n+                    rm -rf ${workDir}\n+                    mkdir -p ${dataDir}\n+                    mkdir -p ${scriptDir}\n+                \"\"\"\n+\n+                def regionListJson = sh(\n+                    script: \"\"\"\n+                        aws ssm get-parameter \\\\\n+                            --name \"${pipelineContext.metadataBasePath}/region-list\" \\\\\n+                            --query 'Parameter.Value' \\\\\n+                            --output text \\\\\n+                            --region ${ssmHomeRegion} 2>/dev/null || echo \"\"\n+                    \"\"\",\n+                    returnStdout: true\n+                ).trim()\n+\n+                if (!regionListJson?.trim()) {\n+                    error(\"Region list parameter '${pipelineContext.metadataBasePath}/region-list' is missing or empty.\")\n+                }\n+\n+                regionList = readJSON(text: regionListJson)\n+                if (!(regionList instanceof List) || regionList.isEmpty()) {\n+                    error(\"Region list is empty. Pulumi config must define at least one region.\")\n                 }\n+\n+                regionList = regionList.collect { it.toString() }\n+\n+                def defaultRegionValue = sh(\n+                    script: \"\"\"\n+                        aws ssm get-parameter \\\\\n+                            --name \"${pipelineContext.metadataBasePath}/default-region\" \\\\\n+                            --query 'Parameter.Value' \\\\\n+                            --output text \\\\\n+                            --region ${ssmHomeRegion} 2>/dev/null || echo \"\"\n+                    \"\"\",\n+                    returnStdout: true\n+                ).trim()\n+\n+                if (!defaultRegionValue) {\n+                    error(\"Default region parameter '${pipelineContext.metadataBasePath}/default-region' is missing.\")\n+                }\n+\n+                if (!regionList.contains(defaultRegionValue)) {\n+                    error(\"Default region '${defaultRegionValue}' is not part of configured region list ${regionList}.\")\n+                }\n+\n+                env.DEFAULT_REGION = defaultRegionValue\n+\n+                def legacyBucket = sh(\n+                    script: \"\"\"\n+                        aws ssm get-parameter \\\\\n+                            --name \"${pipelineContext.metadataBasePath}/s3-bucket-name\" \\\\\n+                            --query 'Parameter.Value' \\\\\n+                            --output text \\\\\n+                            --region ${ssmHomeRegion} 2>/dev/null || echo \"\"\n+                    \"\"\",\n+                    returnStdout: true\n+                ).trim()\n+\n+                if (legacyBucket) {\n+                    env.BACKUP_BUCKET = legacyBucket\n+                }\n+\n+                currentBuild.displayName = \"#${env.BUILD_NUMBER} - ${params.ENVIRONMENT} Backup\"\n+                currentBuild.description = \"Regions=${regionList.join(',')} | Default=${defaultRegionValue}\"\n+\n+                echo \"\"\"\n+                =============================================\n+                SSM Parameter Store Backup (Multi-Region)\n+                =============================================\n+                Environment      : ${params.ENVIRONMENT}\n+                Regions          : ${regionList.join(', ')}\n+                Default Region   : ${defaultRegionValue}\n+                Dry Run          : ${params.DRY_RUN}\n+                Backup Date      : ${env.BACKUP_DATE}\n+                Timestamp        : ${env.BACKUP_TIMESTAMP}\n+                SSM Home Region  : ${ssmHomeRegion}\n+                Work Directory   : ${workDir}\n+                =============================================\n+                \"\"\".stripIndent()\n+\n+                env.REGION_LIST = regionList.join(',')\n+                pipelineContext.timeoutMinutes = Math.max(regionList.size() * 10 + 30, 30)\n             }\n-        }\n-        \n-        stage('Prepare Scripts') {\n-            steps {\n-                script {\n-                    echo \"=== Preparing Collection Scripts ===\"\n-                    \n-                    // Jenkinsリポジトリをチェックアウト\n+\n+            timeout(time: pipelineContext.timeoutMinutes as int, unit: 'MINUTES') {\n+                stage('Prepare Scripts') {\n+                    sh \"rm -rf jenkins-repo\"\n                     dir('jenkins-repo') {\n                         checkout([\n                             $class: 'GitSCM',\n@@ -97,181 +126,350 @@ pipeline {\n                             ]]\n                         ])\n                     }\n-                    \n-                    // スクリプトをコピー\n+\n                     sh \"\"\"\n-                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${SCRIPT_DIR}/\n-                        chmod +x ${SCRIPT_DIR}/collect_parameters.sh\n-                        \n-                        echo \"Script copied and made executable\"\n-                        ls -la ${SCRIPT_DIR}/\n+                        cp jenkins-repo/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh ${scriptDir}/\n+                        chmod +x ${scriptDir}/collect_parameters.sh\n+                        ls -la ${scriptDir}/\n                     \"\"\"\n                 }\n-            }\n-        }\n-        \n-        stage('Collect Parameters') {\n-            steps {\n-                script {\n-                    echo \"=== Collecting SSM Parameters ===\"\n-                    \n-                    // スクリプトの実行\n-                    sh \"\"\"\n-                        # 環境変数を設定\n-                        export ENVIRONMENT=\"${params.ENVIRONMENT}\"\n-                        export ENV_FILTER=\"${env.ENV_FILTER}\"\n-                        export AWS_REGION=\"${AWS_REGION}\"\n-                        export BACKUP_DATE=\"${env.BACKUP_DATE}\"\n-                        export BACKUP_TIMESTAMP=\"${env.BACKUP_TIMESTAMP}\"\n-                        export DATA_DIR=\"${DATA_DIR}\"\n-                        \n-                        # スクリプト実行\n-                        ${SCRIPT_DIR}/collect_parameters.sh\n-                    \"\"\"\n-                    \n-                    // バックアップファイルの確認\n-                    if (fileExists(\"${DATA_DIR}/backup.json\")) {\n-                        def backupData = readJSON file: \"${DATA_DIR}/backup.json\"\n-                        env.PARAM_COUNT = backupData.parameter_count.toString()\n-                        \n-                        if (backupData.parameter_count == 0) {\n-                            echo \"WARNING: No parameters found for backup\"\n-                            currentBuild.result = 'UNSTABLE'\n-                        } else {\n-                            echo \"Backup file contains ${backupData.parameter_count} parameters\"\n+\n+                boolean dryRun = params.DRY_RUN as boolean\n+\n+                regionList.each { region ->\n+                    stage(\"Backup ${region}\") {\n+                        def ctx = loadRegionContext(\n+                            params.ENVIRONMENT,\n+                            region,\n+                            pipelineContext.metadataBasePath,\n+                            ssmHomeRegion,\n+                            dataDir\n+                        )\n+\n+                        def stageStart = System.currentTimeMillis()\n+\n+                        try {\n+                            def result = runBackupForRegion(\n+                                ctx + [\n+                                    defaultRegion: env.DEFAULT_REGION,\n+                                    scriptDir: scriptDir,\n+                                    envFilter: env.ENV_FILTER,\n+                                    backupDate: env.BACKUP_DATE,\n+                                    backupTimestamp: env.BACKUP_TIMESTAMP,\n+                                ],\n+                                dryRun\n+                            )\n+\n+                            def durationSeconds = ((System.currentTimeMillis() - stageStart) / 1000) as long\n+\n+                            regionSummaries[region] = [\n+                                status          : 'SUCCESS',\n+                                parameterCount  : result.parameterCount,\n+                                bucket          : ctx.bucketName,\n+                                s3Key           : result.s3Key,\n+                                dryRun          : dryRun,\n+                                durationSeconds : durationSeconds,\n+                                executionTimeSec: result.executionTimeSec,\n+                                failedCount     : result.failedCount,\n+                            ]\n+\n+                            echo \"Backup for ${region} completed (parameters=${result.parameterCount}, dryRun=${dryRun})\"\n+                        } catch (Throwable t) {\n+                            def durationSeconds = ((System.currentTimeMillis() - stageStart) / 1000) as long\n+                            regionSummaries[region] = [\n+                                status          : 'FAILED',\n+                                message         : t.getMessage(),\n+                                durationSeconds : durationSeconds,\n+                            ]\n+                            throw t\n                         }\n-                    } else {\n-                        error(\"Backup file was not created\")\n                     }\n                 }\n-            }\n-        }\n-        \n-        stage('Upload to S3') {\n-            when {\n-                expression { \n-                    return !params.DRY_RUN && env.PARAM_COUNT && env.PARAM_COUNT.toInteger() > 0\n+\n+                stage('Finalize Report') {\n+                    def summaryFile = \"${workDirRelative}/region_summaries.json\"\n+                    writeJSON file: summaryFile, json: regionSummaries, pretty: 4\n+                    archiveArtifacts artifacts: summaryFile, fingerprint: true\n+                    env.REGION_SUMMARY_PATH = \"${workDir}/${summaryFile.split('/', 2).last()}\"\n+                    echo \"Region summary stored at ${summaryFile}\"\n                 }\n             }\n-            steps {\n-                script {\n-                    echo \"=== Uploading Backup to S3 ===\"\n-                    \n-                    def backupFileName = \"ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\"\n-                    def s3Key = \"${env.BACKUP_DATE}/${backupFileName}\"\n-                    \n-                    // バックアップファイルの名前を変更\n-                    sh \"cp ${DATA_DIR}/backup.json ${DATA_DIR}/${backupFileName}\"\n-                    \n-                    // S3へアップロード（暗号化を明示的に指定）\n-                    sh \"\"\"\n-                        aws s3 cp ${DATA_DIR}/${backupFileName} \\\n-                            s3://${env.BACKUP_BUCKET}/${s3Key} \\\n-                            --sse AES256 \\\n-                            --region ${AWS_REGION}\n-                    \"\"\"\n-                    \n-                    echo \"Backup uploaded to: s3://${env.BACKUP_BUCKET}/${s3Key}\"\n-                    \n-                    // 最新バックアップ情報を更新（完全なS3キーを保存、暗号化を明示的に指定）\n-                    sh \"\"\"\n-                        echo '${s3Key}' | \\\n-                        aws s3 cp - s3://${env.BACKUP_BUCKET}/latest.txt \\\n-                            --sse AES256 \\\n-                            --region ${AWS_REGION}\n-                    \"\"\"\n-                    \n-                    // アップロード確認\n-                    def s3ObjectInfo = sh(\n-                        script: \"\"\"\n-                            aws s3api head-object \\\n-                                --bucket ${env.BACKUP_BUCKET} \\\n-                                --key ${s3Key} \\\n-                                --query '[ContentLength, LastModified]' \\\n-                                --output text \\\n-                                --region ${AWS_REGION}\n-                        \"\"\",\n-                        returnStdout: true\n-                    ).trim()\n-                    \n-                    echo \"S3 Object Info: ${s3ObjectInfo}\"\n-                    \n-                    // セキュリティ上の理由によりアーティファクトとしては保存しない\n-                    // バックアップファイルは暗号化されたS3バケットでのみ管理\n+\n+            currentBuild.result = currentBuild.result ?: 'SUCCESS'\n+        } catch (Throwable err) {\n+            currentBuild.result = currentBuild.result ?: 'FAILURE'\n+            throw err\n+        } finally {\n+            stage('Post Actions') {\n+                emitRunSummary(regionSummaries, params.ENVIRONMENT, params.DRY_RUN as boolean)\n+                try {\n+                    notifyChannels(regionSummaries, params.ENVIRONMENT, params.DRY_RUN as boolean)\n+                } catch (Throwable notificationError) {\n+                    echo \"Failed to send notifications: ${notificationError.getMessage() ?: notificationError.toString()}\"\n                 }\n-            }\n-        }\n-        \n-        stage('Dry Run Report') {\n-            when {\n-                expression { params.DRY_RUN }\n-            }\n-            steps {\n-                script {\n-                    def paramCount = env.PARAM_COUNT ?: '0'\n-                    \n-                    echo \"\"\"\n-                    =============================================\n-                    DRY RUN - バックアップ実行レポート\n-                    =============================================\n-                    \n-                    このドライランでは実際のS3アップロードは行われませんでした。\n-                    \n-                    バックアップ対象:\n-                    - 環境: ${params.ENVIRONMENT}\n-                    - パラメータ数: ${paramCount}\n-                    - バックアップ日時: ${env.BACKUP_TIMESTAMP}\n-                    \n-                    実行時の動作:\n-                    - S3バケット: ${env.BACKUP_BUCKET}\n-                    - S3パス: ${env.BACKUP_DATE}/\n-                    - ファイル名: ssm-backup-${params.ENVIRONMENT}-${env.BACKUP_TIMESTAMP}.json\n-                    \n-                    =============================================\n-                    \"\"\".stripIndent()\n-                    \n-                    // セキュリティ上の理由によりドライラン時もアーティファクトとして保存しない\n+                if (currentBuild.result == 'SUCCESS') {\n+                    echo \"✅ SSMパラメータのバックアップが正常に完了しました\"\n+                } else if (currentBuild.result == 'UNSTABLE') {\n+                    echo \"⚠️ バックアップは完了しましたが、警告があります\"\n+                } else {\n+                    echo \"❌ バックアップが失敗しました。ログを確認してください\"\n                 }\n+\n+                sh \"rm -rf ${workDir} jenkins-repo || true\"\n             }\n         }\n     }\n-    \n-    post {\n-        always {\n-            script {\n-                def paramCount = env.PARAM_COUNT ?: '0'\n-                \n-                // 実行サマリーの表示\n-                echo \"\"\"\n-                =============================================\n-                SSM Parameter Store Backup Summary\n-                =============================================\n-                Build: #${env.BUILD_NUMBER}\n-                Status: ${currentBuild.result ?: 'SUCCESS'}\n-                Environment: ${params.ENVIRONMENT}\n-                Parameters: ${paramCount}\n-                Timestamp: ${env.BACKUP_TIMESTAMP}\n-                Dry Run: ${params.DRY_RUN}\n-                =============================================\n-                \"\"\".stripIndent()\n-            }\n+}\n+\n+def loadRegionContext(String environment, String region, String metadataBasePath, String ssmHomeRegion, String dataDirRoot) {\n+    def parameterName = \"${metadataBasePath}/${region}/s3-bucket-name\"\n+    def bucketName = sh(\n+        script: \"\"\"\n+            aws ssm get-parameter \\\\\n+                --name \"${parameterName}\" \\\\\n+                --query 'Parameter.Value' \\\\\n+                --output text \\\\\n+                --region ${ssmHomeRegion} 2>/dev/null || echo \"\"\n+        \"\"\",\n+        returnStdout: true\n+    ).trim()\n+\n+    if (!bucketName) {\n+        error(\"Bucket definition missing for region ${region}. Expected SSM parameter ${parameterName}.\")\n+    }\n+\n+    def regionDataDir = \"${dataDirRoot}/${region}\"\n+    sh \"\"\"\n+        rm -rf ${regionDataDir}\n+        mkdir -p ${regionDataDir}\n+    \"\"\"\n+\n+    return [\n+        environment   : environment,\n+        region        : region,\n+        bucketName    : bucketName,\n+        regionDataDir : regionDataDir,\n+    ]\n+}\n+\n+def runBackupForRegion(Map ctx, boolean dryRun) {\n+    def envFilter = ctx.envFilter\n+    def scriptDir = ctx.scriptDir\n+    def backupDate = ctx.backupDate\n+    def backupTimestamp = ctx.backupTimestamp\n+    def environment = ctx.environment\n+    def region = ctx.region\n+    def regionDataDir = ctx.regionDataDir\n+    def bucketName = ctx.bucketName\n+    def defaultRegion = ctx.defaultRegion\n+\n+    def backupJsonPath = \"${regionDataDir}/backup.json\"\n+    def backupFileName = \"ssm-backup-${environment}-${region}-${backupTimestamp}.json\"\n+    def backupFilePath = \"${regionDataDir}/${backupFileName}\"\n+    def s3Key = \"${backupDate}/${region}/${backupFileName}\"\n+\n+    withEnv([\n+        \"ENVIRONMENT=${environment}\",\n+        \"ENV_FILTER=${envFilter}\",\n+        \"AWS_REGION=${region}\",\n+        \"BACKUP_DATE=${backupDate}\",\n+        \"BACKUP_TIMESTAMP=${backupTimestamp}\",\n+        \"DATA_DIR=${regionDataDir}\",\n+        \"TARGET_REGION=${region}\",\n+    ]) {\n+        sh \"\"\"\n+            rm -f ${regionDataDir}/*\n+            ${scriptDir}/collect_parameters.sh\n+        \"\"\"\n+    }\n+\n+    if (!fileExists(backupJsonPath)) {\n+        error(\"Backup file was not created for region ${region}.\")\n+    }\n+\n+    sh \"cp ${backupJsonPath} ${backupFilePath}\"\n+\n+    def backupData = readJSON file: backupJsonPath\n+    def parameterCount = (backupData.parameter_count ?: backupData.parameterCount ?: 0) as int\n+\n+    def summaryPath = \"${regionDataDir}/summary.json\"\n+    def scriptSummary = [:]\n+    if (fileExists(summaryPath)) {\n+        scriptSummary = readJSON file: summaryPath\n+    }\n+    def mergedSummary = [:]\n+    mergedSummary << (scriptSummary ?: [:])\n+    mergedSummary << [\n+        region         : region,\n+        parameterCount : parameterCount,\n+        s3Key          : s3Key,\n+        dryRun         : dryRun,\n+        bucket         : bucketName,\n+    ]\n+    writeJSON file: summaryPath, json: mergedSummary, pretty: 4\n+\n+    if (!dryRun && parameterCount > 0) {\n+        sh \"\"\"\n+            aws s3 cp ${backupFilePath} \\\n+                s3://${bucketName}/${s3Key} \\\n+                --sse AES256 \\\n+                --region ${region}\n+        \"\"\"\n+\n+        sh \"\"\"\n+            echo '${s3Key}' | aws s3 cp - s3://${bucketName}/latest-${region}.txt \\\n+                --sse AES256 \\\n+                --region ${region}\n+        \"\"\"\n+\n+        if (region == defaultRegion) {\n+            sh \"\"\"\n+                echo '${s3Key}' | aws s3 cp - s3://${bucketName}/latest.txt \\\n+                    --sse AES256 \\\n+                    --region ${region}\n+            \"\"\"\n         }\n-        \n-        success {\n-            echo \"✅ SSMパラメータのバックアップが正常に完了しました\"\n+\n+        def objectInfo = sh(\n+            script: \"\"\"\n+                aws s3api head-object \\\\\n+                    --bucket ${bucketName} \\\\\n+                    --key ${s3Key} \\\\\n+                    --query '[ContentLength, LastModified]' \\\\\n+                    --output text \\\\\n+                    --region ${region}\n+            \"\"\",\n+            returnStdout: true\n+        ).trim()\n+\n+        echo \"S3 Object Info [${region}]: ${objectInfo}\"\n+    } else if (dryRun) {\n+        echo \"[DRY RUN] Skipped S3 upload for ${region}. Planned key: ${s3Key}\"\n+    } else {\n+        echo \"No parameters to upload for ${region}. Skipping S3 upload.\"\n+    }\n+\n+    def executionTimeSec = mergedSummary.executionTimeSec != null ? (mergedSummary.executionTimeSec as long) : null\n+    def failedCount = mergedSummary.failedCount != null ? (mergedSummary.failedCount as long) : null\n+\n+    return [\n+        parameterCount : parameterCount,\n+        s3Key          : s3Key,\n+        backupFilePath : backupFilePath,\n+        summaryPath    : summaryPath,\n+        executionTimeSec: executionTimeSec,\n+        failedCount     : failedCount,\n+    ]\n+}\n+\n+def emitRunSummary(Map regionSummaries, String environment, boolean dryRun) {\n+    echo \"\"\"\n+    =============================================\n+    SSM Parameter Store Backup Summary\n+    =============================================\n+    Build       : #${env.BUILD_NUMBER}\n+    Status      : ${currentBuild.result ?: 'UNKNOWN'}\n+    Environment : ${environment}\n+    Dry Run     : ${dryRun}\n+    Regions     : ${env.REGION_LIST ?: 'N/A'}\n+    Summary File: ${env.REGION_SUMMARY_PATH ?: 'N/A'}\n+    =============================================\n+    \"\"\".stripIndent()\n+\n+    regionSummaries.each { region, summary ->\n+        echo \"Region: ${region} => ${summary}\"\n+    }\n+}\n+\n+def notifyChannels(Map regionSummaries, String environment, boolean dryRun) {\n+    def result = currentBuild.result ?: 'UNKNOWN'\n+    def runbookUrl = 'https://github.com/tielec/infrastructure-as-code/blob/main/docs/runbooks/ssm-backup.md'\n+    def buildUrl = env.BUILD_URL ?: ''\n+    def summaryArtifact = env.REGION_SUMMARY_PATH ?: 'N/A'\n+    def totalRegions = regionSummaries?.size() ?: 0\n+    def successCount = regionSummaries.findAll { it.value?.status == 'SUCCESS' }.size()\n+    def failureCount = Math.max(totalRegions - successCount, 0)\n+    def summaryLines = formatRegionSummaryLines(regionSummaries)\n+    def slackColor = (result == 'SUCCESS') ? 'good' : ((result == 'UNSTABLE') ? 'warning' : 'danger')\n+    def slackMessage = \"\"\"*Result*: ${result}\n+*Environment*: ${environment}\n+*Dry Run*: ${dryRun}\n+*Regions*: ${totalRegions} total / ${successCount} success / ${failureCount} failed\n+*Summary Artifact*: ${summaryArtifact}\n+${summaryLines ?: 'No regional data recorded.'}\n+Runbook: ${runbookUrl}\n+${buildUrl ? \"Build: ${buildUrl}\" : ''}\"\"\"\n+\n+    try {\n+        slackSend(\n+            channel: '#infra-backup-alerts',\n+            attachments: [[\n+                color     : slackColor,\n+                title     : \"SSM Backup ${environment} #${env.BUILD_NUMBER}\",\n+                text      : slackMessage,\n+                mrkdwn_in : ['text', 'pretext'],\n+            ]]\n+        )\n+    } catch (Throwable slackErr) {\n+        echo \"Slack notification failed: ${slackErr.getMessage() ?: slackErr.toString()}\"\n+    }\n+\n+    def emailSubjectPrefix = (result == 'FAILURE') ? '[FAIL]' : \"[${result}]\"\n+    def dryRunSuffix = dryRun ? ' (DRY RUN)' : ''\n+    def emailSubject = \"[SSM Backup] ${emailSubjectPrefix} ${environment} #${env.BUILD_NUMBER}${dryRunSuffix}\"\n+    def emailBody = \"\"\"<p>SSM Parameter Store backup for <strong>${environment}</strong> finished with result <strong>${result}</strong>.</p>\n+<p>Dry Run: <strong>${dryRun}</strong><br/>\n+Regions: <strong>${totalRegions}</strong> total / <strong>${successCount}</strong> success / <strong>${failureCount}</strong> failed</p>\n+<p><pre>${summaryLines ?: 'No regional data recorded.'}</pre></p>\n+<p>Region summary artifact: ${summaryArtifact}</p>\n+<p><a href=\"${runbookUrl}\">Runbook</a>${buildUrl ? \" | <a href=\\\\\"${buildUrl}\\\\\">Build Logs</a>\" : ''}</p>\"\"\"\n+\n+    def emailTo = 'ops-alerts@example.com'\n+    def emailCc = (result == 'FAILURE') ? 'sre-oncall@example.com' : ''\n+\n+    try {\n+        emailext(\n+            to: emailTo,\n+            cc: emailCc,\n+            subject: emailSubject,\n+            mimeType: 'text/html',\n+            body: emailBody\n+        )\n+    } catch (Throwable emailErr) {\n+        echo \"Email notification failed: ${emailErr.getMessage() ?: emailErr.toString()}\"\n+    }\n+}\n+\n+def formatRegionSummaryLines(Map regionSummaries) {\n+    if (!regionSummaries || regionSummaries.isEmpty()) {\n+        return ''\n+    }\n+\n+    def lines = []\n+    regionSummaries.keySet().sort().each { region ->\n+        def summary = regionSummaries[region] ?: [:]\n+        def fragments = []\n+        fragments << (summary.status ?: 'UNKNOWN')\n+        if (summary.parameterCount != null) {\n+            fragments << \"count=${summary.parameterCount}\"\n         }\n-        \n-        failure {\n-            echo \"❌ バックアップが失敗しました。ログを確認してください\"\n+        if (summary.failedCount) {\n+            fragments << \"failed=${summary.failedCount}\"\n         }\n-        \n-        unstable {\n-            echo \"⚠️ バックアップは完了しましたが、警告があります\"\n+        if (summary.durationSeconds != null) {\n+            fragments << \"stage=${summary.durationSeconds}s\"\n         }\n-        \n-        cleanup {\n-            // 作業ディレクトリのクリーンアップ\n-            sh \"rm -rf ${WORK_DIR} ${SCRIPT_DIR} jenkins-repo || true\"\n+        if (summary.executionTimeSec != null) {\n+            fragments << \"script=${summary.executionTimeSec}s\"\n         }\n+        if (summary.s3Key) {\n+            fragments << \"s3=${summary.s3Key}\"\n+        }\n+        if (summary.message) {\n+            fragments << \"message=${summary.message}\"\n+        }\n+        lines << \"${region}: ${fragments.join(', ')}\"\n     }\n-}\n\\ No newline at end of file\n+\n+    return lines.join('\\n')\n+}\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_27","type":"command_execution","command":"bash -lc 'git diff jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh'","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_27","type":"command_execution","command":"bash -lc 'git diff jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh'","aggregated_output":"diff --git a/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh b/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\nindex fbea0b2..48c50ed 100644\n--- a/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\n+++ b/jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\n@@ -17,6 +17,7 @@\n #   1: エラー発生\n \n set -euo pipefail\n+SECONDS=0\n \n echo \"======================================\"\n echo \"SSM Parameter Collection Script\"\n@@ -26,8 +27,12 @@ echo \"Filter: ${ENV_FILTER}\"\n echo \"Region: ${AWS_REGION}\"\n echo \"Backup Date: ${BACKUP_DATE}\"\n echo \"Backup Timestamp: ${BACKUP_TIMESTAMP}\"\n+echo \"Target Region: ${AWS_REGION}\"\n echo \"======================================\"\n \n+mkdir -p \"${DATA_DIR}\"\n+rm -f \"${DATA_DIR}/\"*\n+\n # AWS認証情報の確認\n echo \"Checking AWS credentials...\"\n if ! aws sts get-caller-identity --region ${AWS_REGION}; then\n@@ -178,93 +183,73 @@ fi\n PARAM_COUNT=$(echo \"$FILTERED_PARAMS\" | jq 'length' 2>/dev/null || echo \"0\")\n echo \"Found ${PARAM_COUNT} parameters for environment ${ENVIRONMENT}\"\n \n-if [ \"$PARAM_COUNT\" = \"0\" ]; then\n-    echo \"WARNING: No parameters found matching filter '${ENV_FILTER}'\"\n-    # 空のバックアップファイルを作成\n-    jq -n \\\n-        --arg date \"${BACKUP_DATE}\" \\\n-        --arg timestamp \"${BACKUP_TIMESTAMP}\" \\\n-        --arg environment \"${ENVIRONMENT}\" \\\n-        '{\n-            backup_date: $date,\n-            backup_timestamp: $timestamp,\n-            environment: $environment,\n-            parameter_count: 0,\n-            parameters: []\n-        }' > ${DATA_DIR}/backup.json\n-    exit 0\n-fi\n-\n-# パラメータ名の一覧を保存\n-echo \"$FILTERED_PARAMS\" | jq -r '.[].Name' > ${DATA_DIR}/parameter_names.txt\n-\n-# パラメータ取得前に待機（レート制限対策）\n-echo \"Waiting before fetching parameter values...\"\n-sleep 2\n-\n-# パラメータを取得してバックアップデータを作成（バッチ処理で高速化）\n-echo \"Fetching parameter values...\"\n BACKUP_DATA=\"[]\"\n BATCH_SIZE=10  # AWS APIの制限により最大10個\n FAILED_COUNT=0\n FAILED_PARAMS=()\n+TOTAL_PARAMS=$PARAM_COUNT\n \n-# パラメータ名を配列に読み込み\n-mapfile -t PARAM_NAMES < ${DATA_DIR}/parameter_names.txt\n-TOTAL_PARAMS=${#PARAM_NAMES[@]}\n+if [ \"$PARAM_COUNT\" != \"0\" ]; then\n+    # パラメータ名の一覧を保存\n+    echo \"$FILTERED_PARAMS\" | jq -r '.[].Name' > ${DATA_DIR}/parameter_names.txt\n \n-# バッチ処理でパラメータを取得\n-for ((i=0; i<$TOTAL_PARAMS; i+=BATCH_SIZE)); do\n-    # バッチの終了インデックスを計算\n-    end=$((i + BATCH_SIZE))\n-    if [ $end -gt $TOTAL_PARAMS ]; then\n-        end=$TOTAL_PARAMS\n-    fi\n-    \n-    # 進捗表示\n-    echo \"Fetching parameters $((i + 1))-$end of ${TOTAL_PARAMS}...\"\n-    \n-    # バッチ用のパラメータ名を準備\n-    batch_params=()\n-    for ((j=i; j<end; j++)); do\n-        batch_params+=(\"${PARAM_NAMES[$j]}\")\n-    done\n-    \n-    # get-parameters（複数形）でバッチ取得\n-    if [ ${#batch_params[@]} -gt 0 ]; then\n-        # AWS CLIコマンドを直接実行（xargsを使わない）\n-        BATCH_RESULT=$(aws ssm get-parameters \\\n-            --names \"${batch_params[@]}\" \\\n-            --with-decryption \\\n-            --output json \\\n-            --region ${AWS_REGION} 2>/dev/null || echo '{\"Parameters\": [], \"InvalidParameters\": []}')\n-        \n-        # 取得成功したパラメータを追加\n-        VALID_PARAMS=$(echo \"$BATCH_RESULT\" | jq '.Parameters // []')\n-        if [ \"$VALID_PARAMS\" != \"[]\" ] && [ \"$VALID_PARAMS\" != \"null\" ]; then\n-            BACKUP_DATA=$(echo \"$BACKUP_DATA\" | jq --argjson new_params \"$VALID_PARAMS\" '. + $new_params')\n+    # パラメータ取得前に待機（レート制限対策）\n+    echo \"Waiting before fetching parameter values...\"\n+    sleep 2\n+\n+    # パラメータ名を配列に読み込み\n+    mapfile -t PARAM_NAMES < ${DATA_DIR}/parameter_names.txt\n+    TOTAL_PARAMS=${#PARAM_NAMES[@]}\n+\n+    # パラメータを取得してバックアップデータを作成（バッチ処理で高速化）\n+    echo \"Fetching parameter values...\"\n+    for ((i=0; i<$TOTAL_PARAMS; i+=BATCH_SIZE)); do\n+        end=$((i + BATCH_SIZE))\n+        if [ $end -gt $TOTAL_PARAMS ]; then\n+            end=$TOTAL_PARAMS\n         fi\n-        \n-        # 取得失敗したパラメータを記録\n-        INVALID_PARAMS=$(echo \"$BATCH_RESULT\" | jq -r '.InvalidParameters[]?' 2>/dev/null)\n-        if [ -n \"$INVALID_PARAMS\" ]; then\n-            while IFS= read -r invalid_param; do\n-                echo \"Warning: Failed to get parameter: $invalid_param\"\n-                FAILED_PARAMS+=(\"$invalid_param\")\n-                FAILED_COUNT=$((FAILED_COUNT + 1))\n-            done <<< \"$INVALID_PARAMS\"\n+\n+        echo \"Fetching parameters $((i + 1))-$end of ${TOTAL_PARAMS}...\"\n+\n+        batch_params=()\n+        for ((j=i; j<end; j++)); do\n+            batch_params+=(\"${PARAM_NAMES[$j]}\")\n+        done\n+\n+        if [ ${#batch_params[@]} -gt 0 ]; then\n+            BATCH_RESULT=$(aws ssm get-parameters \\\n+                --names \"${batch_params[@]}\" \\\n+                --with-decryption \\\n+                --output json \\\n+                --region ${AWS_REGION} 2>/dev/null || echo '{\"Parameters\": [], \"InvalidParameters\": []}')\n+\n+            VALID_PARAMS=$(echo \"$BATCH_RESULT\" | jq '.Parameters // []')\n+            if [ \"$VALID_PARAMS\" != \"[]\" ] && [ \"$VALID_PARAMS\" != \"null\" ]; then\n+                BACKUP_DATA=$(echo \"$BACKUP_DATA\" | jq --argjson new_params \"$VALID_PARAMS\" '. + $new_params')\n+            fi\n+\n+            INVALID_PARAMS=$(echo \"$BATCH_RESULT\" | jq -r '.InvalidParameters[]?' 2>/dev/null)\n+            if [ -n \"$INVALID_PARAMS\" ]; then\n+                while IFS= read -r invalid_param; do\n+                    echo \"Warning: Failed to get parameter: $invalid_param\"\n+                    FAILED_PARAMS+=(\"$invalid_param\")\n+                    FAILED_COUNT=$((FAILED_COUNT + 1))\n+                done <<< \"$INVALID_PARAMS\"\n+            fi\n         fi\n-    fi\n-    \n-    # APIレート制限対策（バッチ間の待機時間を長めに）\n-    if [ $end -lt $TOTAL_PARAMS ]; then\n-        sleep 2\n-    fi\n-done\n+\n+        if [ $end -lt $TOTAL_PARAMS ]; then\n+            sleep 2\n+        fi\n+    done\n+else\n+    echo \"WARNING: No parameters found matching filter '${ENV_FILTER}'\"\n+fi\n \n COUNTER=$TOTAL_PARAMS\n+SUCCESSFUL_COUNT=$((COUNTER - FAILED_COUNT))\n \n-echo \"Successfully fetched $((COUNTER - FAILED_COUNT)) parameters\"\n+echo \"Successfully fetched ${SUCCESSFUL_COUNT} parameters\"\n if [ \"$FAILED_COUNT\" -gt 0 ]; then\n     echo \"Failed to fetch ${FAILED_COUNT} parameters\"\n fi\n@@ -275,7 +260,7 @@ BACKUP_JSON=$(jq -n \\\n     --arg date \"${BACKUP_DATE}\" \\\n     --arg timestamp \"${BACKUP_TIMESTAMP}\" \\\n     --arg environment \"${ENVIRONMENT}\" \\\n-    --arg count \"$((COUNTER - FAILED_COUNT))\" \\\n+    --arg count \"${SUCCESSFUL_COUNT}\" \\\n     --argjson parameters \"$BACKUP_DATA\" \\\n     '{\n         backup_date: $date,\n@@ -287,10 +272,38 @@ BACKUP_JSON=$(jq -n \\\n \n echo \"$BACKUP_JSON\" | jq '.' > ${DATA_DIR}/backup.json\n \n+execution_time=${SECONDS}\n+\n echo \"======================================\"\n echo \"Backup Summary\"\n echo \"======================================\"\n echo \"Backup file created: ${DATA_DIR}/backup.json\"\n-echo \"Total parameters backed up: $(echo \"$BACKUP_JSON\" | jq '.parameter_count')\"\n+echo \"Total parameters backed up: ${SUCCESSFUL_COUNT}\"\n echo \"Failed parameters: ${FAILED_COUNT}\"\n-echo \"======================================\"\n\\ No newline at end of file\n+echo \"======================================\"\n+\n+# サマリーファイルを生成して上位パイプラインで参照できるようにする\n+echo \"Creating summary file...\"\n+jq -n \\\n+    --arg environment \"${ENVIRONMENT}\" \\\n+    --arg region \"${AWS_REGION}\" \\\n+    --arg backupDate \"${BACKUP_DATE}\" \\\n+    --arg backupTimestamp \"${BACKUP_TIMESTAMP}\" \\\n+    --argjson parameterCount ${SUCCESSFUL_COUNT} \\\n+    --argjson failedCount ${FAILED_COUNT} \\\n+    --argjson executionTimeSec ${execution_time} \\\n+    '{\n+        environment: $environment,\n+        region: $region,\n+        backupDate: $backupDate,\n+        backupTimestamp: $backupTimestamp,\n+        parameterCount: $parameterCount,\n+        failedCount: $failedCount,\n+        executionTimeSec: $executionTimeSec,\n+        backup_date: $backupDate,\n+        backup_timestamp: $backupTimestamp,\n+        parameter_count: $parameterCount,\n+        failed_count: $failedCount\n+    }' > \"${DATA_DIR}/summary.json\"\n+\n+echo \"Summary file created: ${DATA_DIR}/summary.json\"\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_28","type":"command_execution","command":"bash -lc \"sed -n '1,80p' jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_28","type":"command_execution","command":"bash -lc \"sed -n '1,80p' jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\"","aggregated_output":"#!/bin/bash\n# SSM Parameter Collection and Backup Script\n# SSMパラメータを収集してバックアップファイルを作成\n# \n# 使用方法:\n#   このスクリプトは環境変数を通じて設定を受け取ります\n#   必須環境変数:\n#     - ENVIRONMENT: バックアップ対象の環境 (dev/prod)\n#     - ENV_FILTER: パラメータフィルタ文字列 (/dev/, /prod/)\n#     - AWS_REGION: AWSリージョン\n#     - BACKUP_DATE: バックアップ日付 (YYYY-MM-DD)\n#     - BACKUP_TIMESTAMP: バックアップタイムスタンプ\n#     - DATA_DIR: データ出力ディレクトリ\n#\n# 戻り値:\n#   0: 正常終了\n#   1: エラー発生\n\nset -euo pipefail\nSECONDS=0\n\necho \"======================================\"\necho \"SSM Parameter Collection Script\"\necho \"======================================\"\necho \"Environment: ${ENVIRONMENT}\"\necho \"Filter: ${ENV_FILTER}\"\necho \"Region: ${AWS_REGION}\"\necho \"Backup Date: ${BACKUP_DATE}\"\necho \"Backup Timestamp: ${BACKUP_TIMESTAMP}\"\necho \"Target Region: ${AWS_REGION}\"\necho \"======================================\"\n\nmkdir -p \"${DATA_DIR}\"\nrm -f \"${DATA_DIR}/\"*\n\n# AWS認証情報の確認\necho \"Checking AWS credentials...\"\nif ! aws sts get-caller-identity --region ${AWS_REGION}; then\n    echo \"Error: Failed to get AWS credentials. Please check IAM role or credentials.\"\n    exit 1\nfi\necho \"AWS credentials verified.\"\n\n# AWS API呼び出しのリトライ機能\naws_cli_with_retry() {\n    local max_retries=5\n    local retry_delay=3  # 初期待機時間を長めに設定\n    local retry_count=0\n    \n    while [ $retry_count -lt $max_retries ]; do\n        # AWS CLIを実行（環境変数で制御）\n        if output=$(AWS_PAGER=\"\" AWS_CLI_AUTO_PROMPT=off \"$@\" 2>&1); then\n            echo \"$output\"\n            return 0\n        else\n            if echo \"$output\" | grep -q \"ThrottlingException\\|Rate exceeded\"; then\n                retry_count=$((retry_count + 1))\n                echo \"  Rate limit hit. Retry ${retry_count}/${max_retries} after ${retry_delay}s...\" >&2\n                sleep $retry_delay\n                retry_delay=$((retry_delay * 2))  # Exponential backoff\n                if [ $retry_delay -gt 60 ]; then\n                    retry_delay=60  # Max delay 60s\n                fi\n            else\n                echo \"Error: $output\" >&2\n                return 1\n            fi\n        fi\n    done\n    \n    echo \"Error: Max retries reached\" >&2\n    return 1\n}\n\n# パラメータ一覧の取得（ページネーション対応、フィルタリング最適化）\nfetch_all_parameters() {\n    local next_token=\"\"\n    local page=1\n    local all_params=\"[]\"\n    \n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_29","type":"file_change","changes":[{"path":"/tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator/.ai-workflow/issue-391/04_implementation/output/implementation.md","kind":"update"}],"status":"completed"}}
{"type":"item.started","item":{"id":"item_30","type":"command_execution","command":"bash -lc \"sed -n '420,520p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_30","type":"command_execution","command":"bash -lc \"sed -n '420,520p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"    def emailBody = \"\"\"<p>SSM Parameter Store backup for <strong>${environment}</strong> finished with result <strong>${result}</strong>.</p>\n<p>Dry Run: <strong>${dryRun}</strong><br/>\nRegions: <strong>${totalRegions}</strong> total / <strong>${successCount}</strong> success / <strong>${failureCount}</strong> failed</p>\n<p><pre>${summaryLines ?: 'No regional data recorded.'}</pre></p>\n<p>Region summary artifact: ${summaryArtifact}</p>\n<p><a href=\"${runbookUrl}\">Runbook</a>${buildUrl ? \" | <a href=\\\\\"${buildUrl}\\\\\">Build Logs</a>\" : ''}</p>\"\"\"\n\n    def emailTo = 'ops-alerts@example.com'\n    def emailCc = (result == 'FAILURE') ? 'sre-oncall@example.com' : ''\n\n    try {\n        emailext(\n            to: emailTo,\n            cc: emailCc,\n            subject: emailSubject,\n            mimeType: 'text/html',\n            body: emailBody\n        )\n    } catch (Throwable emailErr) {\n        echo \"Email notification failed: ${emailErr.getMessage() ?: emailErr.toString()}\"\n    }\n}\n\ndef formatRegionSummaryLines(Map regionSummaries) {\n    if (!regionSummaries || regionSummaries.isEmpty()) {\n        return ''\n    }\n\n    def lines = []\n    regionSummaries.keySet().sort().each { region ->\n        def summary = regionSummaries[region] ?: [:]\n        def fragments = []\n        fragments << (summary.status ?: 'UNKNOWN')\n        if (summary.parameterCount != null) {\n            fragments << \"count=${summary.parameterCount}\"\n        }\n        if (summary.failedCount) {\n            fragments << \"failed=${summary.failedCount}\"\n        }\n        if (summary.durationSeconds != null) {\n            fragments << \"stage=${summary.durationSeconds}s\"\n        }\n        if (summary.executionTimeSec != null) {\n            fragments << \"script=${summary.executionTimeSec}s\"\n        }\n        if (summary.s3Key) {\n            fragments << \"s3=${summary.s3Key}\"\n        }\n        if (summary.message) {\n            fragments << \"message=${summary.message}\"\n        }\n        lines << \"${region}: ${fragments.join(', ')}\"\n    }\n\n    return lines.join('\\n')\n}\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_31","type":"file_change","changes":[{"path":"/tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator/jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_32","type":"file_change","changes":[{"path":"/tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator/jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile","kind":"update"}],"status":"completed"}}
{"type":"item.completed","item":{"id":"item_33","type":"file_change","changes":[{"path":"/tmp/jenkins-785de167/workspace/AI_Workflow/ai_workflow_orchestrator/jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile","kind":"update"}],"status":"completed"}}
{"type":"item.started","item":{"id":"item_34","type":"command_execution","command":"bash -lc \"sed -n '280,320p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_34","type":"command_execution","command":"bash -lc \"sed -n '280,320p' jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\"","aggregated_output":"        sh \"\"\"\n            rm -f ${regionDataDir}/*\n            ${scriptDir}/collect_parameters.sh\n        \"\"\"\n    }\n\n    if (!fileExists(backupJsonPath)) {\n        error(\"Backup file was not created for region ${region}.\")\n    }\n\n    sh \"cp ${backupJsonPath} ${backupFilePath}\"\n\n    def backupData = readJSON file: backupJsonPath\n    def parameterCount = (backupData.parameter_count ?: backupData.parameterCount ?: 0) as int\n\n    def summaryPath = \"${regionDataDir}/summary.json\"\n    def scriptSummary = [:]\n    if (fileExists(summaryPath)) {\n        scriptSummary = readJSON file: summaryPath\n    }\n    def mergedSummary = [:]\n    mergedSummary << (scriptSummary ?: [:])\n    mergedSummary << [\n        region         : region,\n        parameterCount : parameterCount,\n        s3Key          : s3Key,\n        dryRun         : dryRun,\n        bucket         : bucketName,\n    ]\n    writeJSON file: summaryPath, json: mergedSummary, pretty: 4\n\n    if (!dryRun && parameterCount > 0) {\n        sh \"\"\"\n            aws s3 cp ${backupFilePath} \\\n                s3://${bucketName}/${s3Key} \\\n                --sse AES256 \\\n                --region ${region}\n        \"\"\"\n\n        sh \"\"\"\n            echo '${s3Key}' | aws s3 cp - s3://${bucketName}/latest-${region}.txt \\\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_35","type":"command_execution","command":"bash -lc \"nl -ba jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile | sed -n '200,340p'\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_35","type":"command_execution","command":"bash -lc \"nl -ba jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile | sed -n '200,340p'\"","aggregated_output":"   200\t            currentBuild.result = currentBuild.result ?: 'FAILURE'\n   201\t            throw err\n   202\t        } finally {\n   203\t            stage('Post Actions') {\n   204\t                emitRunSummary(regionSummaries, params.ENVIRONMENT, params.DRY_RUN as boolean)\n   205\t                try {\n   206\t                    notifyChannels(regionSummaries, params.ENVIRONMENT, params.DRY_RUN as boolean)\n   207\t                } catch (Throwable notificationError) {\n   208\t                    echo \"Failed to send notifications: ${notificationError.getMessage() ?: notificationError.toString()}\"\n   209\t                }\n   210\t                if (currentBuild.result == 'SUCCESS') {\n   211\t                    echo \"✅ SSMパラメータのバックアップが正常に完了しました\"\n   212\t                } else if (currentBuild.result == 'UNSTABLE') {\n   213\t                    echo \"⚠️ バックアップは完了しましたが、警告があります\"\n   214\t                } else {\n   215\t                    echo \"❌ バックアップが失敗しました。ログを確認してください\"\n   216\t                }\n   217\t\n   218\t                sh \"rm -rf ${workDir} jenkins-repo || true\"\n   219\t            }\n   220\t        }\n   221\t    }\n   222\t}\n   223\t\n   224\tdef loadRegionContext(String environment, String region, String metadataBasePath, String ssmHomeRegion, String dataDirRoot) {\n   225\t    def parameterName = \"${metadataBasePath}/${region}/s3-bucket-name\"\n   226\t    def bucketName = sh(\n   227\t        script: \"\"\"\n   228\t            aws ssm get-parameter \\\\\n   229\t                --name \"${parameterName}\" \\\\\n   230\t                --query 'Parameter.Value' \\\\\n   231\t                --output text \\\\\n   232\t                --region ${ssmHomeRegion} 2>/dev/null || echo \"\"\n   233\t        \"\"\",\n   234\t        returnStdout: true\n   235\t    ).trim()\n   236\t\n   237\t    if (!bucketName) {\n   238\t        error(\"Bucket definition missing for region ${region}. Expected SSM parameter ${parameterName}.\")\n   239\t    }\n   240\t\n   241\t    def regionDataDir = \"${dataDirRoot}/${region}\"\n   242\t    sh \"\"\"\n   243\t        rm -rf ${regionDataDir}\n   244\t        mkdir -p ${regionDataDir}\n   245\t    \"\"\"\n   246\t\n   247\t    return [\n   248\t        environment   : environment,\n   249\t        region        : region,\n   250\t        bucketName    : bucketName,\n   251\t        regionDataDir : regionDataDir,\n   252\t    ]\n   253\t}\n   254\t\n   255\tdef runBackupForRegion(Map ctx, boolean dryRun) {\n   256\t    def envFilter = ctx.envFilter\n   257\t    def scriptDir = ctx.scriptDir\n   258\t    def backupDate = ctx.backupDate\n   259\t    def backupTimestamp = ctx.backupTimestamp\n   260\t    def environment = ctx.environment\n   261\t    def region = ctx.region\n   262\t    def regionDataDir = ctx.regionDataDir\n   263\t    def bucketName = ctx.bucketName\n   264\t    def defaultRegion = ctx.defaultRegion\n   265\t\n   266\t    def backupJsonPath = \"${regionDataDir}/backup.json\"\n   267\t    def backupFileName = \"ssm-backup-${environment}-${region}-${backupTimestamp}.json\"\n   268\t    def backupFilePath = \"${regionDataDir}/${backupFileName}\"\n   269\t    def s3Key = \"${backupDate}/${region}/${backupFileName}\"\n   270\t\n   271\t    withEnv([\n   272\t        \"ENVIRONMENT=${environment}\",\n   273\t        \"ENV_FILTER=${envFilter}\",\n   274\t        \"AWS_REGION=${region}\",\n   275\t        \"BACKUP_DATE=${backupDate}\",\n   276\t        \"BACKUP_TIMESTAMP=${backupTimestamp}\",\n   277\t        \"DATA_DIR=${regionDataDir}\",\n   278\t        \"TARGET_REGION=${region}\",\n   279\t    ]) {\n   280\t        sh \"\"\"\n   281\t            rm -f ${regionDataDir}/*\n   282\t            ${scriptDir}/collect_parameters.sh\n   283\t        \"\"\"\n   284\t    }\n   285\t\n   286\t    if (!fileExists(backupJsonPath)) {\n   287\t        error(\"Backup file was not created for region ${region}.\")\n   288\t    }\n   289\t\n   290\t    sh \"cp ${backupJsonPath} ${backupFilePath}\"\n   291\t\n   292\t    def backupData = readJSON file: backupJsonPath\n   293\t    def parameterCount = (backupData.parameter_count ?: backupData.parameterCount ?: 0) as int\n   294\t\n   295\t    def summaryPath = \"${regionDataDir}/summary.json\"\n   296\t    def scriptSummary = [:]\n   297\t    if (fileExists(summaryPath)) {\n   298\t        scriptSummary = readJSON file: summaryPath\n   299\t    }\n   300\t    def mergedSummary = [:]\n   301\t    mergedSummary << (scriptSummary ?: [:])\n   302\t    mergedSummary << [\n   303\t        region         : region,\n   304\t        parameterCount : parameterCount,\n   305\t        s3Key          : s3Key,\n   306\t        dryRun         : dryRun,\n   307\t        bucket         : bucketName,\n   308\t    ]\n   309\t    writeJSON file: summaryPath, json: mergedSummary, pretty: 4\n   310\t\n   311\t    if (!dryRun && parameterCount > 0) {\n   312\t        sh \"\"\"\n   313\t            aws s3 cp ${backupFilePath} \\\n   314\t                s3://${bucketName}/${s3Key} \\\n   315\t                --sse AES256 \\\n   316\t                --region ${region}\n   317\t        \"\"\"\n   318\t\n   319\t        sh \"\"\"\n   320\t            echo '${s3Key}' | aws s3 cp - s3://${bucketName}/latest-${region}.txt \\\n   321\t                --sse AES256 \\\n   322\t                --region ${region}\n   323\t        \"\"\"\n   324\t\n   325\t        if (region == defaultRegion) {\n   326\t            sh \"\"\"\n   327\t                echo '${s3Key}' | aws s3 cp - s3://${bucketName}/latest.txt \\\n   328\t                    --sse AES256 \\\n   329\t                    --region ${region}\n   330\t            \"\"\"\n   331\t        }\n   332\t\n   333\t        def objectInfo = sh(\n   334\t            script: \"\"\"\n   335\t                aws s3api head-object \\\\\n   336\t                    --bucket ${bucketName} \\\\\n   337\t                    --key ${s3Key} \\\\\n   338\t                    --query '[ContentLength, LastModified]' \\\\\n   339\t                    --output text \\\\\n   340\t                    --region ${region}\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_36","type":"command_execution","command":"bash -lc \"nl -ba jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile | sed -n '360,460p'\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_36","type":"command_execution","command":"bash -lc \"nl -ba jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile | sed -n '360,460p'\"","aggregated_output":"   360\t        executionTimeSec: executionTimeSec,\n   361\t        failedCount     : failedCount,\n   362\t    ]\n   363\t}\n   364\t\n   365\tdef emitRunSummary(Map regionSummaries, String environment, boolean dryRun) {\n   366\t    echo \"\"\"\n   367\t    =============================================\n   368\t    SSM Parameter Store Backup Summary\n   369\t    =============================================\n   370\t    Build       : #${env.BUILD_NUMBER}\n   371\t    Status      : ${currentBuild.result ?: 'UNKNOWN'}\n   372\t    Environment : ${environment}\n   373\t    Dry Run     : ${dryRun}\n   374\t    Regions     : ${env.REGION_LIST ?: 'N/A'}\n   375\t    Summary File: ${env.REGION_SUMMARY_PATH ?: 'N/A'}\n   376\t    =============================================\n   377\t    \"\"\".stripIndent()\n   378\t\n   379\t    regionSummaries.each { region, summary ->\n   380\t        echo \"Region: ${region} => ${summary}\"\n   381\t    }\n   382\t}\n   383\t\n   384\tdef notifyChannels(Map regionSummaries, String environment, boolean dryRun) {\n   385\t    def result = currentBuild.result ?: 'UNKNOWN'\n   386\t    def runbookUrl = 'https://github.com/tielec/infrastructure-as-code/blob/main/docs/runbooks/ssm-backup.md'\n   387\t    def buildUrl = env.BUILD_URL ?: ''\n   388\t    def summaryArtifact = env.REGION_SUMMARY_PATH ?: 'N/A'\n   389\t    def totalRegions = regionSummaries?.size() ?: 0\n   390\t    def successCount = regionSummaries.findAll { it.value?.status == 'SUCCESS' }.size()\n   391\t    def failureCount = Math.max(totalRegions - successCount, 0)\n   392\t    def summaryLines = formatRegionSummaryLines(regionSummaries)\n   393\t    def slackColor = (result == 'SUCCESS') ? 'good' : ((result == 'UNSTABLE') ? 'warning' : 'danger')\n   394\t    def slackMessage = \"\"\"*Result*: ${result}\n   395\t*Environment*: ${environment}\n   396\t*Dry Run*: ${dryRun}\n   397\t*Regions*: ${totalRegions} total / ${successCount} success / ${failureCount} failed\n   398\t*Summary Artifact*: ${summaryArtifact}\n   399\t${summaryLines ?: 'No regional data recorded.'}\n   400\tRunbook: ${runbookUrl}\n   401\t${buildUrl ? \"Build: ${buildUrl}\" : ''}\"\"\"\n   402\t\n   403\t    try {\n   404\t        slackSend(\n   405\t            channel: '#infra-backup-alerts',\n   406\t            attachments: [[\n   407\t                color     : slackColor,\n   408\t                title     : \"SSM Backup ${environment} #${env.BUILD_NUMBER}\",\n   409\t                text      : slackMessage,\n   410\t                mrkdwn_in : ['text', 'pretext'],\n   411\t            ]]\n   412\t        )\n   413\t    } catch (Throwable slackErr) {\n   414\t        echo \"Slack notification failed: ${slackErr.getMessage() ?: slackErr.toString()}\"\n   415\t    }\n   416\t\n   417\t    def emailSubjectPrefix = (result == 'FAILURE') ? '[FAIL]' : \"[${result}]\"\n   418\t    def dryRunSuffix = dryRun ? ' (DRY RUN)' : ''\n   419\t    def emailSubject = \"[SSM Backup] ${emailSubjectPrefix} ${environment} #${env.BUILD_NUMBER}${dryRunSuffix}\"\n   420\t    def summaryBlock = summaryLines ?: 'No regional data recorded.'\n   421\t    def escapedSummaryBlock = escapeHtml(summaryBlock)\n   422\t    def escapedSummaryArtifact = escapeHtml(summaryArtifact)\n   423\t    def emailBody = \"\"\"<p>SSM Parameter Store backup for <strong>${environment}</strong> finished with result <strong>${result}</strong>.</p>\n   424\t<p>Dry Run: <strong>${dryRun}</strong><br/>\n   425\tRegions: <strong>${totalRegions}</strong> total / <strong>${successCount}</strong> success / <strong>${failureCount}</strong> failed</p>\n   426\t<p><pre>${escapedSummaryBlock}</pre></p>\n   427\t<p>Region summary artifact: ${escapedSummaryArtifact}</p>\n   428\t<p><a href=\"${runbookUrl}\">Runbook</a>${buildUrl ? \" | <a href=\\\\\"${buildUrl}\\\\\">Build Logs</a>\" : ''}</p>\"\"\"\n   429\t\n   430\t    def emailTo = 'ops-alerts@example.com'\n   431\t    def emailCc = (result == 'FAILURE') ? 'sre-oncall@example.com' : ''\n   432\t\n   433\t    try {\n   434\t        emailext(\n   435\t            to: emailTo,\n   436\t            cc: emailCc,\n   437\t            subject: emailSubject,\n   438\t            mimeType: 'text/html',\n   439\t            body: emailBody\n   440\t        )\n   441\t    } catch (Throwable emailErr) {\n   442\t        echo \"Email notification failed: ${emailErr.getMessage() ?: emailErr.toString()}\"\n   443\t    }\n   444\t}\n   445\t\n   446\tdef formatRegionSummaryLines(Map regionSummaries) {\n   447\t    if (!regionSummaries || regionSummaries.isEmpty()) {\n   448\t        return ''\n   449\t    }\n   450\t\n   451\t    def lines = []\n   452\t    regionSummaries.keySet().sort().each { region ->\n   453\t        def summary = regionSummaries[region] ?: [:]\n   454\t        def fragments = []\n   455\t        fragments << (summary.status ?: 'UNKNOWN')\n   456\t        if (summary.parameterCount != null) {\n   457\t            fragments << \"count=${summary.parameterCount}\"\n   458\t        }\n   459\t        if (summary.failedCount) {\n   460\t            fragments << \"failed=${summary.failedCount}\"\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_37","type":"command_execution","command":"bash -lc \"nl -ba jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile | sed -n '460,520p'\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_37","type":"command_execution","command":"bash -lc \"nl -ba jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile | sed -n '460,520p'\"","aggregated_output":"   460\t            fragments << \"failed=${summary.failedCount}\"\n   461\t        }\n   462\t        if (summary.durationSeconds != null) {\n   463\t            fragments << \"stage=${summary.durationSeconds}s\"\n   464\t        }\n   465\t        if (summary.executionTimeSec != null) {\n   466\t            fragments << \"script=${summary.executionTimeSec}s\"\n   467\t        }\n   468\t        if (summary.s3Key) {\n   469\t            fragments << \"s3=${summary.s3Key}\"\n   470\t        }\n   471\t        if (summary.message) {\n   472\t            fragments << \"message=${summary.message}\"\n   473\t        }\n   474\t        lines << \"${region}: ${fragments.join(', ')}\"\n   475\t    }\n   476\t\n   477\t    return lines.join('\\n')\n   478\t}\n   479\t\n   480\tdef escapeHtml(String value) {\n   481\t    if (!value) {\n   482\t        return ''\n   483\t    }\n   484\t\n   485\t    value\n   486\t        .replace('&', '&amp;')\n   487\t        .replace('<', '&lt;')\n   488\t        .replace('>', '&gt;')\n   489\t        .replace('\"', '&quot;')\n   490\t        .replace(\"'\", '&#39;')\n   491\t}\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_38","type":"command_execution","command":"bash -lc \"nl -ba jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh | sed -n '150,260p'\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_38","type":"command_execution","command":"bash -lc \"nl -ba jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh | sed -n '150,260p'\"","aggregated_output":"   150\t        if [ -z \"$next_token\" ]; then\n   151\t            break\n   152\t        fi\n   153\t        \n   154\t        page=$((page + 1))\n   155\t        \n   156\t        # APIレート制限対策（ページ間の待機時間を長めに）\n   157\t        sleep 2\n   158\t    done\n   159\t    \n   160\t    echo \"$all_params\"\n   161\t}\n   162\t\n   163\t# メイン処理\n   164\techo \"Starting parameter collection...\"\n   165\t\n   166\t# AWS CLIのページネーション設定を無効化\n   167\texport AWS_PAGER=\"\"\n   168\t\n   169\t# フィルタリングされたパラメータを取得（API側でフィルタリング済み）\n   170\tFILTERED_PARAMS=$(fetch_all_parameters)\n   171\tif [ $? -ne 0 ] || [ -z \"$FILTERED_PARAMS\" ]; then\n   172\t    echo \"Warning: fetch_all_parameters failed or returned empty\" >&2\n   173\t    FILTERED_PARAMS='[]'\n   174\tfi\n   175\t\n   176\t# JSONの検証\n   177\tif ! echo \"$FILTERED_PARAMS\" | jq empty 2>/dev/null; then\n   178\t    echo \"Warning: Invalid JSON received from fetch_all_parameters\" >&2\n   179\t    echo \"Received data (first 200 chars): ${FILTERED_PARAMS:0:200}\" >&2\n   180\t    FILTERED_PARAMS='[]'\n   181\tfi\n   182\t\n   183\tPARAM_COUNT=$(echo \"$FILTERED_PARAMS\" | jq 'length' 2>/dev/null || echo \"0\")\n   184\techo \"Found ${PARAM_COUNT} parameters for environment ${ENVIRONMENT}\"\n   185\t\n   186\tBACKUP_DATA=\"[]\"\n   187\tBATCH_SIZE=10  # AWS APIの制限により最大10個\n   188\tFAILED_COUNT=0\n   189\tFAILED_PARAMS=()\n   190\tTOTAL_PARAMS=$PARAM_COUNT\n   191\t\n   192\tif [ \"$PARAM_COUNT\" != \"0\" ]; then\n   193\t    # パラメータ名の一覧を保存\n   194\t    echo \"$FILTERED_PARAMS\" | jq -r '.[].Name' > ${DATA_DIR}/parameter_names.txt\n   195\t\n   196\t    # パラメータ取得前に待機（レート制限対策）\n   197\t    echo \"Waiting before fetching parameter values...\"\n   198\t    sleep 2\n   199\t\n   200\t    # パラメータ名を配列に読み込み\n   201\t    mapfile -t PARAM_NAMES < ${DATA_DIR}/parameter_names.txt\n   202\t    TOTAL_PARAMS=${#PARAM_NAMES[@]}\n   203\t\n   204\t    # パラメータを取得してバックアップデータを作成（バッチ処理で高速化）\n   205\t    echo \"Fetching parameter values...\"\n   206\t    for ((i=0; i<$TOTAL_PARAMS; i+=BATCH_SIZE)); do\n   207\t        end=$((i + BATCH_SIZE))\n   208\t        if [ $end -gt $TOTAL_PARAMS ]; then\n   209\t            end=$TOTAL_PARAMS\n   210\t        fi\n   211\t\n   212\t        echo \"Fetching parameters $((i + 1))-$end of ${TOTAL_PARAMS}...\"\n   213\t\n   214\t        batch_params=()\n   215\t        for ((j=i; j<end; j++)); do\n   216\t            batch_params+=(\"${PARAM_NAMES[$j]}\")\n   217\t        done\n   218\t\n   219\t        if [ ${#batch_params[@]} -gt 0 ]; then\n   220\t            BATCH_RESULT=$(aws ssm get-parameters \\\n   221\t                --names \"${batch_params[@]}\" \\\n   222\t                --with-decryption \\\n   223\t                --output json \\\n   224\t                --region ${AWS_REGION} 2>/dev/null || echo '{\"Parameters\": [], \"InvalidParameters\": []}')\n   225\t\n   226\t            VALID_PARAMS=$(echo \"$BATCH_RESULT\" | jq '.Parameters // []')\n   227\t            if [ \"$VALID_PARAMS\" != \"[]\" ] && [ \"$VALID_PARAMS\" != \"null\" ]; then\n   228\t                BACKUP_DATA=$(echo \"$BACKUP_DATA\" | jq --argjson new_params \"$VALID_PARAMS\" '. + $new_params')\n   229\t            fi\n   230\t\n   231\t            INVALID_PARAMS=$(echo \"$BATCH_RESULT\" | jq -r '.InvalidParameters[]?' 2>/dev/null)\n   232\t            if [ -n \"$INVALID_PARAMS\" ]; then\n   233\t                while IFS= read -r invalid_param; do\n   234\t                    echo \"Warning: Failed to get parameter: $invalid_param\"\n   235\t                    FAILED_PARAMS+=(\"$invalid_param\")\n   236\t                    FAILED_COUNT=$((FAILED_COUNT + 1))\n   237\t                done <<< \"$INVALID_PARAMS\"\n   238\t            fi\n   239\t        fi\n   240\t\n   241\t        if [ $end -lt $TOTAL_PARAMS ]; then\n   242\t            sleep 2\n   243\t        fi\n   244\t    done\n   245\telse\n   246\t    echo \"WARNING: No parameters found matching filter '${ENV_FILTER}'\"\n   247\tfi\n   248\t\n   249\tCOUNTER=$TOTAL_PARAMS\n   250\tSUCCESSFUL_COUNT=$((COUNTER - FAILED_COUNT))\n   251\t\n   252\techo \"Successfully fetched ${SUCCESSFUL_COUNT} parameters\"\n   253\tif [ \"$FAILED_COUNT\" -gt 0 ]; then\n   254\t    echo \"Failed to fetch ${FAILED_COUNT} parameters\"\n   255\tfi\n   256\t\n   257\t# バックアップファイルの作成\n   258\techo \"Creating backup file...\"\n   259\tBACKUP_JSON=$(jq -n \\\n   260\t    --arg date \"${BACKUP_DATE}\" \\\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_39","type":"command_execution","command":"bash -lc \"nl -ba jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh | sed -n '260,320p'\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_39","type":"command_execution","command":"bash -lc \"nl -ba jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh | sed -n '260,320p'\"","aggregated_output":"   260\t    --arg date \"${BACKUP_DATE}\" \\\n   261\t    --arg timestamp \"${BACKUP_TIMESTAMP}\" \\\n   262\t    --arg environment \"${ENVIRONMENT}\" \\\n   263\t    --arg count \"${SUCCESSFUL_COUNT}\" \\\n   264\t    --argjson parameters \"$BACKUP_DATA\" \\\n   265\t    '{\n   266\t        backup_date: $date,\n   267\t        backup_timestamp: $timestamp,\n   268\t        environment: $environment,\n   269\t        parameter_count: $count | tonumber,\n   270\t        parameters: $parameters\n   271\t    }')\n   272\t\n   273\techo \"$BACKUP_JSON\" | jq '.' > ${DATA_DIR}/backup.json\n   274\t\n   275\texecution_time=${SECONDS}\n   276\t\n   277\techo \"======================================\"\n   278\techo \"Backup Summary\"\n   279\techo \"======================================\"\n   280\techo \"Backup file created: ${DATA_DIR}/backup.json\"\n   281\techo \"Total parameters backed up: ${SUCCESSFUL_COUNT}\"\n   282\techo \"Failed parameters: ${FAILED_COUNT}\"\n   283\techo \"======================================\"\n   284\t\n   285\t# サマリーファイルを生成して上位パイプラインで参照できるようにする\n   286\techo \"Creating summary file...\"\n   287\tjq -n \\\n   288\t    --arg environment \"${ENVIRONMENT}\" \\\n   289\t    --arg region \"${AWS_REGION}\" \\\n   290\t    --arg backupDate \"${BACKUP_DATE}\" \\\n   291\t    --arg backupTimestamp \"${BACKUP_TIMESTAMP}\" \\\n   292\t    --argjson parameterCount ${SUCCESSFUL_COUNT} \\\n   293\t    --argjson failedCount ${FAILED_COUNT} \\\n   294\t    --argjson executionTimeSec ${execution_time} \\\n   295\t    '{\n   296\t        environment: $environment,\n   297\t        region: $region,\n   298\t        backupDate: $backupDate,\n   299\t        backupTimestamp: $backupTimestamp,\n   300\t        parameterCount: $parameterCount,\n   301\t        failedCount: $failedCount,\n   302\t        executionTimeSec: $executionTimeSec,\n   303\t        backup_date: $backupDate,\n   304\t        backup_timestamp: $backupTimestamp,\n   305\t        parameter_count: $parameterCount,\n   306\t        failed_count: $failedCount\n   307\t    }' > \"${DATA_DIR}/summary.json\"\n   308\t\n   309\techo \"Summary file created: ${DATA_DIR}/summary.json\"\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_40","type":"command_execution","command":"bash -lc \"nl -ba .ai-workflow/issue-391/04_implementation/output/implementation.md | sed -n '120,220p'\"","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_40","type":"command_execution","command":"bash -lc \"nl -ba .ai-workflow/issue-391/04_implementation/output/implementation.md | sed -n '120,220p'\"","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_41","type":"command_execution","command":"bash -lc 'nl -ba .ai-workflow/issue-391/04_implementation/output/implementation.md'","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_41","type":"command_execution","command":"bash -lc 'nl -ba .ai-workflow/issue-391/04_implementation/output/implementation.md'","aggregated_output":"     1\t# 実装ログ\n     2\t\n     3\t## 実装サマリー\n     4\t- 実装戦略: EXTEND\n     5\t- 変更ファイル数: 9個\n     6\t- 新規作成ファイル数: 2個\n     7\t\n     8\t## 変更ファイル一覧\n     9\t\n    10\t### 新規作成\n    11\t- `docs/runbooks/ssm-backup.md`: マルチリージョン運用手順・ロールバック・通知フローを整理したRunbook\n    12\t- `.ai-workflow/issue-391/04_implementation/output/implementation.md`: 本フェーズの実装内容を記録\n    13\t\n    14\t### 修正\n    15\t- `pulumi/jenkins-ssm-backup-s3/index.ts`: 多リージョンS3/SSMリソース生成と地域メタデータ出力に対応\n    16\t- `pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml`: リージョン配列・デフォルトリージョン・SSMホームリージョンを追加\n    17\t- `pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml`: 本番スタック用に同上設定を追加\n    18\t- `pulumi/jenkins-ssm-backup-s3/package.json`: Jest系依存と`jest --passWithNoTests`スクリプトを定義\n    19\t- `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile`: Scripted Pipeline化とリージョン逐次ステージ/サマリ生成を実装\n    20\t- `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh`: リージョンログ/ディレクトリ初期化/summary出力を追加\n    21\t- `jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy`: 説明文・実行時間注記をマルチリージョン対応へ更新\n    22\t- `.ai-workflow/issue-391/metadata.json`: ワークフロー管理情報がimplementationフェーズに遷移\n    23\t\n    24\t## 実装詳細\n    25\t\n    26\t### ファイル1: pulumi/jenkins-ssm-backup-s3/index.ts\n    27\t- **変更内容**: リージョン配列を検証し、リージョンごとにProviderを切り替えてS3バケット/パブリックアクセスブロック/ポリシー/SSMパラメータを生成。既存互換キーとリージョンリスト/デフォルトリージョンのメタデータを出力し、`bucketMap` をエクスポート。\n    28\t- **理由**: PulumiスタックでFR-1/FR-2のマルチリージョン要件を満たし、Jenkins側がリージョン一覧とバケット名を参照できるようにするため。\n    29\t- **注意点**: `regions` と `defaultRegion` のPulumi Config設定が必須。`ssmHomeRegion` を変更する場合はJenkinsパイプラインの環境変数とも整合させる。\n    30\t\n    31\t### ファイル2: pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml\n    32\t- **変更内容**: `regions`, `defaultRegion`, `ssmHomeRegion` を追加し、Dev環境の多リージョン構成を定義。\n    33\t- **理由**: Pulumiコードの新しい入力インターフェースに合わせるため。\n    34\t- **注意点**: 本番と異なるリージョン構成にする場合は`defaultRegion`を必ず配列内に含める。\n    35\t\n    36\t### ファイル3: pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml\n    37\t- **変更内容**: Prod環境用にDevと同様のマルチリージョン設定フィールドを追加。\n    38\t- **理由**: Pulumiスタックを本番でも同じインターフェースで動かすため。\n    39\t- **注意点**: 本番のリージョン変更時はRunbookに従い事前告知と`pulumi preview`を実行する。\n    40\t\n    41\t### ファイル4: pulumi/jenkins-ssm-backup-s3/package.json\n    42\t- **変更内容**: Jest/ts-jest/@types/jestをdevDependenciesに追加し、`npm test`でエラーとならないよう`jest --passWithNoTests`を設定。\n    43\t- **理由**: Phase 5で追加予定のユニットテスト基盤を事前に整え、今フェーズでもTypeScriptビルド確認が可能な状態にするため。\n    44\t- **注意点**: `npm install`実行後は`node_modules`をコミットしないよう注意。\n    45\t\n    46\t### ファイル5: jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\n    47\t- **変更内容**: DeclarativeからScripted Pipelineへ移行し、SSMから取得したリージョン配列で逐次ステージを生成。リージョンごとのバックアップ実行、S3アップロード（地域別`latest-<region>.txt`とデフォルト用`latest.txt`）、`region_summaries.json`の生成、ポストサマリー出力を実装。\n    48\t- **理由**: FR-3の逐次処理/失敗制御要件に対応しつつ、リージョン数に応じた動的ステージ生成とメタ情報出力を実現するため。\n    49\t- **注意点**: SSMホームリージョンを変える場合は Jenkins ノードに `SSM_HOME_REGION` 環境変数を設定する。S3アップロードはパラメータ数0の場合にスキップする仕様。\n    50\t\n    51\t### ファイル6: jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\n    52\t- **変更内容**: 実行前に出力ディレクトリを初期化し、ターゲットリージョンをログに出力。バックアップ処理後にリージョン別サマリーJSONを生成。\n    53\t- **理由**: 多リージョン実行時にファイル衝突を避け、パイプラインで参照できる統一フォーマットのサマリーを提供するため。\n    54\t- **注意点**: jq/AWS CLI依存は従来通り。DRY_RUN時はパイプライン側で制御する。\n    55\t\n    56\t### ファイル7: jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy\n    57\t- **変更内容**: ジョブ説明とcronコメントをマルチリージョン運用向けに更新し、Runbook参照先を明示。\n    58\t- **理由**: FR-4の「UIパラメータ変更なしで多リージョン対応」の方針を維持しつつ利用者への注意点を明文化するため。\n    59\t- **注意点**: 説明文内のRunbookパス変更時は併せて更新する。\n    60\t\n    61\t### ファイル8: docs/runbooks/ssm-backup.md\n    62\t- **変更内容**: バックアップジョブの概要、リージョン追加/削除手順、ロールバック、通知、トラブルシューティングを整理。\n    63\t- **理由**: 運用チームが多リージョン化後の手順と連絡フローを即座に参照できるようにするため。\n    64\t- **注意点**: Pulumi Configや通知チャネルを更新したら本Runbookも同期する。\n    65\t\n    66\t### ファイル9: .ai-workflow/issue-391/metadata.json\n    67\t- **変更内容**: ワークフロー状態が implementation フェーズ開始を示すよう自動更新。\n    68\t- **理由**: AIワークフローの進行管理に伴うメタ情報更新。\n    69\t- **注意点**: システム更新のため手動で編集しない。\n    70\t\n    71\t## 次のステップ\n    72\t- Phase 5（test_implementation）でPulumi/Jenkinsの自動テストコードを追加し`npm test`/jenkinsfile-runner検証を実装\n    73\t- Phase 6（testing）で`pulumi preview`とjenkinsfile-runner dry-runを実施し、マルチリージョン挙動を確認\n    74\t\n    75\t## 修正履歴\n    76\t\n    77\t### 修正1: 通知処理の実装不足を解消\n    78\t- **指摘内容**: JenkinsのPost ActionsでSlack/メール通知が未実装で設計要件とRunbookの通知フローを満たしていない。\n    79\t- **修正内容**: `notifyChannels`ヘルパーを追加し、Post ActionsからSlack(`slackSend`)とメール(`emailext`)で`regionSummaries`の要約とRunbookリンクを配信するようにした。失敗時もパイプラインが継続するよう例外を捕捉。\n    80\t- **影響範囲**: `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile`\n    81\t\n    82\t### 修正2: バックアップサマリーに実行時間を追加\n    83\t- **指摘内容**: `collect_parameters.sh` が出力する `summary.json` に実行時間メトリクスがなく、通知や可観測性改善の設計意図を満たしていない。\n    84\t- **修正内容**: スクリプトで処理時間を計測し `executionTimeSec` を含めたサマリーを生成。パイプラインでサマリーを統合して`regionSummaries`へ反映し、通知でも参照できるようにした。\n    85\t- **影響範囲**: `jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh`, `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile`\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_42","type":"command_execution","command":"bash -lc 'git status -sb'","aggregated_output":"","status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_42","type":"command_execution","command":"bash -lc 'git status -sb'","aggregated_output":"## ai-workflow/issue-391...origin/ai-workflow/issue-391\n M .ai-workflow/issue-391/metadata.json\n M jenkins/jobs/dsl/admin/admin_ssm_backup_job.groovy\n M jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile\n M jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh\n M pulumi/jenkins-ssm-backup-s3/Pulumi.dev.yaml\n M pulumi/jenkins-ssm-backup-s3/Pulumi.prod.yaml\n M pulumi/jenkins-ssm-backup-s3/index.ts\n M pulumi/jenkins-ssm-backup-s3/package.json\n?? .ai-workflow/issue-391/04_implementation/\n?? docs/\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_43","type":"agent_message","text":"Added Slack/email notifications to Jenkins post actions and surfaced execution metrics for downstream reporting.\n- Wired the Post Actions stage to call a new `notifyChannels` helper so Slack (`slackSend`) and email (`emailext`) alerts always include regional summaries, runbook link, and stay non-blocking if delivery fails (`jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile:203`, `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile:384-444`).\n- Merged the script-generated summary with additional pipeline metadata, propagating `executionTimeSec`/`failedCount` into both the archived JSON and `regionSummaries` for richer notifications (`jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile:292-310`, `jenkins/jobs/pipeline/admin/ssm-backup/Jenkinsfile:345-361`).\n- Instrumented `collect_parameters.sh` to measure total runtime, support empty results without early exit, and emit an expanded summary schema that the pipeline now consumes (`jenkins/jobs/pipeline/admin/ssm-backup/scripts/collect_parameters.sh:183-309`).\n- Recorded the remediation details in the implementation log per workflow requirements (`.ai-workflow/issue-391/04_implementation/output/implementation.md:75-85`).\n\nTests: not run (Jenkins pipeline updates require a controller to exercise).\n\nNext steps: 1. Trigger a dry-run build to confirm Slack/email payloads render correctly and include execution metrics. 2. Inspect the archived `region_summaries.json` to verify the merged summary fields match notification content."}}
{"type":"turn.completed","usage":{"input_tokens":1783880,"cached_input_tokens":1711360,"output_tokens":28480}}